{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a1cf13",
   "metadata": {},
   "source": [
    "### When your Language Model cannot even do Determiners right: Probing for Anti-Presuppositions and the Maximize Presupposition! Principle | @BlackboxNLP 2023\n",
    "\n",
    "- In this notebook, we first preprocess the corpora from the SuperGlue datasets and then fine-tune the language models on these data with masked modeling\n",
    "\n",
    "- cf. huggingface tutorial: https://huggingface.co/learn/nlp-course/chapter7/3?fw=pt\n",
    "\n",
    "---- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5afd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import default_data_collator\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d6f7d",
   "metadata": {},
   "source": [
    "### Load model(s)\n",
    "\n",
    "- uncomment the one that shall be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95eed69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "## BERT base\n",
    "model_checkpoint = \"bert-base-cased\" \n",
    "\n",
    "## BERT mutliingual multil_bert \n",
    "#model_checkpoint = \"bert-base-multilingual-cased\" \n",
    "\n",
    "## xlm RoBERTa \n",
    "#model_checkpoint = \"xlm-roberta-base\"\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ffc666",
   "metadata": {},
   "source": [
    "### Load and preprocess super glue data\n",
    " \n",
    "- For question-answering datasets (BoolQ, COPA, MULTIRC), we merge the data in such a way that the context paragraph comes first, followed by the corresponding question, and then the correct answer. \n",
    "- As for natural language inference datasets (CB, RTE), we adopt the methodology described by Raffel et al. 2019, where we commence with the hypothesis, followed by a colon, and then the premise. We specifically include only entailment pairs, excluding instances involving contradictions.\n",
    " \n",
    " \n",
    "- We excluded the following corpora from SuperGlue because they were not \"beneficial\" for our task and/ or could not get preprocessed in a way that MLM can be applied:\n",
    "    - record (Reading Comprehension with Commonsense Reasoning Dataset, Zhang et al., 2018) (QA)\n",
    "    - wic(Word-in-Context, Pilehvar and Camacho-Collados, 2019) (WSD / word sense disambiguation)\n",
    "    - wsc (Winograd Schema Challenge, Levesque et al., 2012) (coref)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c060b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row(datasample):\n",
    "    for row in datasample:\n",
    "        for key, value in row.items():\n",
    "            #print(f\"Key: {key}, Value: {value}\")\n",
    "            print(key,\"--\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd5620",
   "metadata": {},
   "source": [
    "####  QA datasets\n",
    "- **BOOLQ** Boolean Questions, Clark et al., 2019\n",
    "- **COPA** Choice of Plausible Alternatives, Roemmele et al., 2011\n",
    "- **MULTIRC** Multi-Sentence Reading Comprehension, Khashabi et al., 2018\n",
    "\n",
    "\n",
    "- generally, for these QA datasets, the input is processed in this way: paragraph, question, right answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457f502e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset super_glue (/Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94532191064448169df2acd34fbd875f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-63f613b0c62f3545.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-647bdbc085b909b4.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-fa20af76f3656ea8.arrow\n"
     ]
    }
   ],
   "source": [
    "##  ---- superglue_boolq ----\n",
    "#(Boolean Questions, Clark et al., 2019) (QA)\n",
    "#QA task where each example consists of a short passage and a yes/no question about the passage.  \n",
    "\n",
    "superglue_boolq = load_dataset(\"super_glue\", \"boolq\") \n",
    "sample_boolq = superglue_boolq[\"train\"].shuffle().select(range(1))\n",
    "\n",
    "\n",
    "## Passage, Question and then the right answer\n",
    "def create_new_value(row):\n",
    "    label_value = \"Yes.\" if row['label'] == 1 else \"No.\"\n",
    "    question = row['question'].capitalize() + \"?\"\n",
    "    new_value = f\"{row['passage']} {question} {label_value}\"\n",
    "    return new_value\n",
    "\n",
    "# try out with sample \n",
    "#sample_boolq = sample_boolq.map(lambda row: {'new_column': create_new_value(row)})\n",
    "#print_row(sample_boolq)\n",
    "\n",
    "# now with the whole corpus (and also exlude the other columns because I don't need them anymore)\n",
    "superglue_boolq = superglue_boolq.map(lambda row: {'new_column': create_new_value(row)}, remove_columns=['question', 'passage', 'idx', 'label'])\n",
    "#superglue_boolq[\"train\"][\"new_column\"] #looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f4f6b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset super_glue (/Users/judith/.cache/huggingface/datasets/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4aeafcac19947229e6300e9fb3735ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f9423760f4452795e528092a36f12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-b1ef6cdf9295be1e.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-2a6c6f292ab84594.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-896bdc4a44de60a9.arrow\n"
     ]
    }
   ],
   "source": [
    "##  ---- superglue_copa ---- \n",
    "# (Choice of Plausible Alternatives, Roemmele et al., 2011) (QA)\n",
    "\n",
    "superglue_copa = load_dataset(\"super_glue\", \"copa\") \n",
    "sample_copa = superglue_copa[\"train\"].shuffle().select(range(1))\n",
    "\n",
    "## question:\n",
    "# cause: What was the cause for this?\n",
    "# effect: What happened as a result?\n",
    "## label:\n",
    "# 0 = premise 1 is the right answer\n",
    "# 1 = premise 2 is the rigth answer\n",
    "\n",
    "def create_new_value(row):\n",
    "    if row['question'] == \"cause\":\n",
    "        question = \"What was the cause for this?\"\n",
    "        if row[\"label\"] == 0:\n",
    "            new_value = f\"{row['premise']} {question} {row['choice1']}\"\n",
    "        else:\n",
    "            new_value = f\"{row['premise']} {question} {row['choice2']}\"\n",
    "    else:\n",
    "        question = \"What happened as a result?\"\n",
    "        if row[\"label\"] == 0:\n",
    "            new_value = f\"{row['premise']} {question} {row['choice1']}\"\n",
    "        else:\n",
    "            new_value = f\"{row['premise']} {question} {row['choice2']}\"\n",
    "            \n",
    "    return new_value\n",
    "\n",
    "### try out with sample \n",
    "sample_copa = sample_copa.map(lambda row: {'new_column': create_new_value(row)})\n",
    "#print_row(sample_copa)\n",
    "\n",
    "# now with the whole corpus (and exclude the columns that we don't need anymore)\n",
    "superglue_copa = superglue_copa.map(lambda row: {'new_column': create_new_value(row)}, remove_columns=['premise', 'choice1', 'choice2', 'question', 'idx', 'label'])\n",
    "#superglue_copa[\"train\"][\"new_column\"] #looks good\n",
    "\n",
    "### because here we now have more test- than training-data, we swap the training and test datasets\n",
    "new_train_dataset = superglue_copa[\"test\"]\n",
    "new_test_dataset = superglue_copa[\"train\"]\n",
    "validation_dataset = superglue_copa[\"validation\"]\n",
    "\n",
    "superglue_copa = DatasetDict({\n",
    "    \"train\": new_train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": new_test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a787b4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset super_glue (/Users/judith/.cache/huggingface/datasets/super_glue/multirc/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed453345b144dd9833e351d24805c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/multirc/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-cab9f51582d86a0e.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/multirc/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-d3f44f12dc1f447c.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/multirc/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-6ab5547a39c36313.arrow\n"
     ]
    }
   ],
   "source": [
    "##  ---- superglue_multirc ---- \n",
    "# (Multi-Sentence Reading Comprehension, Khashabi et al., 2018) (QA)\n",
    "# QA task where each example consists of a context paragraph, a question about that paragraph, \n",
    "# and a list of possible answers.\n",
    "\n",
    "superglue_multirc = load_dataset(\"super_glue\", \"multirc\") \n",
    "sample_multirc = superglue_multirc[\"train\"].shuffle().select(range(1))\n",
    "\n",
    "# hier: paragraph, question, then answer\n",
    "def create_new_value(row):\n",
    "    new_value = f\"{row['paragraph']} {row['question']} {row['answer']}\"\n",
    "    return new_value\n",
    "\n",
    "### try out with sample \n",
    "#sample_multirc = sample_multirc.map(lambda row: {'new_column': create_new_value(row)})\n",
    "#print_row(sample_multirc)\n",
    "\n",
    "# now with the whole corpus (and exclude the columns that we don't need anymore)\n",
    "superglue_multirc = superglue_multirc.map(lambda row: {'new_column': create_new_value(row)}, remove_columns=['paragraph', 'question', 'answer', 'idx', 'label'])\n",
    "#superglue_multirc[\"train\"][\"new_column\"] #looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a934b2",
   "metadata": {},
   "source": [
    "####  NLI datasets\n",
    "\n",
    "- **CB** CommitmentBank, De Marneffe et al., 2019\n",
    "- **RTE** Recognizing Textual Entailment \n",
    "\n",
    "- generally, here we handle the data preprocessing like the t5 authors: first the hypothesis; then \":\", then the premise (but only for entailment-pairs, i.e. no contradictions etc. included)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ef809ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset super_glue (/Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7865075a1430452a8bd0c3b2868f35c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-4e1fc93bcf0c1970.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-e410ca42beeee79c.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-620f7d8527718b4d.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ced1b48e4fe06474.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-dcde1066bb7d5268.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-9cc7e61c6dd6893a.arrow\n"
     ]
    }
   ],
   "source": [
    "##  ---- superglue_cb ---- \n",
    "#(CommitmentBank, De Marneffe et al., 2019) (NLI)\n",
    "# Each example consists of a premise containing an embedded clause \n",
    "# and the corresponding hypothesis is the extraction of that clause.\n",
    "\n",
    "superglue_cb = load_dataset(\"super_glue\", \"cb\") \n",
    "sample_cb = superglue_cb[\"train\"].shuffle().select(range(1))\n",
    "\n",
    "## I do it like the t5 authors; first the hypothesis; then \":\", then the premise\n",
    "## but I only do it for the cases where label = 0, otherwise it would be a contradiction\n",
    "def create_new_value(row):\n",
    "    if row['label'] != 1:\n",
    "        hypothesis = row['hypothesis'].capitalize() + \":\"\n",
    "        new_value = f\"{hypothesis} {row['premise']}\"\n",
    "        return new_value\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "### try out with sample \n",
    "#sample_cb = sample_cb.map(lambda row: {'new_column': create_new_value(row)})\n",
    "# Filter out None values to keep only rows where label is 1 (otherwise we include contradictions)\n",
    "#sample_cb = sample_cb.filter(lambda row: row['new_column'] is not None)\n",
    "# Print the updated dataset\n",
    "#print_row(sample_cb)\n",
    "\n",
    "### now with the whole corpus (and remove the columns that we don't need anymore)\n",
    "superglue_cb = superglue_cb.map(lambda row: {'new_column': create_new_value(row)}, remove_columns=['premise', 'hypothesis', 'idx', 'label'])\n",
    "# Filter out None values to keep only rows where label is 1 (otherwise we include contradictions)\n",
    "superglue_cb = superglue_cb.filter(lambda row: row['new_column'] is not None)\n",
    "#superglue_cb[\"train\"][\"new_column\"] #looks good\n",
    "\n",
    "### because here we now have more test- than training-data, we swap the training and test datasets\n",
    "new_train_dataset = superglue_cb[\"test\"]\n",
    "new_test_dataset = superglue_cb[\"train\"]\n",
    "validation_dataset = superglue_cb[\"validation\"]\n",
    "\n",
    "superglue_cb = DatasetDict({\n",
    "    \"train\": new_train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": new_test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150ad019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset super_glue (/Users/judith/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81de4f1e8d3645f9aac38748e5bec99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-1574df8752a454be.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-7a5309014a5b7476.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-112d1572824f523c.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-e31dfcc55dec0b4c.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-2d9a23f03c842e9d.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-0e6722f06993a598.arrow\n"
     ]
    }
   ],
   "source": [
    "##  ---- superglue_rte ---- \n",
    "# Recognizing Textual Entailment (NLI)\n",
    "# two-class classification: entailment and not_entailment.\n",
    "\n",
    "superglue_rte = load_dataset(\"super_glue\", \"rte\") \n",
    "sample_rte = superglue_rte[\"train\"].shuffle().select(range(3))\n",
    "\n",
    "#label 0 = entailmant: label 1 = no entailment\n",
    "## I do it like I did for cb (thus, like the t5 authors; first the hypothesis; then \":\", then the premise)\n",
    "## but I only do it for the cases where label = 0, otherwise it would be no entailment\n",
    "\n",
    "def create_new_value(row):\n",
    "    if row['label'] != 1:\n",
    "        hypothesis = row['hypothesis'].replace(\".\",\":\")\n",
    "        new_value = f\"{hypothesis} {row['premise']}\"\n",
    "        return new_value\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "### try out with sample \n",
    "#sample_rte = sample_rte.map(lambda row: {'new_column': create_new_value(row)})\n",
    "# Filter out None values to keep only rows where label is 1 (otherwise we include cases with no entailments)\n",
    "#sample_rte = sample_rte.filter(lambda row: row['new_column'] is not None)\n",
    "# Print the updated dataset\n",
    "#print_row(sample_rte)\n",
    "\n",
    "### now with the whole corpus (and remove the colums that I don't need anymore)\n",
    "superglue_rte = superglue_rte.map(lambda row: {'new_column': create_new_value(row)}, remove_columns=['premise', 'hypothesis', 'idx', 'label'])\n",
    "# Filter out None values to keep only rows where label is 1 (otherwise we include contradictions)\n",
    "superglue_rte = superglue_rte.filter(lambda row: row['new_column'] is not None)\n",
    "#superglue_rte[\"train\"][\"new_column\"] #looks good\n",
    "\n",
    "### because here we now have more test- than training-data, I swap the training and test datasets\n",
    "new_train_dataset = superglue_rte[\"test\"]\n",
    "new_test_dataset = superglue_rte[\"train\"]\n",
    "validation_dataset = superglue_rte[\"validation\"]\n",
    "\n",
    "superglue_rte = DatasetDict({\n",
    "    \"train\": new_train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": new_test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73cc190",
   "metadata": {},
   "source": [
    "#### Merge these corpora to one\n",
    "\n",
    "- --> but first only the three and the two NLI corpora together, because they need to be truncated differently:\n",
    "    - --> QA from the left (so that the question (which is at the end) remains in the data) \n",
    "    - --> NLI from the rigtht (so that the hypothesis (which is at the beginning) remains in the data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef41b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### QA \n",
    "# Create an empty datasetDict\n",
    "superglue_qa = DatasetDict()\n",
    "\n",
    "# List of datasets I need to merge\n",
    "dataset_dicts_to_merge_qa = [superglue_boolq, superglue_copa, superglue_multirc]\n",
    "\n",
    "# Iterate through each split and merge datasets\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    merged_datasets = [dataset_dict[split] for dataset_dict in dataset_dicts_to_merge_qa]\n",
    "    merged_dataset = concatenate_datasets(merged_datasets)\n",
    "    \n",
    "    # Add the merged dataset to the superglue_data\n",
    "    superglue_qa[split] = merged_dataset\n",
    "\n",
    "\n",
    "### NLI\n",
    "# Create an empty datasetDict\n",
    "superglue_nli = DatasetDict()\n",
    "\n",
    "# List of datasets I need to merge\n",
    "dataset_dicts_to_merge_nli = [superglue_cb, superglue_rte]\n",
    "\n",
    "# Iterate through each split and merge datasets\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    merged_datasets = [dataset_dict[split] for dataset_dict in dataset_dicts_to_merge_nli]\n",
    "    merged_dataset = concatenate_datasets(merged_datasets)\n",
    "    \n",
    "    # Add the merged dataset to the superglue_data\n",
    "    superglue_nli[split] = merged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda8644",
   "metadata": {},
   "source": [
    "#### Now tokenize the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50da23bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length: 3891\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "# Iterate through each split and find the maximum length\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    dataset = superglue_qa[split]\n",
    "    max_split_length = max(len(item) for item in dataset['new_column'])\n",
    "    max_length_data = max(max_length, max_split_length)\n",
    "\n",
    "print(\"Maximum length:\", max_length_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63a4427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"new_column\"], max_length=128, padding=True, truncation=True)#, truncation_side=\"left\")\n",
    "    if tokenizer.is_fast:\n",
    "        #grab the word IDs as we will need them later on to do whole word masking\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91765ac",
   "metadata": {},
   "source": [
    "#### Truncate the data\n",
    "- In order to fit the data to the models' maximum context size, we truncate the QA datasets from the left (since the questions appear at the end of the items) and the NLI datasets from the right (as the premises appear at the beginning of the items).s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d554cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-46ac5b06cfd21938.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-dcddbe8feef464b7.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-9611ea1df10822ed.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a267384b08248fd6.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-d499e7cd82fb40cd.arrow\n",
      "Loading cached processed dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-fb0fb20dc719d6f8.arrow\n"
     ]
    }
   ],
   "source": [
    "# QA\n",
    "tokenizer.truncation_side='left'\n",
    "tokenized_superglue_qa = superglue_qa.map(tokenize_function, batched=True) \n",
    "\n",
    "# NLI\n",
    "tokenizer.truncation_side='right'\n",
    "tokenized_superglue_nli = superglue_nli.map(tokenize_function, batched=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbf0ad00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Zosie's wishes had been consulted : But first Zosie had come. Rufus, driving back from London with the hashish his dealer swore was genuine Indian charas and a package of best Colombian, picked her off the street - ` ` a piece of property that is found ownerless''. And she had slept with Rufus in the Centaur Room it being taken for granted she would share his bed though Adam did not think her wishes had been consulted. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_superglue_nli[\"train\"][32][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28961683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Leaning Tower of Pisa - - The tower's tilt began during construction in the 12th century, caused by an inadequate foundation on ground too soft on one side to properly support the structure's weight. The tilt increased in the decades before the structure was completed in the 14th century. It gradually increased until the structure was stabilized ( and the tilt partially corrected ) by efforts in the late 20th and early 21st centuries. Was the leaning tower of pisa built leaning? No. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_superglue_qa[\"train\"][32][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f6bee949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ca10e9789443fb02.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-6a8aee13b1b97207.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/judith/.cache/huggingface/datasets/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-cbc86b15f24db202.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-206f4127b9ac0ebd.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-912b5a508e973784.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-40b315ce4281c92f.arrow\n"
     ]
    }
   ],
   "source": [
    "### shuffle each of these \n",
    "tokenized_superglue_nli = tokenized_superglue_nli.shuffle(seed=42)\n",
    "tokenized_superglue_qa = tokenized_superglue_qa.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97305d41",
   "metadata": {},
   "source": [
    "#### data balancing \n",
    "- We balance our corpus by downsampling the QA datasets, ensuring equal representation between the QA and NLI datasets, leading to a total of 9608 datapoints\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "090ad5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-206f4127b9ac0ebd.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-912b5a508e973784.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/judith/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-40b315ce4281c92f.arrow\n"
     ]
    }
   ],
   "source": [
    "### sample down the qa dataset because it is much bigger\n",
    "# (for now) (maybe later I can try with a bigger dataset) we make it is as big as the nli dataset\n",
    "\n",
    "# Sizes from the nli dataset\n",
    "train_size_nli = tokenized_superglue_nli[\"train\"].num_rows\n",
    "test_size_nli = tokenized_superglue_nli[\"test\"].num_rows\n",
    "validation_size_nli = tokenized_superglue_nli[\"validation\"].num_rows\n",
    "\n",
    "# Split the QA dataset into train, validation, and test\n",
    "train_qa = tokenized_superglue_qa[\"train\"].shuffle(seed=42).select(range(train_size_nli))\n",
    "validation_qa = tokenized_superglue_qa[\"validation\"].shuffle(seed=42).select(range(validation_size_nli))\n",
    "test_qa = tokenized_superglue_qa[\"test\"].shuffle(seed=42).select(range(test_size_nli))\n",
    "\n",
    "# Create a new DatasetDict with the adjusted splits\n",
    "tokenized_superglue_qa = DatasetDict({\n",
    "    \"train\": train_qa,\n",
    "    \"validation\": validation_qa,\n",
    "    \"test\": test_qa\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "642e23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge these two now to one big datset:\n",
    "\n",
    "# Create an empty super_glue datasetDict\n",
    "tokenized_superglue = DatasetDict()\n",
    "\n",
    "# List of datasets I need to merge\n",
    "dataset_dicts_to_merge = [tokenized_superglue_nli, tokenized_superglue_qa]\n",
    "\n",
    "# Iterate through each split and merge datasets\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    merged_datasets = [dataset_dict[split] for dataset_dict in dataset_dicts_to_merge]\n",
    "    merged_dataset = concatenate_datasets(merged_datasets)    \n",
    "    # Add the merged dataset to the superglue_data\n",
    "    tokenized_superglue[split] = merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1419f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57843861946c4b8fb13a0cfef0ef1bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c385d1758180489cae30105a53a33e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3217b1fa74f445f8802061a8286b61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add labels column (to have the ground truth for MLM)\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    dataset = tokenized_superglue[split]\n",
    "    dataset = dataset.map(lambda row: {'labels': row['input_ids'], **row})\n",
    "    tokenized_superglue[split] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d5c4451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Laden family was forced to find a buyer for Usama's share of the family company in 1994. The Saudi government subsequently froze the proceeds of the sale. This action had the effect of divesting Bin Laden of what otherwise might indeed have been a large fortune. Nor were Bin Laden's assets in Sudan a source of money for al Qaeda. When Bin Laden lived in Sudan from 1991 to 1996, he owned a number of businesses and other assets. How did the tradecraft of each of the 9 / 11 plotters go to fund the terrorist activities of 9 / 11? Ordinary expenditures that defeated detection [SEP]\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_superglue[\"train\"][3294][\"input_ids\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "524e650c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Laden family was forced to find a buyer for Usama's share of the family company in 1994. The Saudi government subsequently froze the proceeds of the sale. This action had the effect of divesting Bin Laden of what otherwise might indeed have been a large fortune. Nor were Bin Laden's assets in Sudan a source of money for al Qaeda. When Bin Laden lived in Sudan from 1991 to 1996, he owned a number of businesses and other assets. How did the tradecraft of each of the 9 / 11 plotters go to fund the terrorist activities of 9 / 11? Ordinary expenditures that defeated detection [SEP]\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_superglue[\"train\"][3294][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91b23ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"new_column\"\n",
    "for split in tokenized_superglue.keys():\n",
    "    dataset = tokenized_superglue[split]\n",
    "    dataset = dataset.remove_columns(\"new_column\")\n",
    "    tokenized_superglue[split] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c813d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 6500\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 348\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 2760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_superglue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f4ea3",
   "metadata": {},
   "source": [
    "#### insert  the masked tokens \n",
    "\n",
    "- To proceed with the fine-tuning of the models using these datasets for mask-filling, we employ masking on the specific minimal pairs of interest, that is, the words \"the,\" \"a,\" \"all,\" and \"both\"\n",
    " \n",
    "- data collator from hugging face is masking tokens not words...  --> because we want to mask whole words, we need to build our own  data collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63cba67",
   "metadata": {},
   "source": [
    "#### --> Random masking (not in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f2ba319",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Whole word masking\n",
    "\n",
    "wwm_probability = 0.1 #=fraction of the tokens to be masked (15% = used fo BERT and common choice in literature)\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "        \n",
    "        # Create a map between words and corresponding token indices\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Randomly mask words\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "        feature[\"labels\"] = new_labels\n",
    "\n",
    "    return default_data_collator(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cfb92a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] was purchased solely with federal legal aid dollars, should be used to provide legal services for poor [MASK] in South Carolina [MASK] \" Kleiman said. LSC wants the title to go to the equal justice center in Charleston or [MASK] we want 100 [MASK] of the proceeds from [MASK] sale of [MASK] [MASK] to stay [MASK] Charleston. We are not contemplating taking that money out of South [MASK], \" he said. Kleiman said if [MASK] neighborhood legal program in Charleston \" had honored their [MASK], this would [MASK] be an issue [MASK] \" A local bar in [MASK] County paid how much for the Charelston building? $ 50, 000 [SEP]'\n"
     ]
    }
   ],
   "source": [
    "### Testing\n",
    "samples = [tokenized_superglue[\"train\"][i] for i in range(4001,4002)]\n",
    "batch1 = whole_word_masking_data_collator(samples)\n",
    "\n",
    "for chunk in batch1[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77eae69",
   "metadata": {},
   "source": [
    "#### --> Specific word masking: Masking the determiners \"a\" and \"the\" as well as  \"all\" and \"both\" (in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05a5eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the words we want to mask\n",
    "words_to_mask = [\"the\", \"a\", \"all\", \"both\", \"The\", \"A\", \"All\", \"Both\"]\n",
    "\n",
    "# Function to mask specific words.. .\n",
    "def mask_specific_words(input_text, words_to_mask, tokenizer):\n",
    "    words = input_text.split()\n",
    "    masked_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in words_to_mask:\n",
    "            masked_words.append(tokenizer.mask_token)\n",
    "        else:\n",
    "            masked_words.append(word)\n",
    "            \n",
    "    masked_text = \" \".join(masked_words)\n",
    "    return masked_text\n",
    "\n",
    "# Test the specific word masking function\n",
    "#input_text = \"Of these, Jan received the banana and a pear. All bananas and both pears...\"\n",
    "#words_to_mask = [\"the\", \"a\", \"both\", \"all\"]\n",
    "#print(mask_specific_words(input_text, words_to_mask, tokenizer)) #lÃ¤uft \n",
    "\n",
    "# create own data collator\n",
    "def specific_word_masking_data_collator(features, words_to_mask=words_to_mask, tokenizer=tokenizer):\n",
    "    new_features = []\n",
    "    \n",
    "    for feature in features:\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_input_ids = []\n",
    "        new_labels = []\n",
    "        \n",
    "        for idx, token_id in enumerate(input_ids):\n",
    "            token = tokenizer.decode([token_id])\n",
    "            if token in words_to_mask:\n",
    "                new_input_ids.append(tokenizer.mask_token_id)\n",
    "                new_labels.append(labels[idx])\n",
    "            else:\n",
    "                new_input_ids.append(token_id)\n",
    "                new_labels.append(-100)\n",
    "        \n",
    "        new_feature = {\n",
    "            \"input_ids\": new_input_ids,\n",
    "            \"attention_mask\": feature[\"attention_mask\"],\n",
    "            \"token_type_ids\": feature[\"token_type_ids\"],\n",
    "            \"labels\": new_labels\n",
    "        }\n",
    "        new_features.append(new_feature)\n",
    "\n",
    "    return default_data_collator(new_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bb3b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for RoBERTA: no token_type_ids\n",
    "def specific_word_masking_data_collator_roberta(features, words_to_mask=words_to_mask, tokenizer=tokenizer):\n",
    "    new_features = []\n",
    "    \n",
    "    for feature in features:\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_input_ids = []\n",
    "        new_labels = []\n",
    "        \n",
    "        for idx, token_id in enumerate(input_ids):\n",
    "            token = tokenizer.decode([token_id])\n",
    "            if token in words_to_mask:\n",
    "                new_input_ids.append(tokenizer.mask_token_id)\n",
    "                new_labels.append(labels[idx])\n",
    "            else:\n",
    "                new_input_ids.append(token_id)\n",
    "                new_labels.append(-100)\n",
    "        \n",
    "        new_feature = {\n",
    "            \"input_ids\": new_input_ids,\n",
    "            \"attention_mask\": feature[\"attention_mask\"],\n",
    "            #\"token_type_ids\": feature[\"token_type_ids\"],\n",
    "            \"labels\": new_labels\n",
    "        }\n",
    "        new_features.append(new_feature)\n",
    "\n",
    "    return default_data_collator(new_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d47f3033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] was purchased solely with federal legal aid dollars, should be used to provide legal services for poor people in South Carolina, \" Kleiman said. LSC wants [MASK] title to go to [MASK] equal justice center in Charleston or \" we want 100 percent of [MASK] proceeds from [MASK] sale of [MASK] building to stay in Charleston. We are not contemplating taking that money out of South Carolina, \" he said. Kleiman said if [MASK] neighborhood legal program in Charleston \" had honored their obligation, this would not be an issue. \" [MASK] local bar in Charleston County paid how much for [MASK] Charelston building? $ 50, 000 [SEP]'\n"
     ]
    }
   ],
   "source": [
    "### Testing\n",
    "\n",
    "# Apply the specific_word_masking_data_collator function\n",
    "samples = [tokenized_superglue[\"train\"][i] for i in range(4001,4002)]\n",
    "\n",
    "#batch2 = specific_word_masking_data_collator(samples, words_to_mask, tokenizer)\n",
    "batch2 = specific_word_masking_data_collator_roberta(samples, words_to_mask, tokenizer)\n",
    "\n",
    "for chunk in batch2[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055bbf7",
   "metadata": {},
   "source": [
    "### Finetune the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f3564bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle.. :)\n",
    "tokenized_superglue = tokenized_superglue.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ace678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/judith/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "## log into the huggingcae hub\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f72bea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98890172",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify the arguments for the Trainer:\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_superglue[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-SuperGlue\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    #push_to_hub=True,\n",
    "    #fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    "    remove_unused_columns=False # so we don't lose the word ids \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c69388b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for testing reasons, make a small subset:\n",
    "\n",
    "small_train_subset = tokenized_superglue[\"train\"].select(range(400)) \n",
    "small_validation_subset = tokenized_superglue[\"validation\"].select(range(100))  \n",
    "small_test_subset = tokenized_superglue[\"test\"].select(range(200))  \n",
    "\n",
    "small_dataset = DatasetDict({\n",
    "    \"train\": small_train_subset,\n",
    "    \"validation\": small_validation_subset,\n",
    "    \"test\": small_test_subset\n",
    "})\n",
    "\n",
    "#small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9136278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the trainer for the whole word masking /random masked tokens\n",
    "trainer_random_masking = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_superglue[\"train\"],\n",
    "    eval_dataset=tokenized_superglue[\"test\"],\n",
    "    data_collator = whole_word_masking_data_collator,\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f202e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_mask = [\"the\", \"a\", \"all\", \"both\", \"The\", \"A\", \"All\", \"Both\"]\n",
    "\n",
    "# instantiate the trainer for the specific word masking /masking our target words\n",
    "trainer_specific_masking = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_superglue[\"train\"],\n",
    "    eval_dataset=tokenized_superglue[\"test\"],\n",
    "    #train_dataset=small_dataset[\"train\"], #test... \n",
    "    #eval_dataset=small_dataset[\"test\"], #test... \n",
    "    data_collator=specific_word_masking_data_collator, \n",
    "    #data_collator=specific_word_masking_data_collator_roberta, #when Roberta model is used! \n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05040da6",
   "metadata": {},
   "source": [
    "#### Training... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b3881f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='306' max='306' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [306/306 6:47:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.234393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.253583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.284446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=306, training_loss=0.11653236104966769, metrics={'train_runtime': 24542.6477, 'train_samples_per_second': 0.795, 'train_steps_per_second': 0.012, 'total_flos': 1286410394880000.0, 'train_loss': 0.11653236104966769, 'epoch': 3.0})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_specific_masking.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b74cbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model! \n",
    "trainer_specific_masking.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0326d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
