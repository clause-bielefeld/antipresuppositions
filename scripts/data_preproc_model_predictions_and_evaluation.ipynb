{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139ba5ff",
   "metadata": {},
   "source": [
    "### When your Language Model cannot even do Determiners right: Probing for Anti-Presuppositions and the Maximize Presupposition! Principle | @BlackboxNLP 2023\n",
    "\n",
    "- In this notebook, we preprocess the data from Schneider et al. 2019 (available here: https://osf.io/tjp3e) and then use it for masked language modeling for the different conditions as described in the paper. Also we calculate basic statistics for these results (e.g. Completion Sensitivy) and create some plots.\n",
    "\n",
    "---- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983df9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35366e5",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7435f7",
   "metadata": {},
   "source": [
    "###### UNIQUE FRUIT AND NON-UNIQUE FRUIT CONDITIONS (determiners \"the\" and \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d582778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3232936567.py:132: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_bert['masked_sentence'] = df_bert['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3232936567.py:133: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_bert_multil['masked_sentence'] = df_bert_multil['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3232936567.py:134: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_roberta['masked_sentence'] = df_roberta['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3232936567.py:140: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_bert_EN['masked_sentence'] = df_bert_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3232936567.py:141: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_bert_multil_EN['masked_sentence'] = df_bert_multil_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3232936567.py:142: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_roberta_EN['masked_sentence'] = df_roberta_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3232936567.py:147: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_bert_EN_finetuned_specific['masked_sentence'] = df_bert_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3232936567.py:148: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_bert_multil_EN_finetuned_specific['masked_sentence'] = df_bert_multil_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3232936567.py:149: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_roberta_EN_finetuned_specific['masked_sentence'] = df_roberta_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n"
     ]
    }
   ],
   "source": [
    "####### GERMAN #######\n",
    "# load the data \n",
    "stimuli_df = pd.read_csv('../data/Schneider2019_stimulus_sentences.csv', header=None)\n",
    "\n",
    "# only keep the columns that are relevant\n",
    "columns_to_exclude = [2, 7, 8, 9]\n",
    "\n",
    "stimuli_df = stimuli_df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# rename the columns\n",
    "stimuli_df = stimuli_df.rename(columns={0:\"unique_fruit\", 1:\"double_fruit\",\n",
    "                           3:\"determiner\", 4:\"received_fruit\", \n",
    "                           5:\"stimulus_sentence\", 6:\"sentence_type\",\n",
    "                           10:\"condition\", 11:\"item\"})\n",
    "\n",
    "# only keep the felicitous and infelicitous conditions (i.e. exclude the false conditions)\n",
    "stimuli_df = stimuli_df.loc[(stimuli_df['condition'] != 1) & (stimuli_df['condition'] != 2)]\n",
    "\n",
    "## Replace values in the \"double_fruit\" column with plural forms (so I can use these to fill the template)\n",
    "#print(sorted(list(stimuli_df[\"double_fruit\"].value_counts().keys())))\n",
    "replacements = {\n",
    "    'Ananas': \"Ananasse\",\n",
    "    'Banane': 'Bananen',\n",
    "    'Birne': 'Birnen',\n",
    "    'Erdbeere': 'Erdbeeren',\n",
    "    'Orange': 'Orangen',\n",
    "    'Pflaume': 'Pflaumen',\n",
    "    'Zitrone': 'Zitronen'}\n",
    "\n",
    "stimuli_df['double_fruit'] = stimuli_df['double_fruit'].replace(replacements)\n",
    "\n",
    "## Exclude the infelicitous conditions from the dataframe\n",
    "# (because (DEF_infelicitous == INDEF_felicitous and INDEF_infelicitous == DEF_felicitous)\n",
    "stimuli_df = stimuli_df.loc[~stimuli_df['sentence_type'].isin([\"INDEF_infelicitous\", \"DEF_infelicitous\"])]\n",
    "\n",
    "####### ENGLISH #######\n",
    "## create an English version of this dataset \n",
    "stimuli_df_EN = stimuli_df.copy()\n",
    "\n",
    "# map old fruit values to new values\n",
    "fruit_mapping = {\n",
    "    'Ananas': 'pineapple',\n",
    "    'Ananasse': 'pineapples',\n",
    "    'Banane': 'banana',\n",
    "    'Bananen': 'bananas',\n",
    "    'Birne': 'pear',\n",
    "    'Birnen': 'pears',\n",
    "    'Erdbeere': 'strawberry',\n",
    "    'Erdbeeren': 'strawberries',\n",
    "    'Orange': 'orange',\n",
    "    'Orangen': 'oranges',\n",
    "    'Pflaume': 'plum',\n",
    "    'Pflaumen': 'plums',\n",
    "    'Zitrone': 'lemon', \n",
    "    'Zitronen': 'lemons'}\n",
    "\n",
    "# Replace the values in \"unique_fruit\" column \n",
    "stimuli_df_EN['unique_fruit'] = stimuli_df_EN['unique_fruit'].replace(fruit_mapping)\n",
    "stimuli_df_EN['received_fruit'] = stimuli_df_EN['received_fruit'].replace(fruit_mapping)\n",
    "stimuli_df_EN['double_fruit'] = stimuli_df_EN['double_fruit'].replace(fruit_mapping)\n",
    "\n",
    "### Translate the stimulus_sentence\n",
    "def cut_sentence(sentence):\n",
    "    # Split the sentence into words\n",
    "    words = sentence.split()\n",
    "    # Remove the first three words and the last word\n",
    "    words = words[3:-1]\n",
    "    # Join the remaining words back into a new sentence\n",
    "    new_sentence = ' '.join(words)\n",
    "    new_sentence += \".\"\n",
    "    return new_sentence\n",
    "\n",
    "# Function to translate sentences and replace \"die\" and \"eine\" with \"the\" and \"a\"\n",
    "def translate_sentence(sentence):\n",
    "    translated_sentence = sentence\n",
    "    words = sentence.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if word in ['die', 'eine'] and i < len(words) - 1:\n",
    "            next_word = words[i + 1]\n",
    "            if next_word in fruit_mapping:\n",
    "                determiner = 'the' if word == 'die' else 'a'\n",
    "                translated_sentence = translated_sentence.replace(f\"{word} {next_word}\", f\"Of these, Jan received {determiner} {fruit_mapping[next_word]}\")\n",
    "                translated_sentence = cut_sentence(translated_sentence)\n",
    "    return translated_sentence\n",
    "\n",
    "# Apply the translation function to the DataFrame\n",
    "stimuli_df_EN['stimulus_sentence'] = stimuli_df_EN['stimulus_sentence'].apply(translate_sentence)\n",
    "\n",
    "\n",
    "####### BOTH LANGUAGES #######\n",
    "## add column with the filled context sentence to the dataframes\n",
    "context_template = \"Jans Mutter war einkaufen. Sie hat eine {} und zwei {} gekauft.\" \n",
    "context_template_EN = \"Jan's mother was shopping. She bought one {} and two {}.\"\n",
    "\n",
    "# List to store the filled sentences\n",
    "filled_sentences = []\n",
    "filled_sentences_EN = [] \n",
    "\n",
    "# Iterate through the DataFrame and fill the placeholders\n",
    "for index, row in stimuli_df.iterrows():\n",
    "    unique_fruit = row['unique_fruit']\n",
    "    double_fruit = row['double_fruit']\n",
    "    context = context_template.format(unique_fruit, double_fruit)\n",
    "    filled_sentences.append(context)\n",
    "\n",
    "for index, row in stimuli_df_EN.iterrows():\n",
    "    unique_fruit = row['unique_fruit']\n",
    "    double_fruit = row['double_fruit']\n",
    "    context_EN = context_template_EN.format(unique_fruit, double_fruit)\n",
    "    filled_sentences_EN.append(context_EN)\n",
    "    \n",
    "# Now add a new column to the DataFrames with the filled sentences\n",
    "stimuli_df['context_sentence'] = filled_sentences\n",
    "stimuli_df_EN['context_sentence'] = filled_sentences_EN\n",
    "\n",
    "#### create dfs for the different models\n",
    "df_bert = stimuli_df.copy()\n",
    "df_bert_multil = stimuli_df.copy()\n",
    "df_roberta = stimuli_df.copy()\n",
    "\n",
    "df_bert_EN = stimuli_df_EN.copy()\n",
    "df_bert_multil_EN = stimuli_df_EN.copy()\n",
    "df_roberta_EN = stimuli_df_EN.copy()\n",
    "\n",
    "# dfs for the different fine-tuned models (only for English)\n",
    "df_bert_EN_finetuned_specific = stimuli_df_EN.copy()\n",
    "df_bert_multil_EN_finetuned_specific = stimuli_df_EN.copy()\n",
    "df_roberta_EN_finetuned_specific = stimuli_df_EN.copy()\n",
    "\n",
    "# add a new column to the dataframe with a MASK token for the determiners\n",
    "#(--> note: different models may have different mask tokens)\n",
    "df_bert['masked_sentence'] = df_bert['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
    "df_bert_multil['masked_sentence'] = df_bert_multil['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
    "df_roberta['masked_sentence'] = df_roberta['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '<mask>')\n",
    "# add a new column to the dataframe which contains the whole prompt for the models (i.e. context + masked sentence')\n",
    "df_bert['prompt'] = df_bert['context_sentence'] + ' ' + df_bert['masked_sentence']\n",
    "df_bert_multil['prompt'] = df_bert_multil['context_sentence'] + ' ' + df_bert_multil['masked_sentence']\n",
    "df_roberta['prompt'] = df_roberta['context_sentence'] + ' ' + df_roberta['masked_sentence']\n",
    "\n",
    "df_bert_EN['masked_sentence'] = df_bert_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_bert_multil_EN['masked_sentence'] = df_bert_multil_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_roberta_EN['masked_sentence'] = df_roberta_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
    "df_bert_EN['prompt'] = df_bert_EN['context_sentence'] + ' ' + df_bert_EN['masked_sentence']\n",
    "df_bert_multil_EN['prompt'] = df_bert_multil_EN['context_sentence'] + ' ' + df_bert_multil_EN['masked_sentence']\n",
    "df_roberta_EN['prompt'] = df_roberta_EN['context_sentence'] + ' ' + df_roberta_EN['masked_sentence']\n",
    "\n",
    "df_bert_EN_finetuned_specific['masked_sentence'] = df_bert_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_bert_multil_EN_finetuned_specific['masked_sentence'] = df_bert_multil_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_roberta_EN_finetuned_specific['masked_sentence'] = df_roberta_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
    "df_bert_EN_finetuned_specific['prompt'] = df_bert_EN_finetuned_specific['context_sentence'] + ' ' + df_bert_EN_finetuned_specific['masked_sentence']\n",
    "df_bert_multil_EN_finetuned_specific['prompt'] = df_bert_multil_EN_finetuned_specific['context_sentence'] + ' ' + df_bert_multil_EN_finetuned_specific['masked_sentence']\n",
    "df_roberta_EN_finetuned_specific['prompt'] = df_roberta_EN_finetuned_specific['context_sentence'] + ' ' + df_roberta_EN_finetuned_specific['masked_sentence']\n",
    "\n",
    "#Add the model names as a separate column in the dataframes\n",
    "df_bert['model_name'] = \"bert-base-german-cased\"\n",
    "df_bert_multil['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_roberta['model_name'] =\"xlm-roberta-base\"\n",
    "df_bert_EN['model_name'] = \"bert-base-cased\"\n",
    "df_bert_multil_EN['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_roberta_EN['model_name'] =\"xlm-roberta-base\"\n",
    "df_bert_EN_finetuned_specific['model_name'] = \"bert-base-cased -- finetuned specific masking\"\n",
    "df_bert_multil_EN_finetuned_specific['model_name'] =\"bert-base-multilingual-cased finetuned specific masking\"\n",
    "df_roberta_EN_finetuned_specific['model_name'] =\"xlm-roberta-base -- finetuned specific masking\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee504ad9",
   "metadata": {},
   "source": [
    "###### PAIR OF FRUITS CONDITION (triggers \"both\" and \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0acad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3977963494.py:82: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allebeide_bert['masked_sentence'] = df_allebeide_bert['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3977963494.py:83: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allebeide_bert_multil['masked_sentence'] = df_allebeide_bert_multil['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3977963494.py:84: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allebeide_roberta['masked_sentence'] = df_allebeide_roberta['stimulus_sentence'].str.replace(r'\\bbeide\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3977963494.py:89: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_bert['masked_sentence'] = df_allboth_bert['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3977963494.py:90: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_bert_multil['masked_sentence'] = df_allboth_bert_multil['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3977963494.py:91: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_roberta['masked_sentence'] = df_allboth_roberta['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3977963494.py:96: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_bert_finetuned_specific['masked_sentence'] = df_allboth_bert_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3977963494.py:97: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_bert_multil_finetuned_specific['masked_sentence'] = df_allboth_bert_multil_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3977963494.py:98: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_roberta_finetuned_specific['masked_sentence'] = df_allboth_roberta_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n"
     ]
    }
   ],
   "source": [
    "####### GERMAN #######\n",
    "### create a new dataframe to test the alle/beide condition (not from Schneider, but my extension)\n",
    "stimuli_df_allebeide = stimuli_df.copy()\n",
    "\n",
    "# only keep the INDEF condition because it is the easiest one to change\n",
    "stimuli_df_allebeide = stimuli_df_allebeide.loc[~stimuli_df_allebeide['sentence_type'].isin([\"DEF_felicitous\"])]\n",
    "\n",
    "# function to replace the singular fruit names with the plural form and the determiner with \"beide\"\n",
    "def replace_fruit_names(sentence, double_fruit):\n",
    "    # Extract the singular fruit name from the sentence\n",
    "    singular_fruit = sentence.split(\" \")[-2]  # because the singular fruit name is always the second last word\n",
    "\n",
    "    # Replace the singular fruit name with the plural form from \"double_fruit\" column\n",
    "    plural_fruit = double_fruit if double_fruit else singular_fruit + \"en\"\n",
    "    new_sentence = sentence.replace(singular_fruit, plural_fruit)\n",
    "    \n",
    "    # Replace \"eine\" with \"beide\"\n",
    "    new_sentence = new_sentence.replace(\"eine\", \"beide\")\n",
    "    return new_sentence\n",
    "\n",
    "# Apply the function to the \"sentence_type\" column \n",
    "stimuli_df_allebeide['stimulus_sentence'] = stimuli_df_allebeide.apply(lambda row: replace_fruit_names(row['stimulus_sentence'], row['double_fruit']), axis=1)\n",
    "\n",
    "# Replace column name \"determiner\" with \"trigger\"\n",
    "stimuli_df_allebeide.rename(columns={'determiner': 'trigger'}, inplace=True)\n",
    "\n",
    "# Replace values in \"sentence_type\" column\n",
    "stimuli_df_allebeide['sentence_type'] = stimuli_df_allebeide['sentence_type'].replace('INDEF_felicitous', 'all_both')\n",
    "\n",
    "# Replace values in \"trigger\" column\n",
    "stimuli_df_allebeide['trigger'] = stimuli_df_allebeide['trigger'].replace('INDEF', 'beide')\n",
    "\n",
    "\n",
    "####### ENGLISH #######\n",
    "### create a new dataframe to test all/both for the English data too\n",
    "stimuli_df_allboth = stimuli_df_EN.copy()\n",
    "\n",
    "# only keep the INDEF condition because it is the easiest one to change\n",
    "stimuli_df_allboth = stimuli_df_allboth.loc[~stimuli_df_allboth['sentence_type'].isin([\"DEF_felicitous\"])]\n",
    "\n",
    "def replace_with_plural(sentence, double_fruit):\n",
    "    # Extract the singular fruit name from the sentence\n",
    "    singular_fruit = sentence.split()[-2].lower()  # Assuming the singular fruit name is always the second last word\n",
    "    \n",
    "    # Replace the singular fruit name with the plural form from \"double_fruit\" column\n",
    "    plural_fruit = double_fruit if double_fruit else singular_fruit + \"s\"\n",
    "    \n",
    "    # Replace only the exact occurrence of the singular fruit name with the plural form in the sentence\n",
    "    new_sentence = sentence.replace(' ' + singular_fruit + ' ', ' both ' + plural_fruit + ' ')\n",
    "    # work around because replacing didn't work\n",
    "    new_sentence = \" \".join(new_sentence.split()[0:-1])+ \".\"\n",
    "    \n",
    "    return new_sentence\n",
    "\n",
    "# Apply the function to the \"stimulus_sentence\" column\n",
    "stimuli_df_allboth['stimulus_sentence'] = stimuli_df_allboth.apply(lambda row: replace_with_plural(row['stimulus_sentence'], row['double_fruit']), axis=1)\n",
    "\n",
    "# Replace column name \"determiner\" with \"trigger\"\n",
    "stimuli_df_allboth.rename(columns={'determiner': 'trigger'}, inplace=True)\n",
    "\n",
    "# Replace values in \"sentence_type\" column\n",
    "stimuli_df_allboth['sentence_type'] = stimuli_df_allboth['sentence_type'].replace('INDEF_felicitous', 'all_both')\n",
    "\n",
    "# Replace values in \"trigger\" column\n",
    "stimuli_df_allboth['trigger'] = stimuli_df_allboth['trigger'].replace('INDEF', 'both')\n",
    "\n",
    "#### create dfs for the different models\n",
    "df_allebeide_bert = stimuli_df_allebeide.copy()\n",
    "df_allebeide_bert_multil = stimuli_df_allebeide.copy()\n",
    "df_allebeide_roberta = stimuli_df_allebeide.copy()\n",
    "\n",
    "df_allboth_bert = stimuli_df_allboth.copy()\n",
    "df_allboth_bert_multil = stimuli_df_allboth.copy()\n",
    "df_allboth_roberta = stimuli_df_allboth.copy()\n",
    "\n",
    "# dfs for the different fine-tuned models (only for English)\n",
    "df_allboth_bert_finetuned_specific = stimuli_df_allboth.copy()\n",
    "df_allboth_bert_multil_finetuned_specific = stimuli_df_allboth.copy()\n",
    "df_allboth_roberta_finetuned_specific = stimuli_df_allboth.copy()\n",
    "\n",
    "# add a new column to the dataframe with a MASK token for the determiners\n",
    "df_allebeide_bert['masked_sentence'] = df_allebeide_bert['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
    "df_allebeide_bert_multil['masked_sentence'] = df_allebeide_bert_multil['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
    "df_allebeide_roberta['masked_sentence'] = df_allebeide_roberta['stimulus_sentence'].str.replace(r'\\bbeide\\b', '<mask>')\n",
    "df_allebeide_bert['prompt'] = df_allebeide_bert['context_sentence'] + ' ' + df_allebeide_bert['masked_sentence']\n",
    "df_allebeide_bert_multil['prompt'] = df_allebeide_bert_multil['context_sentence'] + ' ' + df_allebeide_bert_multil['masked_sentence']\n",
    "df_allebeide_roberta['prompt'] = df_allebeide_roberta['context_sentence'] + ' ' + df_allebeide_roberta['masked_sentence']\n",
    "\n",
    "df_allboth_bert['masked_sentence'] = df_allboth_bert['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_bert_multil['masked_sentence'] = df_allboth_bert_multil['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_roberta['masked_sentence'] = df_allboth_roberta['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n",
    "df_allboth_bert['prompt'] = df_allboth_bert['context_sentence'] + ' ' + df_allboth_bert['masked_sentence']\n",
    "df_allboth_bert_multil['prompt'] = df_allboth_bert_multil['context_sentence'] + ' ' + df_allboth_bert_multil['masked_sentence']\n",
    "df_allboth_roberta['prompt'] = df_allboth_roberta['context_sentence'] + ' ' + df_allboth_roberta['masked_sentence']\n",
    "\n",
    "df_allboth_bert_finetuned_specific['masked_sentence'] = df_allboth_bert_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_bert_multil_finetuned_specific['masked_sentence'] = df_allboth_bert_multil_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_roberta_finetuned_specific['masked_sentence'] = df_allboth_roberta_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n",
    "df_allboth_bert_finetuned_specific['prompt'] = df_allboth_bert_finetuned_specific['context_sentence'] + ' ' + df_allboth_bert_finetuned_specific['masked_sentence']\n",
    "df_allboth_bert_multil_finetuned_specific['prompt'] = df_allboth_bert_multil_finetuned_specific['context_sentence'] + ' ' + df_allboth_bert_multil_finetuned_specific['masked_sentence']\n",
    "df_allboth_roberta_finetuned_specific['prompt'] = df_allboth_roberta_finetuned_specific['context_sentence'] + ' ' + df_allboth_roberta_finetuned_specific['masked_sentence']\n",
    "\n",
    "#Add the model names as a separate column in the dataframes\n",
    "df_allebeide_bert['model_name'] = \"bert-base-german-cased\"\n",
    "df_allebeide_bert_multil['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_allebeide_roberta['model_name'] =\"xlm-roberta-base\"\n",
    "df_allboth_bert['model_name'] = \"bert-base-cased\"\n",
    "df_allboth_bert_multil['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_allboth_roberta['model_name'] =\"xlm-roberta-base\"\n",
    "df_allboth_bert_finetuned_specific['model_name'] = \"bert-base-cased -- finetuned specific masking\"\n",
    "df_allboth_bert_multil_finetuned_specific['model_name'] =\"bert-base-multilingual-cased -- finetuned specific masking\"\n",
    "df_allboth_roberta_finetuned_specific['model_name'] =\"xlm-roberta-base -- finetuned specific masking\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ab6f3d",
   "metadata": {},
   "source": [
    "\n",
    "###### ADDITIONAL CONDITIONS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beaaebe",
   "metadata": {},
   "source": [
    "###### Definite determiner in the context sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "308ddcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/4099437934.py:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_defdet_bert['masked_sentence'] = df_defdet_bert['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/4099437934.py:46: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_defdet_bert_multil['masked_sentence'] = df_defdet_bert_multil['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/4099437934.py:47: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_defdet_roberta['masked_sentence'] = df_defdet_roberta['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/4099437934.py:52: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_defdet_bert_EN['masked_sentence'] = df_defdet_bert_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/4099437934.py:53: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_defdet_bert_multil_EN['masked_sentence'] = df_defdet_bert_multil_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/4099437934.py:54: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_defdet_roberta_EN['masked_sentence'] = df_defdet_roberta_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/4099437934.py:59: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_defdet_bert_EN_finetuned_specific['masked_sentence'] = df_defdet_bert_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/4099437934.py:60: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_defdet_bert_multil_EN_finetuned_specific['masked_sentence'] = df_defdet_bert_multil_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/4099437934.py:61: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_defdet_roberta_EN_finetuned_specific['masked_sentence'] = df_defdet_roberta_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n"
     ]
    }
   ],
   "source": [
    "### make a copy of the df\n",
    "stimuli_df_defdet = stimuli_df.copy()\n",
    "stimuli_df_defdet_EN = stimuli_df_EN.copy()\n",
    "\n",
    "#change context sentence to def-det in pre context\n",
    "context_template_defdet_EN = \"Jan's mother was shopping. She bought the {} and two {}.\" \n",
    "context_template_defdet = \"Jans Mutter war einkaufen. Sie hat die {} und zwei {} gekauft.\" \n",
    "\n",
    "#List to store the filled sentences\n",
    "filled_sentences_defdet = []\n",
    "filled_sentences_defdet_EN = []\n",
    "\n",
    "# Iterate through the DataFrame and fill the placeholders\n",
    "for index, row in stimuli_df_defdet.iterrows():\n",
    "    unique_fruit = row['unique_fruit']\n",
    "    double_fruit = row['double_fruit']\n",
    "    context_defdet = context_template_defdet.format(unique_fruit, double_fruit)\n",
    "    filled_sentences_defdet.append(context_defdet)\n",
    "    \n",
    "for index, row in stimuli_df_defdet_EN.iterrows():\n",
    "    unique_fruit = row['unique_fruit']\n",
    "    double_fruit = row['double_fruit']\n",
    "    context_defdet_EN = context_template_defdet_EN.format(unique_fruit, double_fruit)\n",
    "    filled_sentences_defdet_EN.append(context_defdet_EN)\n",
    "    \n",
    "# Now add a new column to the DataFrames with the filled sentences\n",
    "stimuli_df_defdet['context_sentence'] = filled_sentences_defdet\n",
    "stimuli_df_defdet_EN['context_sentence'] = filled_sentences_defdet_EN\n",
    "\n",
    "#### create dfs for the different models\n",
    "df_defdet_bert = stimuli_df_defdet.copy()\n",
    "df_defdet_bert_multil = stimuli_df_defdet.copy()\n",
    "df_defdet_roberta = stimuli_df_defdet.copy()\n",
    "\n",
    "df_defdet_bert_EN = stimuli_df_defdet_EN.copy()\n",
    "df_defdet_bert_multil_EN = stimuli_df_defdet_EN.copy()\n",
    "df_defdet_roberta_EN = stimuli_df_defdet_EN.copy()\n",
    "\n",
    "# dfs for the different fine-tuned models (only for English)\n",
    "df_defdet_bert_EN_finetuned_specific = stimuli_df_defdet_EN.copy()\n",
    "df_defdet_bert_multil_EN_finetuned_specific = stimuli_df_defdet_EN.copy()\n",
    "df_defdet_roberta_EN_finetuned_specific = stimuli_df_defdet_EN.copy()\n",
    "\n",
    "# add a new column to the dataframe with a MASK token for the determiners\n",
    "df_defdet_bert['masked_sentence'] = df_defdet_bert['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
    "df_defdet_bert_multil['masked_sentence'] = df_defdet_bert_multil['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
    "df_defdet_roberta['masked_sentence'] = df_defdet_roberta['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '<mask>')\n",
    "df_defdet_bert['prompt'] = df_defdet_bert['context_sentence'] + ' ' + df_defdet_bert['masked_sentence']\n",
    "df_defdet_bert_multil['prompt'] = df_defdet_bert_multil['context_sentence'] + ' ' + df_defdet_bert_multil['masked_sentence']\n",
    "df_defdet_roberta['prompt'] = df_defdet_roberta['context_sentence'] + ' ' + df_defdet_roberta['masked_sentence']\n",
    "\n",
    "df_defdet_bert_EN['masked_sentence'] = df_defdet_bert_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_defdet_bert_multil_EN['masked_sentence'] = df_defdet_bert_multil_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_defdet_roberta_EN['masked_sentence'] = df_defdet_roberta_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
    "df_defdet_bert_EN['prompt'] = df_defdet_bert_EN['context_sentence'] + ' ' + df_defdet_bert_EN['masked_sentence']\n",
    "df_defdet_bert_multil_EN['prompt'] = df_defdet_bert_multil_EN['context_sentence'] + ' ' + df_defdet_bert_multil_EN['masked_sentence']\n",
    "df_defdet_roberta_EN['prompt'] = df_defdet_roberta_EN['context_sentence'] + ' ' + df_defdet_roberta_EN['masked_sentence']\n",
    "\n",
    "df_defdet_bert_EN_finetuned_specific['masked_sentence'] = df_defdet_bert_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_defdet_bert_multil_EN_finetuned_specific['masked_sentence'] = df_defdet_bert_multil_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_defdet_roberta_EN_finetuned_specific['masked_sentence'] = df_defdet_roberta_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
    "df_defdet_bert_EN_finetuned_specific['prompt'] = df_defdet_bert_EN_finetuned_specific['context_sentence'] + ' ' + df_defdet_bert_EN_finetuned_specific['masked_sentence']\n",
    "df_defdet_bert_multil_EN_finetuned_specific['prompt'] = df_defdet_bert_multil_EN_finetuned_specific['context_sentence'] + ' ' + df_defdet_bert_multil_EN_finetuned_specific['masked_sentence']\n",
    "df_defdet_roberta_EN_finetuned_specific['prompt'] = df_defdet_roberta_EN_finetuned_specific['context_sentence'] + ' ' + df_defdet_roberta_EN_finetuned_specific['masked_sentence']\n",
    "\n",
    "#Add the model names as a separate column in the dataframes\n",
    "df_defdet_bert['model_name'] = \"bert-base-german-cased\"\n",
    "df_defdet_bert_multil['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_defdet_roberta['model_name'] =\"xlm-roberta-base\"\n",
    "df_defdet_bert_EN['model_name'] = \"bert-base-german-cased\"\n",
    "df_defdet_bert_multil_EN['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_defdet_roberta_EN['model_name'] =\"xlm-roberta-base\"\n",
    "df_defdet_bert_EN_finetuned_specific['model_name'] = \"bert-base-german-cased -- finetuned specific masking\"\n",
    "df_defdet_bert_multil_EN_finetuned_specific['model_name'] =\"bert-base-multilingual-cased -- finetuned specific masking\"\n",
    "df_defdet_roberta_EN_finetuned_specific['model_name'] =\"xlm-roberta-base -- finetuned specific masking\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044a876",
   "metadata": {},
   "source": [
    "###### Indefinite determiner in the context sentence for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f3b993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3652158259.py:31: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_indefdet_bert_EN['masked_sentence'] = df_indefdet_bert_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3652158259.py:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_indefdet_bert_multil_EN['masked_sentence'] = df_indefdet_bert_multil_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3652158259.py:33: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_indefdet_roberta_EN['masked_sentence'] = df_indefdet_roberta_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3652158259.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_indefdet_bert_EN_finetuned_specific['masked_sentence'] = df_indefdet_bert_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3652158259.py:39: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_indefdet_bert_multil_EN_finetuned_specific['masked_sentence'] = df_indefdet_bert_multil_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3652158259.py:40: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_indefdet_roberta_EN_finetuned_specific['masked_sentence'] = df_indefdet_roberta_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n"
     ]
    }
   ],
   "source": [
    "### make a copy of the df\n",
    "stimuli_df_indefdet_EN = stimuli_df_EN.copy()\n",
    "\n",
    "#change context sentence to indef-det in pre context\n",
    "context_template_indefdet_EN = \"Jan's mother was shopping. She bought a {} and two {}.\" \n",
    "\n",
    "#List to store the filled sentences\n",
    "filled_sentences_indefdet_EN = []\n",
    "\n",
    "# Iterate through the DataFrame and fill the placeholders\n",
    "for index, row in stimuli_df_indefdet_EN.iterrows():\n",
    "    unique_fruit = row['unique_fruit']\n",
    "    double_fruit = row['double_fruit']\n",
    "    context_indefdet_EN = context_template_indefdet_EN.format(unique_fruit, double_fruit)\n",
    "    filled_sentences_indefdet_EN.append(context_indefdet_EN)\n",
    "    \n",
    "# Now add a new column to the DataFrames with the filled sentences\n",
    "stimuli_df_indefdet_EN['context_sentence'] = filled_sentences_indefdet_EN\n",
    "\n",
    "#### create dfs for the different models\n",
    "df_indefdet_bert_EN = stimuli_df_indefdet_EN.copy()\n",
    "df_indefdet_bert_multil_EN = stimuli_df_indefdet_EN.copy()\n",
    "df_indefdet_roberta_EN = stimuli_df_indefdet_EN.copy()\n",
    "\n",
    "# dfs for the different fine-tuned model\n",
    "df_indefdet_bert_EN_finetuned_specific = stimuli_df_indefdet_EN.copy()\n",
    "df_indefdet_bert_multil_EN_finetuned_specific = stimuli_df_indefdet_EN.copy()\n",
    "df_indefdet_roberta_EN_finetuned_specific = stimuli_df_indefdet_EN.copy()\n",
    "\n",
    "# add a new column to the dataframe with a MASK token for the determiners\n",
    "df_indefdet_bert_EN['masked_sentence'] = df_indefdet_bert_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_indefdet_bert_multil_EN['masked_sentence'] = df_indefdet_bert_multil_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_indefdet_roberta_EN['masked_sentence'] = df_indefdet_roberta_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
    "df_indefdet_bert_EN['prompt'] = df_indefdet_bert_EN['context_sentence'] + ' ' + df_indefdet_bert_EN['masked_sentence']\n",
    "df_indefdet_bert_multil_EN['prompt'] = df_indefdet_bert_multil_EN['context_sentence'] + ' ' + df_indefdet_bert_multil_EN['masked_sentence']\n",
    "df_indefdet_roberta_EN['prompt'] = df_indefdet_roberta_EN['context_sentence'] + ' ' + df_indefdet_roberta_EN['masked_sentence']\n",
    "\n",
    "df_indefdet_bert_EN_finetuned_specific['masked_sentence'] = df_indefdet_bert_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_indefdet_bert_multil_EN_finetuned_specific['masked_sentence'] = df_indefdet_bert_multil_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_indefdet_roberta_EN_finetuned_specific['masked_sentence'] = df_indefdet_roberta_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
    "df_indefdet_bert_EN_finetuned_specific['prompt'] = df_indefdet_bert_EN_finetuned_specific['context_sentence'] + ' ' + df_indefdet_bert_EN_finetuned_specific['masked_sentence']\n",
    "df_indefdet_bert_multil_EN_finetuned_specific['prompt'] = df_indefdet_bert_multil_EN_finetuned_specific['context_sentence'] + ' ' + df_indefdet_bert_multil_EN_finetuned_specific['masked_sentence']\n",
    "df_indefdet_roberta_EN_finetuned_specific['prompt'] = df_indefdet_roberta_EN_finetuned_specific['context_sentence'] + ' ' + df_indefdet_roberta_EN_finetuned_specific['masked_sentence']\n",
    "\n",
    "#Add the model names as a separate column in the dataframes\n",
    "df_indefdet_bert_EN['model_name'] = \"bert-base-german-cased\"\n",
    "df_indefdet_bert_multil_EN['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_indefdet_roberta_EN['model_name'] =\"xlm-roberta-base\"\n",
    "df_indefdet_bert_EN_finetuned_specific['model_name'] = \"bert-base-german-cased -- finetuned specific masking\"\n",
    "df_indefdet_bert_multil_EN_finetuned_specific['model_name'] =\"bert-base-multilingual-cased -- finetuned specific masking\"\n",
    "df_indefdet_roberta_EN_finetuned_specific['model_name'] =\"xlm-roberta-base -- finetuned specific masking\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6967449",
   "metadata": {},
   "source": [
    "###### \"both\" in the context sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a9038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1326199365.py:25: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allebeide_beidepre_bert['masked_sentence'] = df_allebeide_beidepre_bert['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1326199365.py:26: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allebeide_beidepre_bert_multil['masked_sentence'] = df_allebeide_beidepre_bert_multil['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1326199365.py:27: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allebeide_beidepre_roberta['masked_sentence'] = df_allebeide_beidepre_roberta['stimulus_sentence'].str.replace(r'\\bbeide\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1326199365.py:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_bothpre_bert['masked_sentence'] = df_allboth_bothpre_bert['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1326199365.py:33: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_bothpre_bert_multil['masked_sentence'] = df_allboth_bothpre_bert_multil['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1326199365.py:34: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_bothpre_roberta['masked_sentence'] = df_allboth_bothpre_roberta['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1326199365.py:39: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_bothpre_bert_finetuned_specific['masked_sentence'] = df_allboth_bothpre_bert_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1326199365.py:40: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_bothpre_bert_multil_finetuned_specific['masked_sentence'] = df_allboth_bothpre_bert_multil_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1326199365.py:41: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_bothpre_roberta_finetuned_specific['masked_sentence'] = df_allboth_bothpre_roberta_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n"
     ]
    }
   ],
   "source": [
    "### make a copy of the df\n",
    "stimuli_df_allebeide_beidepre = stimuli_df_allebeide.copy()\n",
    "stimuli_df_allboth_bothpre = stimuli_df_allboth.copy()\n",
    "\n",
    "# Replace \"zwei\" with \"beide\" in the \"context_sentence\" column\n",
    "stimuli_df_allebeide_beidepre['context_sentence'] = stimuli_df_allebeide_beidepre['context_sentence'].replace('zwei', 'beide', regex=True)\n",
    "# Replace \"two\" with \"both\" in the \"context_sentence\" column of the English data\n",
    "stimuli_df_allboth_bothpre['context_sentence'] = stimuli_df_allboth_bothpre['context_sentence'].replace('two', 'both', regex=True)\n",
    "\n",
    "#### create dfs for the different models\n",
    "df_allebeide_beidepre_bert = stimuli_df_allebeide_beidepre.copy()\n",
    "df_allebeide_beidepre_bert_multil = stimuli_df_allebeide_beidepre.copy()\n",
    "df_allebeide_beidepre_roberta = stimuli_df_allebeide_beidepre.copy()\n",
    " \n",
    "df_allboth_bothpre_bert = stimuli_df_allboth_bothpre.copy()\n",
    "df_allboth_bothpre_bert_multil = stimuli_df_allboth_bothpre.copy()\n",
    "df_allboth_bothpre_roberta = stimuli_df_allboth_bothpre.copy()\n",
    "\n",
    "# dfs for the different fine-tuned models (only for English)\n",
    "df_allboth_bothpre_bert_finetuned_specific = stimuli_df_allboth_bothpre.copy()\n",
    "df_allboth_bothpre_bert_multil_finetuned_specific = stimuli_df_allboth_bothpre.copy()\n",
    "df_allboth_bothpre_roberta_finetuned_specific = stimuli_df_allboth_bothpre.copy()\n",
    "\n",
    "# add a new column to the dataframe with a MASK token for the determiners\n",
    "df_allebeide_beidepre_bert['masked_sentence'] = df_allebeide_beidepre_bert['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
    "df_allebeide_beidepre_bert_multil['masked_sentence'] = df_allebeide_beidepre_bert_multil['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
    "df_allebeide_beidepre_roberta['masked_sentence'] = df_allebeide_beidepre_roberta['stimulus_sentence'].str.replace(r'\\bbeide\\b', '<mask>')\n",
    "df_allebeide_beidepre_bert['prompt'] = df_allebeide_beidepre_bert['context_sentence'] + ' ' + df_allebeide_beidepre_bert['masked_sentence']\n",
    "df_allebeide_beidepre_bert_multil['prompt'] = df_allebeide_beidepre_bert_multil['context_sentence'] + ' ' + df_allebeide_beidepre_bert_multil['masked_sentence']\n",
    "df_allebeide_beidepre_roberta['prompt'] = df_allebeide_beidepre_roberta['context_sentence'] + ' ' + df_allebeide_beidepre_roberta['masked_sentence']\n",
    "\n",
    "df_allboth_bothpre_bert['masked_sentence'] = df_allboth_bothpre_bert['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_bothpre_bert_multil['masked_sentence'] = df_allboth_bothpre_bert_multil['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_bothpre_roberta['masked_sentence'] = df_allboth_bothpre_roberta['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n",
    "df_allboth_bothpre_bert['prompt'] = df_allboth_bothpre_bert['context_sentence'] + ' ' + df_allboth_bothpre_bert['masked_sentence']\n",
    "df_allboth_bothpre_bert_multil['prompt'] = df_allboth_bothpre_bert_multil['context_sentence'] + ' ' + df_allboth_bothpre_bert_multil['masked_sentence']\n",
    "df_allboth_bothpre_roberta['prompt'] = df_allboth_bothpre_roberta['context_sentence'] + ' ' + df_allboth_bothpre_roberta['masked_sentence']\n",
    "\n",
    "df_allboth_bothpre_bert_finetuned_specific['masked_sentence'] = df_allboth_bothpre_bert_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_bothpre_bert_multil_finetuned_specific['masked_sentence'] = df_allboth_bothpre_bert_multil_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_bothpre_roberta_finetuned_specific['masked_sentence'] = df_allboth_bothpre_roberta_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n",
    "df_allboth_bothpre_bert_finetuned_specific['prompt'] = df_allboth_bothpre_bert_finetuned_specific['context_sentence'] + ' ' + df_allboth_bothpre_bert_finetuned_specific['masked_sentence']\n",
    "df_allboth_bothpre_bert_multil_finetuned_specific['prompt'] = df_allboth_bothpre_bert_multil_finetuned_specific['context_sentence'] + ' ' + df_allboth_bothpre_bert_multil_finetuned_specific['masked_sentence']\n",
    "df_allboth_bothpre_roberta_finetuned_specific['prompt'] = df_allboth_bothpre_roberta_finetuned_specific['context_sentence'] + ' ' + df_allboth_bothpre_roberta_finetuned_specific['masked_sentence']\n",
    "\n",
    "#Add the model names as a separate column in the dataframes\n",
    "df_allebeide_beidepre_bert['model_name'] = \"bert-base-german-cased\"\n",
    "df_allebeide_beidepre_bert_multil['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_allebeide_beidepre_roberta['model_name'] =\"xlm-roberta-base\"\n",
    "df_allboth_bothpre_bert['model_name'] = \"bert-base-cased\"\n",
    "df_allboth_bothpre_bert_multil['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_allboth_bothpre_roberta['model_name'] =\"xlm-roberta-base\"\n",
    "df_allboth_bothpre_bert_finetuned_specific['model_name'] = \"bert-base-cased -- finetuned specific masking\"\n",
    "df_allboth_bothpre_bert_multil_finetuned_specific['model_name'] =\"bert-base-multilingual-cased -- finetuned specific masking\"\n",
    "df_allboth_bothpre_roberta_finetuned_specific['model_name'] =\"xlm-roberta-base -- finetuned specific masking\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf0586",
   "metadata": {},
   "source": [
    "###### Adjectives \"einzige\"/\"single\" in the context sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd7a88b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/959169577.py:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_intervAdjectives_bert['masked_sentence'] = df_intervAdjectives_bert['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/959169577.py:46: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_intervAdjectives_bert_multil['masked_sentence'] = df_intervAdjectives_bert_multil['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/959169577.py:47: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_intervAdjectives_roberta['masked_sentence'] = df_intervAdjectives_roberta['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/959169577.py:52: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_intervAdjectives_bert_EN['masked_sentence'] = df_intervAdjectives_bert_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/959169577.py:53: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_intervAdjectives_bert_multil_EN['masked_sentence'] = df_intervAdjectives_bert_multil_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/959169577.py:54: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_intervAdjectives_roberta_EN['masked_sentence'] = df_intervAdjectives_roberta_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/959169577.py:59: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_intervAdjectives_bert_EN_finetuned_specific['masked_sentence'] = df_intervAdjectives_bert_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/959169577.py:60: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_intervAdjectives_bert_multil_EN_finetuned_specific['masked_sentence'] = df_intervAdjectives_bert_multil_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/959169577.py:61: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_intervAdjectives_roberta_EN_finetuned_specific['masked_sentence'] = df_intervAdjectives_roberta_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n"
     ]
    }
   ],
   "source": [
    "### make a copy of the df \n",
    "stimuli_df_intervAdjectives = stimuli_df.copy()\n",
    "stimuli_df_intervAdjectives_EN = stimuli_df_EN.copy()\n",
    "\n",
    "#change context sentence\n",
    "context_template_intervAdjectives= \"Jans Mutter war einkaufen. Sie hat eine einzige {} und zwei {} gekauft.\" \n",
    "context_template_intervAdjectives_EN = \"Jan's mother was shopping. She bought one single {} and two {}.\" \n",
    "\n",
    "#List to store the filled sentences\n",
    "filled_sentences_intervAdjectives = []\n",
    "filled_sentences_intervAdjectives_EN = []\n",
    "\n",
    "# Iterate through the DataFrame and fill the placeholders\n",
    "for index, row in stimuli_df_intervAdjectives.iterrows():\n",
    "    unique_fruit = row['unique_fruit']\n",
    "    double_fruit = row['double_fruit']\n",
    "    context_intervAdjectives = context_template_intervAdjectives.format(unique_fruit, double_fruit)\n",
    "    filled_sentences_intervAdjectives.append(context_intervAdjectives)\n",
    "    \n",
    "for index, row in stimuli_df_intervAdjectives_EN.iterrows():\n",
    "    unique_fruit = row['unique_fruit']\n",
    "    double_fruit = row['double_fruit']\n",
    "    context_intervAdjectives_EN = context_template_intervAdjectives_EN.format(unique_fruit, double_fruit)\n",
    "    filled_sentences_intervAdjectives_EN.append(context_intervAdjectives_EN)   \n",
    "\n",
    "# Now add a new column to the DataFrames with the filled sentences\n",
    "stimuli_df_intervAdjectives['context_sentence'] = filled_sentences_intervAdjectives\n",
    "stimuli_df_intervAdjectives_EN['context_sentence'] = filled_sentences_intervAdjectives_EN\n",
    "\n",
    "#### create dfs for the different models\n",
    "df_intervAdjectives_bert = stimuli_df_intervAdjectives.copy()\n",
    "df_intervAdjectives_bert_multil = stimuli_df_intervAdjectives.copy()\n",
    "df_intervAdjectives_roberta = stimuli_df_intervAdjectives.copy()\n",
    "\n",
    "df_intervAdjectives_bert_EN = stimuli_df_intervAdjectives_EN.copy()\n",
    "df_intervAdjectives_bert_multil_EN = stimuli_df_intervAdjectives_EN.copy()\n",
    "df_intervAdjectives_roberta_EN = stimuli_df_intervAdjectives_EN.copy()\n",
    "\n",
    "# dfs for the different fine-tuned models (only for English)\n",
    "df_intervAdjectives_bert_EN_finetuned_specific = stimuli_df_intervAdjectives_EN.copy()\n",
    "df_intervAdjectives_bert_multil_EN_finetuned_specific = stimuli_df_intervAdjectives_EN.copy()\n",
    "df_intervAdjectives_roberta_EN_finetuned_specific = stimuli_df_intervAdjectives_EN.copy()\n",
    "\n",
    "# add a new column to the dataframe with a MASK token for the determiners\n",
    "df_intervAdjectives_bert['masked_sentence'] = df_intervAdjectives_bert['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
    "df_intervAdjectives_bert_multil['masked_sentence'] = df_intervAdjectives_bert_multil['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '[MASK]')\n",
    "df_intervAdjectives_roberta['masked_sentence'] = df_intervAdjectives_roberta['stimulus_sentence'].str.replace(r'\\b(eine|die)\\b', '<mask>')\n",
    "df_intervAdjectives_bert['prompt'] = df_intervAdjectives_bert['context_sentence'] + ' ' + df_intervAdjectives_bert['masked_sentence']\n",
    "df_intervAdjectives_bert_multil['prompt'] = df_intervAdjectives_bert_multil['context_sentence'] + ' ' + df_intervAdjectives_bert_multil['masked_sentence']\n",
    "df_intervAdjectives_roberta['prompt'] = df_intervAdjectives_roberta['context_sentence'] + ' ' + df_intervAdjectives_roberta['masked_sentence']\n",
    "\n",
    "df_intervAdjectives_bert_EN['masked_sentence'] = df_intervAdjectives_bert_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_intervAdjectives_bert_multil_EN['masked_sentence'] = df_intervAdjectives_bert_multil_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_intervAdjectives_roberta_EN['masked_sentence'] = df_intervAdjectives_roberta_EN['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
    "df_intervAdjectives_bert_EN['prompt'] = df_intervAdjectives_bert_EN['context_sentence'] + ' ' + df_intervAdjectives_bert_EN['masked_sentence']\n",
    "df_intervAdjectives_bert_multil_EN['prompt'] = df_intervAdjectives_bert_multil_EN['context_sentence'] + ' ' + df_intervAdjectives_bert_multil_EN['masked_sentence']\n",
    "df_intervAdjectives_roberta_EN['prompt'] = df_intervAdjectives_roberta_EN['context_sentence'] + ' ' + df_intervAdjectives_roberta_EN['masked_sentence']\n",
    "\n",
    "df_intervAdjectives_bert_EN_finetuned_specific['masked_sentence'] = df_intervAdjectives_bert_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_intervAdjectives_bert_multil_EN_finetuned_specific['masked_sentence'] = df_intervAdjectives_bert_multil_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '[MASK]')\n",
    "df_intervAdjectives_roberta_EN_finetuned_specific['masked_sentence'] = df_intervAdjectives_roberta_EN_finetuned_specific['stimulus_sentence'].str.replace(r'\\b(a|the)\\b', '<mask>')\n",
    "df_intervAdjectives_bert_EN_finetuned_specific['prompt'] = df_intervAdjectives_bert_EN_finetuned_specific['context_sentence'] + ' ' + df_intervAdjectives_bert_EN_finetuned_specific['masked_sentence']\n",
    "df_intervAdjectives_bert_multil_EN_finetuned_specific['prompt'] = df_intervAdjectives_bert_multil_EN_finetuned_specific['context_sentence'] + ' ' + df_intervAdjectives_bert_multil_EN_finetuned_specific['masked_sentence']\n",
    "df_intervAdjectives_roberta_EN_finetuned_specific['prompt'] = df_intervAdjectives_roberta_EN_finetuned_specific['context_sentence'] + ' ' + df_intervAdjectives_roberta_EN_finetuned_specific['masked_sentence']\n",
    "\n",
    "#Add the model names as a separate column in the dataframes\n",
    "df_intervAdjectives_bert['model_name'] = \"bert-base-german-cased\"\n",
    "df_intervAdjectives_bert_multil['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_intervAdjectives_roberta['model_name'] =\"xlm-roberta-base\"\n",
    "df_intervAdjectives_bert_EN['model_name'] = \"bert-base-german-cased\"\n",
    "df_intervAdjectives_bert_multil_EN['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_intervAdjectives_roberta_EN['model_name'] =\"xlm-roberta-base\"\n",
    "df_intervAdjectives_bert_EN_finetuned_specific['model_name'] = \"bert-base-german-cased -- finetuned specific masking\"\n",
    "df_intervAdjectives_bert_multil_EN_finetuned_specific['model_name'] =\"bert-base-multilingual-cased -- finetuned specific masking\"\n",
    "df_intervAdjectives_roberta_EN_finetuned_specific['model_name'] =\"xlm-roberta-base -- finetuned specific masking\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5c54c",
   "metadata": {},
   "source": [
    "###### Extended information in the stimulus sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8d38f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1460654691.py:42: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allebeide_morecontext_bert['masked_sentence'] = df_allebeide_morecontext_bert['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1460654691.py:43: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allebeide_morecontext_bert_multil['masked_sentence'] = df_allebeide_morecontext_bert_multil['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1460654691.py:44: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allebeide_morecontext_roberta['masked_sentence'] = df_allebeide_morecontext_roberta['stimulus_sentence'].str.replace(r'\\bbeide\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1460654691.py:49: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_morecontext_bert['masked_sentence'] = df_allboth_morecontext_bert['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1460654691.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_morecontext_bert_multil['masked_sentence'] = df_allboth_morecontext_bert_multil['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1460654691.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_morecontext_roberta['masked_sentence'] = df_allboth_morecontext_roberta['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1460654691.py:56: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_morecontext_bert_finetuned_specific['masked_sentence'] = df_allboth_morecontext_bert_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1460654691.py:57: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_morecontext_bert_multil_finetuned_specific['masked_sentence'] = df_allboth_morecontext_bert_multil_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/1460654691.py:58: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_allboth_morecontext_roberta_finetuned_specific['masked_sentence'] = df_allboth_morecontext_roberta_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n"
     ]
    }
   ],
   "source": [
    "### make copies of the df \n",
    "stimuli_df_morecontext = stimuli_df.copy()\n",
    "stimuli_df_morecontext_EN = stimuli_df_EN.copy()\n",
    "\n",
    "stimuli_df_allebeide_morecontext = stimuli_df_allebeide.copy()\n",
    "stimuli_df_allboth_morecontext = stimuli_df_allboth.copy()\n",
    "\n",
    "# add the context/ change the sentences stimulus sentence column\n",
    "stimuli_df_morecontext['stimulus_sentence'] = stimuli_df_morecontext['stimulus_sentence'].replace('Davon hat Jan', 'Von den Dingen, die Jans Mutter eingekauft hat, hat Jan', regex=True)\n",
    "stimuli_df_morecontext_EN['stimulus_sentence'] = stimuli_df_morecontext_EN['stimulus_sentence'].replace(\"Of these, Jan\", \"Of the items that Jan's mother bought, Jan\", regex=True)\n",
    "\n",
    "stimuli_df_allebeide_morecontext['stimulus_sentence'] = stimuli_df_allebeide_morecontext['stimulus_sentence'].replace('Davon hat Jan', 'Von den Dingen, die Jans Mutter eingekauft hat, hat Jan', regex=True)\n",
    "stimuli_df_allboth_morecontext['stimulus_sentence'] = stimuli_df_allboth_morecontext['stimulus_sentence'].replace(\"Of these, Jan\", \"Of the items that Jan's mother bought, Jan\", regex=True)\n",
    "\n",
    "#### create dfs for the different models\n",
    "df_morecontext_bert = stimuli_df_morecontext.copy()\n",
    "df_morecontext_bert_multil = stimuli_df_morecontext.copy()\n",
    "df_morecontext_roberta = stimuli_df_morecontext.copy()\n",
    "\n",
    "df_morecontext_bert_EN = stimuli_df_morecontext_EN.copy()\n",
    "df_morecontext_bert_multil_EN = stimuli_df_morecontext_EN.copy()\n",
    "df_morecontext_roberta_EN = stimuli_df_morecontext_EN.copy()\n",
    "\n",
    "df_allebeide_morecontext_bert = stimuli_df_allebeide_morecontext.copy()\n",
    "df_allebeide_morecontext_bert_multil = stimuli_df_allebeide_morecontext.copy()\n",
    "df_allebeide_morecontext_roberta = stimuli_df_allebeide_morecontext.copy()\n",
    "\n",
    "df_allboth_morecontext_bert = stimuli_df_allboth_morecontext.copy()\n",
    "df_allboth_morecontext_bert_multil = stimuli_df_allboth_morecontext.copy()\n",
    "df_allboth_morecontext_roberta = stimuli_df_allboth_morecontext.copy()\n",
    "\n",
    "# dfs for the different fine-tuned models (only for English)\n",
    "df_morecontext_bert_EN_finetuned_specific = stimuli_df_morecontext_EN.copy()\n",
    "df_morecontext_bert_multil_EN_finetuned_specific = stimuli_df_morecontext_EN.copy()\n",
    "df_morecontext_roberta_EN_finetuned_specific = stimuli_df_morecontext_EN.copy()\n",
    "\n",
    "df_allboth_morecontext_bert_finetuned_specific = stimuli_df_allboth_morecontext.copy()\n",
    "df_allboth_morecontext_bert_multil_finetuned_specific = stimuli_df_allboth_morecontext.copy()\n",
    "df_allboth_morecontext_roberta_finetuned_specific = stimuli_df_allboth_morecontext.copy()\n",
    "\n",
    "# add a new column to the dataframe with a MASK token for the determiners\n",
    "df_allebeide_morecontext_bert['masked_sentence'] = df_allebeide_morecontext_bert['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
    "df_allebeide_morecontext_bert_multil['masked_sentence'] = df_allebeide_morecontext_bert_multil['stimulus_sentence'].str.replace(r'\\bbeide\\b', '[MASK]')\n",
    "df_allebeide_morecontext_roberta['masked_sentence'] = df_allebeide_morecontext_roberta['stimulus_sentence'].str.replace(r'\\bbeide\\b', '<mask>')\n",
    "df_allebeide_morecontext_bert['prompt'] = df_allebeide_morecontext_bert['context_sentence'] + ' ' + df_allebeide_morecontext_bert['masked_sentence']\n",
    "df_allebeide_morecontext_bert_multil['prompt'] = df_allebeide_morecontext_bert_multil['context_sentence'] + ' ' + df_allebeide_morecontext_bert_multil['masked_sentence']\n",
    "df_allebeide_morecontext_roberta['prompt'] = df_allebeide_morecontext_roberta['context_sentence'] + ' ' + df_allebeide_morecontext_roberta['masked_sentence']\n",
    "\n",
    "df_allboth_morecontext_bert['masked_sentence'] = df_allboth_morecontext_bert['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_morecontext_bert_multil['masked_sentence'] = df_allboth_morecontext_bert_multil['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_morecontext_roberta['masked_sentence'] = df_allboth_morecontext_roberta['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n",
    "df_allboth_morecontext_bert['prompt'] = df_allboth_morecontext_bert['context_sentence'] + ' ' + df_allboth_morecontext_bert['masked_sentence']\n",
    "df_allboth_morecontext_bert_multil['prompt'] = df_allboth_morecontext_bert_multil['context_sentence'] + ' ' + df_allboth_morecontext_bert_multil['masked_sentence']\n",
    "df_allboth_morecontext_roberta['prompt'] = df_allboth_morecontext_roberta['context_sentence'] + ' ' + df_allboth_morecontext_roberta['masked_sentence']\n",
    "\n",
    "df_allboth_morecontext_bert_finetuned_specific['masked_sentence'] = df_allboth_morecontext_bert_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_morecontext_bert_multil_finetuned_specific['masked_sentence'] = df_allboth_morecontext_bert_multil_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '[MASK]')\n",
    "df_allboth_morecontext_roberta_finetuned_specific['masked_sentence'] = df_allboth_morecontext_roberta_finetuned_specific['stimulus_sentence'].str.replace(r'\\bboth\\b', '<mask>')\n",
    "df_allboth_morecontext_bert_finetuned_specific['prompt'] = df_allboth_morecontext_bert_finetuned_specific['context_sentence'] + ' ' + df_allboth_morecontext_bert_finetuned_specific['masked_sentence']\n",
    "df_allboth_morecontext_bert_multil_finetuned_specific['prompt'] = df_allboth_morecontext_bert_multil_finetuned_specific['context_sentence'] + ' ' + df_allboth_morecontext_bert_multil_finetuned_specific['masked_sentence']\n",
    "df_allboth_morecontext_roberta_finetuned_specific['prompt'] = df_allboth_morecontext_roberta_finetuned_specific['context_sentence'] + ' ' + df_allboth_morecontext_roberta_finetuned_specific['masked_sentence']\n",
    "\n",
    "#Add the model names as a separate column in the dataframes\n",
    "df_allebeide_morecontext_bert['model_name'] = \"bert-base-german-cased\"\n",
    "df_allebeide_morecontext_bert_multil['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_allebeide_morecontext_roberta['model_name'] =\"xlm-roberta-base\"\n",
    "df_allboth_morecontext_bert['model_name'] = \"bert-base-cased\"\n",
    "df_allboth_morecontext_bert_multil['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_allboth_morecontext_roberta['model_name'] =\"xlm-roberta-base\"\n",
    "df_allboth_morecontext_bert_finetuned_specific['model_name'] = \"bert-base-cased -- finetuned specific masking\"\n",
    "df_allboth_morecontext_bert_multil_finetuned_specific['model_name'] =\"bert-base-multilingual-cased -- finetuned specific masking\"\n",
    "df_allboth_morecontext_roberta_finetuned_specific['model_name'] =\"xlm-roberta-base -- finetuned specific masking\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1297ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3204457240.py:48: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_morecontext_roberta[\"masked_sentence\"] = df_morecontext_roberta[\"masked_sentence\"].str.replace(\"\\[MASK\\]\", \"<mask>\")\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3204457240.py:56: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_morecontext_roberta_EN[\"masked_sentence\"] = df_morecontext_roberta_EN[\"masked_sentence\"].str.replace(\"\\[MASK\\]\", \"<mask>\")\n",
      "/var/folders/28/g5by9h753bl2jl0601v064bc0000gn/T/ipykernel_43386/3204457240.py:64: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_morecontext_roberta_EN_finetuned_specific[\"masked_sentence\"] = df_morecontext_roberta_EN_finetuned_specific[\"masked_sentence\"].str.replace(\"\\[MASK\\]\", \"<mask>\")\n"
     ]
    }
   ],
   "source": [
    "# add a new column to the dataframe with a MASK token for the determiners\n",
    "# also for the more context in prompt-condition for def/det\n",
    "# but because I have more occurences of \"die\" now, I cannot replace it that simple; I need some functions:\n",
    "\n",
    "def mask_second_die(sentence):\n",
    "    tokens = sentence.split()\n",
    "    mask_count = 0\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token == \"die\" or token == \"the\":\n",
    "            mask_count += 1\n",
    "            if mask_count == 2:  # Change the second occurrence of \"die\" to \"[MASK]\"\n",
    "                tokens[i] = \"[MASK]\"\n",
    "                break\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def mask_first_eine(sentence):\n",
    "    tokens = sentence.split()\n",
    "    mask_count = 0\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token == \"eine\" or token == \"a\":\n",
    "            mask_count += 1\n",
    "            if mask_count == 1:  # Change the second occurrence of \"die\" to \"[MASK]\"\n",
    "                tokens[i] = \"[MASK]\"\n",
    "                break\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "    \n",
    "def mask_sentence(sentence, determiner):\n",
    "    if determiner == \"DEF\":\n",
    "        return mask_second_die(sentence)\n",
    "    elif determiner == \"INDEF\":\n",
    "        return mask_first_eine(sentence)\n",
    "    else:\n",
    "        return sentence\n",
    "    \n",
    "    \n",
    "#### now apply these functions: \n",
    "# Apply the mask_sentence function to the \"masked_sentence\" column\n",
    "df_morecontext_bert[\"masked_sentence\"] = df_morecontext_bert.apply(lambda row: mask_sentence(row[\"stimulus_sentence\"], row[\"determiner\"]), axis=1)\n",
    "df_morecontext_bert_multil[\"masked_sentence\"] = df_morecontext_bert_multil.apply(lambda row: mask_sentence(row[\"stimulus_sentence\"], row[\"determiner\"]), axis=1)\n",
    "df_morecontext_roberta[\"masked_sentence\"] =df_morecontext_roberta.apply(lambda row: mask_sentence(row[\"stimulus_sentence\"], row[\"determiner\"]), axis=1)\n",
    "df_morecontext_roberta[\"masked_sentence\"] = df_morecontext_roberta[\"masked_sentence\"].str.replace(\"\\[MASK\\]\", \"<mask>\")\n",
    "df_morecontext_bert['prompt'] = df_morecontext_bert['context_sentence'] + ' ' + df_morecontext_bert['masked_sentence']\n",
    "df_morecontext_bert_multil['prompt'] = df_morecontext_bert_multil['context_sentence'] + ' ' + df_morecontext_bert_multil['masked_sentence']\n",
    "df_morecontext_roberta['prompt'] = df_morecontext_roberta['context_sentence'] + ' ' + df_morecontext_roberta['masked_sentence']\n",
    "\n",
    "df_morecontext_bert_EN[\"masked_sentence\"] = df_morecontext_bert_EN.apply(lambda row: mask_sentence(row[\"stimulus_sentence\"], row[\"determiner\"]), axis=1)\n",
    "df_morecontext_bert_multil_EN[\"masked_sentence\"] = df_morecontext_bert_multil_EN.apply(lambda row: mask_sentence(row[\"stimulus_sentence\"], row[\"determiner\"]), axis=1)\n",
    "df_morecontext_roberta_EN[\"masked_sentence\"] =df_morecontext_roberta_EN.apply(lambda row: mask_sentence(row[\"stimulus_sentence\"], row[\"determiner\"]), axis=1)\n",
    "df_morecontext_roberta_EN[\"masked_sentence\"] = df_morecontext_roberta_EN[\"masked_sentence\"].str.replace(\"\\[MASK\\]\", \"<mask>\")\n",
    "df_morecontext_bert_EN['prompt'] = df_morecontext_bert_EN['context_sentence'] + ' ' + df_morecontext_bert_EN['masked_sentence']\n",
    "df_morecontext_bert_multil_EN['prompt'] = df_morecontext_bert_multil_EN['context_sentence'] + ' ' + df_morecontext_bert_multil_EN['masked_sentence']\n",
    "df_morecontext_roberta_EN['prompt'] = df_morecontext_roberta_EN['context_sentence'] + ' ' + df_morecontext_roberta_EN['masked_sentence']\n",
    "\n",
    "df_morecontext_bert_EN_finetuned_specific[\"masked_sentence\"] = df_morecontext_bert_EN_finetuned_specific.apply(lambda row: mask_sentence(row[\"stimulus_sentence\"], row[\"determiner\"]), axis=1)\n",
    "df_morecontext_bert_multil_EN_finetuned_specific[\"masked_sentence\"] = df_morecontext_bert_multil_EN_finetuned_specific.apply(lambda row: mask_sentence(row[\"stimulus_sentence\"], row[\"determiner\"]), axis=1)\n",
    "df_morecontext_roberta_EN_finetuned_specific[\"masked_sentence\"] =df_morecontext_roberta_EN_finetuned_specific.apply(lambda row: mask_sentence(row[\"stimulus_sentence\"], row[\"determiner\"]), axis=1)\n",
    "df_morecontext_roberta_EN_finetuned_specific[\"masked_sentence\"] = df_morecontext_roberta_EN_finetuned_specific[\"masked_sentence\"].str.replace(\"\\[MASK\\]\", \"<mask>\")\n",
    "df_morecontext_bert_EN_finetuned_specific['prompt'] = df_morecontext_bert_EN_finetuned_specific['context_sentence'] + ' ' + df_morecontext_bert_EN_finetuned_specific['masked_sentence']\n",
    "df_morecontext_bert_multil_EN_finetuned_specific['prompt'] = df_morecontext_bert_multil_EN_finetuned_specific['context_sentence'] + ' ' + df_morecontext_bert_multil_EN_finetuned_specific['masked_sentence']\n",
    "df_morecontext_roberta_EN_finetuned_specific['prompt'] = df_morecontext_roberta_EN_finetuned_specific['context_sentence'] + ' ' + df_morecontext_roberta_EN_finetuned_specific['masked_sentence']\n",
    "\n",
    "#Add the model names as a separate column in the dataframes\n",
    "df_morecontext_bert['model_name'] = \"bert-base-german-cased\"\n",
    "df_morecontext_bert_multil['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_morecontext_roberta['model_name'] =\"xlm-roberta-base\"\n",
    "df_morecontext_bert_EN['model_name'] = \"bert-base-german-cased\"\n",
    "df_morecontext_bert_multil_EN['model_name'] =\"bert-base-multilingual-cased\"\n",
    "df_morecontext_roberta_EN['model_name'] =\"xlm-roberta-base\"\n",
    "df_morecontext_bert_EN_finetuned_specific['model_name'] = \"bert-base-german-cased -- finetuned specific masking\"\n",
    "df_morecontext_bert_multil_EN_finetuned_specific['model_name'] =\"bert-base-multilingual-cased -- finetuned specific masking\"\n",
    "df_morecontext_roberta_EN_finetuned_specific['model_name'] =\"xlm-roberta-base -- finetuned specific masking\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6a9868",
   "metadata": {},
   "source": [
    "###### Tests...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23c4a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### CONDITIONS #### \n",
      "\n",
      "**(Non-)uniqe fruit condition -- German** \n",
      " Jans Mutter war einkaufen. Sie hat eine Birne und zwei Bananen gekauft. Davon hat Jan eine Banane bekommen. Jans Mutter war einkaufen. Sie hat eine Birne und zwei Bananen gekauft. Davon hat Jan [MASK] Banane bekommen. \n",
      "\n",
      "**(Non-)uniqe fruit condition -- English** \n",
      " Jan's mother was shopping. She bought one pear and two bananas. Of these, Jan received a banana. \n",
      " Jan's mother was shopping. She bought one pear and two bananas. Of these, Jan received [MASK] banana. \n",
      "\n",
      "**Pair of fruits -- German** \n",
      " Jans Mutter war einkaufen. Sie hat eine Birne und zwei Bananen gekauft. Davon hat Jan beide Bananen bekommen. \n",
      " Jans Mutter war einkaufen. Sie hat eine Birne und zwei Bananen gekauft. Davon hat Jan [MASK] Bananen bekommen. \n",
      "\n",
      "**Pair of fruits -- English** \n",
      " Jan's mother was shopping. She bought one pear and two bananas. Of these, Jan received both bananas. \n",
      " Jan's mother was shopping. She bought one pear and two bananas. Of these, Jan received [MASK] bananas. \n",
      "\n",
      "----------\n",
      "**Definite determiner in the context sentence -- German** \n",
      " Jans Mutter war einkaufen. Sie hat die Birne und zwei Bananen gekauft. Davon hat Jan eine Banane bekommen. \n",
      " Jans Mutter war einkaufen. Sie hat die Birne und zwei Bananen gekauft. Davon hat Jan [MASK] Banane bekommen. \n",
      "\n",
      "**Definite determiner in the context sentence -- English** \n",
      " Jan's mother was shopping. She bought the pear and two bananas. Of these, Jan received a banana. \n",
      " Jan's mother was shopping. She bought the pear and two bananas. Of these, Jan received [MASK] banana. \n",
      "\n",
      "**Indefinite determiner in the context sentence -- English** \n",
      " Jan's mother was shopping. She bought a pear and two bananas. Of these, Jan received a banana. \n",
      " Jan's mother was shopping. She bought a pear and two bananas. Of these, Jan received [MASK] banana. \n",
      "\n",
      "**'both' in the context sentence -- German** \n",
      " Jans Mutter war einkaufen. Sie hat eine Birne und beide Bananen gekauft. Davon hat Jan beide Bananen bekommen. \n",
      " Jans Mutter war einkaufen. Sie hat eine Birne und beide Bananen gekauft. Davon hat Jan [MASK] Bananen bekommen. \n",
      "\n",
      "**'both' in the context sentence -- English** \n",
      " Jan's mother was shopping. She bought one pear and both bananas. Of these, Jan received both bananas. \n",
      " Jan's mother was shopping. She bought one pear and both bananas. Of these, Jan received [MASK] bananas. \n",
      "\n",
      "**Adjectives 'einzige' / 'single' in the context sentence -- German** \n",
      " Jans Mutter war einkaufen. Sie hat eine einzige Birne und zwei Bananen gekauft. Davon hat Jan eine Banane bekommen. \n",
      " Jans Mutter war einkaufen. Sie hat eine einzige Birne und zwei Bananen gekauft. Davon hat Jan [MASK] Banane bekommen. \n",
      "\n",
      "**Adjectives 'einzige' / 'single' in the context sentence -- English** \n",
      " Jan's mother was shopping. She bought one single pear and two bananas. Of these, Jan received a banana. \n",
      " Jan's mother was shopping. She bought one single pear and two bananas. Of these, Jan received [MASK] banana. \n",
      "\n",
      "**Extended information in the stimulus sentence ((non-)unique fruit) -- German** \n",
      " Jans Mutter war einkaufen. Sie hat eine Birne und zwei Bananen gekauft. Von den Dingen, die Jans Mutter eingekauft hat, hat Jan eine Banane bekommen. \n",
      " Jans Mutter war einkaufen. Sie hat eine Birne und zwei Bananen gekauft. Von den Dingen, die Jans Mutter eingekauft hat, hat Jan [MASK] Banane bekommen. \n",
      "\n",
      "**Extended information in the stimulus sentence ((non-)unique fruit) -- English** \n",
      " Jan's mother was shopping. She bought one pear and two bananas. Of the items that Jan's mother bought, Jan received a banana. \n",
      " Jan's mother was shopping. She bought one pear and two bananas. Of the items that Jan's mother bought, Jan received [MASK] banana. \n",
      "\n",
      "**Extended information in the stimulus sentence (pair of fruits) -- German** \n",
      " Jans Mutter war einkaufen. Sie hat eine Birne und zwei Bananen gekauft. Von den Dingen, die Jans Mutter eingekauft hat, hat Jan beide Bananen bekommen. \n",
      " Jans Mutter war einkaufen. Sie hat eine Birne und zwei Bananen gekauft. Von den Dingen, die Jans Mutter eingekauft hat, hat Jan [MASK] Bananen bekommen. \n",
      "\n",
      "**Extended information in the stimulus sentence (pair of fruits) -- English** \n",
      " Jan's mother was shopping. She bought one pear and two bananas. Of the items that Jan's mother bought, Jan received both bananas. \n",
      " Jan's mother was shopping. She bought one pear and two bananas. Of the items that Jan's mother bought, Jan received [MASK] bananas. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"#### CONDITIONS #### \\n\")\n",
    "\n",
    "print(\"**(Non-)uniqe fruit condition -- German**\",\"\\n\", \n",
    "      stimuli_df[\"context_sentence\"][3], stimuli_df[\"stimulus_sentence\"][3],\n",
    "      df_bert_multil[\"prompt\"][3], \"\\n\")\n",
    "\n",
    "print(\"**(Non-)uniqe fruit condition -- English**\",\"\\n\", \n",
    "      stimuli_df_EN[\"context_sentence\"][3], stimuli_df_EN[\"stimulus_sentence\"][3], \"\\n\", \n",
    "     df_bert_multil_EN[\"prompt\"][3], \"\\n\")\n",
    "\n",
    "print(\"**Pair of fruits -- German**\", \"\\n\", \n",
    "      stimuli_df_allebeide[\"context_sentence\"][3], stimuli_df_allebeide[\"stimulus_sentence\"][3], \"\\n\", \n",
    "      df_allebeide_bert_multil[\"prompt\"][3], \"\\n\")\n",
    "\n",
    "print(\"**Pair of fruits -- English**\", \"\\n\", \n",
    "      stimuli_df_allboth[\"context_sentence\"][3], stimuli_df_allboth[\"stimulus_sentence\"][3],\"\\n\", \n",
    "      df_allboth_bert_multil[\"prompt\"][3], \"\\n\")\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "print(\"**Definite determiner in the context sentence -- German**\", \"\\n\", \n",
    "      stimuli_df_defdet[\"context_sentence\"][3], stimuli_df_defdet[\"stimulus_sentence\"][3],\"\\n\",\n",
    "      df_defdet_bert[\"prompt\"][3], \"\\n\")\n",
    "\n",
    "print(\"**Definite determiner in the context sentence -- English**\", \"\\n\", \n",
    "      stimuli_df_defdet_EN[\"context_sentence\"][3], stimuli_df_defdet_EN[\"stimulus_sentence\"][3],\"\\n\",\n",
    "      df_defdet_bert_EN[\"prompt\"][3], \"\\n\")\n",
    "\n",
    "\n",
    "print(\"**Indefinite determiner in the context sentence -- English**\", \"\\n\",\n",
    "      stimuli_df_indefdet_EN[\"context_sentence\"][3], stimuli_df_indefdet_EN[\"stimulus_sentence\"][3],\"\\n\",\n",
    "      df_indefdet_bert_EN[\"prompt\"][3], \"\\n\")\n",
    "    \n",
    "\n",
    "print(\"**'both' in the context sentence -- German**\", \"\\n\",\n",
    "      stimuli_df_allebeide_beidepre[\"context_sentence\"][3], stimuli_df_allebeide_beidepre[\"stimulus_sentence\"][3], \"\\n\", \n",
    "      df_allebeide_beidepre_bert_multil[\"prompt\"][3], \"\\n\")\n",
    "      \n",
    "    \n",
    "print(\"**'both' in the context sentence -- English**\",\"\\n\",\n",
    "      stimuli_df_allboth_bothpre[\"context_sentence\"][3], stimuli_df_allboth_bothpre[\"stimulus_sentence\"][3], \"\\n\",\n",
    "      df_allboth_bothpre_bert_finetuned_specific[\"prompt\"][3], \"\\n\")\n",
    "\n",
    "print(\"**Adjectives 'einzige' / 'single' in the context sentence -- German**\",\"\\n\",\n",
    "      stimuli_df_intervAdjectives[\"context_sentence\"][3], stimuli_df_intervAdjectives[\"stimulus_sentence\"][3], \"\\n\",\n",
    "      df_intervAdjectives_bert_multil[\"prompt\"][3], \"\\n\")\n",
    "      \n",
    "\n",
    "print(\"**Adjectives 'einzige' / 'single' in the context sentence -- English**\", \"\\n\",\n",
    "      stimuli_df_intervAdjectives_EN[\"context_sentence\"][3], stimuli_df_intervAdjectives_EN[\"stimulus_sentence\"][3], \"\\n\",\n",
    "      df_intervAdjectives_bert_multil_EN[\"prompt\"][3], \"\\n\")\n",
    "\n",
    "print(\"**Extended information in the stimulus sentence ((non-)unique fruit) -- German**\", \"\\n\",\n",
    "      stimuli_df_morecontext[\"context_sentence\"][3], stimuli_df_morecontext[\"stimulus_sentence\"][3], \"\\n\",\n",
    "      df_morecontext_bert[\"prompt\"][3], \"\\n\")\n",
    "      \n",
    "print(\"**Extended information in the stimulus sentence ((non-)unique fruit) -- English**\", \"\\n\",\n",
    "      stimuli_df_morecontext_EN[\"context_sentence\"][3], stimuli_df_morecontext_EN[\"stimulus_sentence\"][3], \"\\n\",\n",
    "      df_morecontext_bert_multil_EN[\"prompt\"][3], \"\\n\")\n",
    "\n",
    "print(\"**Extended information in the stimulus sentence (pair of fruits) -- German**\", \"\\n\",\n",
    "      stimuli_df_allebeide_morecontext[\"context_sentence\"][3], stimuli_df_allebeide_morecontext[\"stimulus_sentence\"][3], \"\\n\",\n",
    "      df_allebeide_morecontext_bert_multil[\"prompt\"][3], \"\\n\")\n",
    "      \n",
    "print(\"**Extended information in the stimulus sentence (pair of fruits) -- English**\",\"\\n\",\n",
    "      stimuli_df_allboth_morecontext[\"context_sentence\"][3], stimuli_df_allboth_morecontext[\"stimulus_sentence\"][3], \"\\n\",\n",
    "      df_allboth_morecontext_bert_multil_finetuned_specific[\"prompt\"][3], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9871d",
   "metadata": {},
   "source": [
    "----------\n",
    "### Load models and get predictions\n",
    "\n",
    "- english BERT: https://huggingface.co/bert-base-cased #cased \n",
    "- german BERT: https://huggingface.co/bert-base-german-cased #cased \n",
    "- multilingual BERT: https://huggingface.co/bert-base-multilingual-cased #cased \n",
    "- XLM-RoBERTa: https://huggingface.co/xlm-roberta-base (multilingual version of RoBERTa) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab6ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "german_bert = pipeline(task=\"fill-mask\", model=\"bert-base-german-cased\") # german BERT base uncased  # gibt es auch cased \n",
    "english_bert = pipeline(task=\"fill-mask\", model=\"bert-base-cased\") # english BERT base uncased # gibt es auch cased \n",
    "multil_bert = pipeline(task=\"fill-mask\", model=\"bert-base-multilingual-cased\") # multilingual BERT base uncased # gibt es auch cased \n",
    "xlm_roberta = pipeline(task=\"fill-mask\", model=\"xlm-roberta-base\") #xlm RoBERTa (multilingual version of RoBERTa)\n",
    "\n",
    "#Load fine-tuned models\n",
    "# Bert\n",
    "english_bert_finetuned_specific = pipeline(task=\"fill-mask\", model=\"../models/bert-base-cased-finetuned-SuperGlue\")\n",
    "# multilingual Bert\n",
    "multil_bert_finetuned_specific = pipeline(task=\"fill-mask\", model=\"../models/bert-base-multilingual-cased-finetuned-SuperGlue\")\n",
    "# RoBerta\n",
    "xlm_roberta_finetuned_specific = pipeline(task=\"fill-mask\", model=\"../models/xlm-roberta-base-finetuned-SuperGlue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b61367d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tests... \n",
    "#print(german_bert(\"Hallo, ich wrde gerne [MASK] Bananen kaufen.\", top_k=2), \"\\n\")\n",
    "#print(english_bert(\"Hello, I would like to buy [MASK] bananas.\", top_k=2), \"\\n\")\n",
    "#print(multil_bert(\"Hallo, ich wrde gerne [MASK] Bananen kaufen.\", top_k=2), \"\\n\")\n",
    "#print(xlm_roberta(\"Hello, I would like to buy <mask> bananas.\", top_k=2))\n",
    "#print(\"BERT specific masked\",english_bert_finetuned_specific(\"Hello, I would like to buy [MASK] bananas.\", top_k=2), \"\\n\")\n",
    "#print(\"MULTI BERT specific masked\",multil_bert_finetuned_specific(\"Hello, I would like to buy [MASK] bananas.\", top_k=2), \"\\n\")\n",
    "#print(\"xlm ROBERTA specific masked\",xlm_roberta_finetuned_specific(\"Hello, I would like to buy <mask> bananas.\", top_k=2), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f73068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get the predictions for the unique fruit and non-unique fruit conditions \n",
    "\n",
    "### German\n",
    "def predict_scores(df, model):\n",
    "    \"\"\"\n",
    "    Takes the dataframe and the model as input,\n",
    "    lets the model predict words for the mask tokens\n",
    "    saves top_k tokens and the scores for the definite and the indefinite determiner in the dataframe.\n",
    "    Returns this dataframe.\n",
    "    \"\"\"\n",
    "    # Load the BERT model pipeline\n",
    "    fill_mask = model\n",
    "\n",
    "    # Function to predict MASK token and scores for a given sentence\n",
    "    def predict_mask_with_scores(sentence):\n",
    "        tokens = fill_mask(sentence, top_k=150)  # Get top 5 predicted tokens with scores\n",
    "        bert_score_def = 0\n",
    "        bert_score_indef = 0\n",
    "\n",
    "        predicted_tokens = []\n",
    "        predicted_scores = []\n",
    "        for token in tokens:\n",
    "            predicted_token = token['token_str'].lower()\n",
    "            predicted_tokens.append(predicted_token)\n",
    "            score = token['score']\n",
    "            predicted_scores.append(score)\n",
    "            if predicted_token == 'die':\n",
    "                #because sometimes models predict the same word or the others more than once, but we need the first appearance/highest score\n",
    "                if score > bert_score_def:\n",
    "                    bert_score_def = score\n",
    "            elif predicted_token == 'eine':\n",
    "                if score > bert_score_indef:\n",
    "                    bert_score_indef = score\n",
    "        return predicted_tokens, predicted_scores, bert_score_def, bert_score_indef\n",
    "\n",
    "    # Apply the function to the \"prompt\" column to get scores for \"die\" and \"eine\"\n",
    "    scores_df = df['prompt'].apply(predict_mask_with_scores)\n",
    "\n",
    "    # Split the results into separate columns\n",
    "    df[['predicted_tokens', 'predicted_scores', 'score_def', 'score_indef']] = pd.DataFrame(scores_df.tolist(), index=df.index)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "### English\n",
    "def predict_scores_EN(df, model):\n",
    "    \"\"\"\n",
    "    Takes the dataframe and the model as input,\n",
    "    lets the model predict words for the mask tokens\n",
    "    saves top_k tokens and the scores for the definite and the indefinite determiner in the dataframe.\n",
    "    Returns this dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Load the BERT model pipeline\n",
    "    fill_mask = model\n",
    "\n",
    "    # Function to predict MASK token and scores for a given sentence\n",
    "    def predict_mask_with_scores(sentence):\n",
    "        tokens = fill_mask(sentence, top_k=150)  # Get top 5 predicted tokens with scores\n",
    "        bert_score_def = 0\n",
    "        bert_score_indef = 0\n",
    "        bert_score_one = 0 \n",
    "\n",
    "        predicted_tokens = []\n",
    "        predicted_scores = []\n",
    "        for token in tokens:\n",
    "            predicted_token = token['token_str'].lower()\n",
    "            predicted_tokens.append(predicted_token)\n",
    "            score = token['score']\n",
    "            predicted_scores.append(score)\n",
    "            if predicted_token == 'the':\n",
    "                if score > bert_score_def:\n",
    "                    bert_score_def = score\n",
    "            elif predicted_token == 'a':\n",
    "                if score > bert_score_indef:\n",
    "                    bert_score_indef = score\n",
    "            elif predicted_token == 'one':\n",
    "                if score > bert_score_one:\n",
    "                    bert_score_one = score\n",
    "        return predicted_tokens, predicted_scores, bert_score_def, bert_score_indef, bert_score_one\n",
    "\n",
    "    # Apply the function to the \"prompt\" column to get scores for \"die\" and \"eine\"\n",
    "    scores_df = df['prompt'].apply(predict_mask_with_scores)\n",
    "\n",
    "    # Split the results into separate columns\n",
    "    df[['predicted_tokens', 'predicted_scores', 'score_def', 'score_indef', 'score_one']] = pd.DataFrame(scores_df.tolist(), index=df.index)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffb42b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get the predictions for the pair of fruit conditions \n",
    "\n",
    "def predict_scores_allebeide(df, model):\n",
    "    \"\"\"\n",
    "    Takes the dataframe and the model as input,\n",
    "    lets the model predict words for the mask tokens\n",
    "    saves top_k tokens and the scores for the definite and the indefinite determiner in the dataframe.\n",
    "    Returns this dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Load the BERT model pipeline\n",
    "    fill_mask = model\n",
    "\n",
    "    # Function to predict MASK token and scores for a given sentence\n",
    "    def predict_mask_with_scores_allebeide(sentence):\n",
    "        tokens = fill_mask(sentence, top_k=150)  # Get top 100 predicted tokens with scores\n",
    "        bert_score_beide = 0\n",
    "        bert_score_alle = 0\n",
    "        bert_score_zwei = 0\n",
    "        bert_score_drei = 0\n",
    "        bert_score_vier = 0 \n",
    "\n",
    "        predicted_tokens = []\n",
    "        predicted_scores = []\n",
    "        for token in tokens:\n",
    "            predicted_token = token['token_str'].lower()\n",
    "            predicted_tokens.append(predicted_token)\n",
    "            score = token['score']\n",
    "            predicted_scores.append(score)\n",
    "            if predicted_token == 'beide':\n",
    "                if score > bert_score_beide:\n",
    "                    bert_score_beide = score\n",
    "            elif predicted_token == 'alle':\n",
    "                if score > bert_score_alle:\n",
    "                    bert_score_alle = score\n",
    "            elif predicted_token == 'zwei':\n",
    "                if score > bert_score_zwei: \n",
    "                    bert_score_zwei = score\n",
    "            elif predicted_token == 'drei':\n",
    "                if score > bert_score_drei:\n",
    "                    bert_score_drei = score\n",
    "            elif predicted_token == 'vier':\n",
    "                if score > bert_score_vier: \n",
    "                    bert_score_vier = score\n",
    "                \n",
    "        return predicted_tokens, predicted_scores, bert_score_beide, bert_score_alle, bert_score_zwei, bert_score_drei, bert_score_vier\n",
    "\n",
    "    # Apply the function to the \"prompt\" column to get scores\n",
    "    scores_df = df['prompt'].apply(predict_mask_with_scores_allebeide)\n",
    "\n",
    "    # Split the results into separate columns\n",
    "    df[['predicted_tokens', 'predicted_scores', \n",
    "        'score_beide', 'score_alle',\n",
    "        'score_zwei', 'score_drei', 'score_vier']] = pd.DataFrame(scores_df.tolist(), index=df.index)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "### English\n",
    "def predict_scores_allboth(df, model):\n",
    "    \"\"\"\n",
    "    Takes the dataframe and the model as input,\n",
    "    lets the model predict words for the mask tokens\n",
    "    saves top_k tokens and the scores for the definite and the indefinite determiner in the dataframe.\n",
    "    Returns this dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Load the BERT model pipeline\n",
    "    fill_mask = model\n",
    "\n",
    "    # Function to predict MASK token and scores for a given sentence\n",
    "    def predict_mask_with_scores_allebeide(sentence):\n",
    "        tokens = fill_mask(sentence, top_k=150)  # Get top 150 predicted tokens with scores\n",
    "        bert_score_beide = 0\n",
    "        bert_score_alle = 0\n",
    "        bert_score_two = 0\n",
    "        bert_score_three = 0\n",
    "        bert_score_four = 0 \n",
    "        \n",
    "        predicted_tokens = []\n",
    "        predicted_scores = []\n",
    "        for token in tokens:\n",
    "            predicted_token = token['token_str'].lower()\n",
    "            predicted_tokens.append(predicted_token)\n",
    "            score = token['score']\n",
    "            predicted_scores.append(score)\n",
    "            if predicted_token == 'both':\n",
    "                if score > bert_score_beide:\n",
    "                    bert_score_beide = score\n",
    "            elif predicted_token == 'all':\n",
    "                if score > bert_score_alle:\n",
    "                    bert_score_alle = score\n",
    "            elif predicted_token == 'two':\n",
    "                if score > bert_score_two: \n",
    "                    bert_score_two = score\n",
    "            elif predicted_token == 'three':\n",
    "                if score > bert_score_three:\n",
    "                    bert_score_three = score\n",
    "            elif predicted_token == 'four':\n",
    "                if score > bert_score_four: \n",
    "                    bert_score_four = score\n",
    "\n",
    "        return predicted_tokens, predicted_scores, bert_score_beide, bert_score_alle, bert_score_two, bert_score_three, bert_score_four\n",
    "\n",
    "    # Apply the function to the \"prompt\" column to get scores\n",
    "    scores_df = df['prompt'].apply(predict_mask_with_scores_allebeide)\n",
    "\n",
    "    # Split the results into separate columns\n",
    "    df[['predicted_tokens', 'predicted_scores', \n",
    "        'score_both', 'score_all',\n",
    "        'score_two', 'score_three', 'score_four']] = pd.DataFrame(scores_df.tolist(), index=df.index)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bd67cb",
   "metadata": {},
   "source": [
    "##### --> apply to the \"standard\" conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52797914",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### (Non-)uniqe fruit condition\n",
    "# german BERT\n",
    "df_bert = predict_scores(df= df_bert, model=german_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_bert_multil = predict_scores(df= df_bert_multil, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_roberta = predict_scores(df=df_roberta, model=xlm_roberta)\n",
    "\n",
    "## English data \n",
    "# english base \n",
    "df_bert_EN = predict_scores_EN(df= df_bert_EN, model=english_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_bert_multil_EN = predict_scores_EN(df= df_bert_multil_EN, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_roberta_EN = predict_scores_EN(df=df_roberta_EN, model=xlm_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "442117ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### pair of fruits condition\n",
    "# german BERT\n",
    "df_allebeide_bert = predict_scores_allebeide(df= df_allebeide_bert, model=german_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_allebeide_bert_multil = predict_scores_allebeide(df= df_allebeide_bert_multil, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_allebeide_roberta = predict_scores_allebeide(df=df_allebeide_roberta, model=xlm_roberta)\n",
    "\n",
    "## English\n",
    "# english BERT\n",
    "df_allboth_bert = predict_scores_allboth(df= df_allboth_bert, model=english_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_allboth_bert_multil = predict_scores_allboth(df= df_allboth_bert_multil, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_allboth_roberta = predict_scores_allboth(df=df_allboth_roberta, model=xlm_roberta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b7bcc7",
   "metadata": {},
   "source": [
    "##### --> apply to the additional conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "833fbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Definite determiner in the context sentence condition\n",
    "# german BERT\n",
    "df_defdet_bert = predict_scores(df= df_defdet_bert, model=german_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_defdet_bert_multil = predict_scores(df= df_defdet_bert_multil, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_defdet_roberta = predict_scores(df=df_defdet_roberta, model=xlm_roberta)\n",
    "\n",
    "## English\n",
    "# english BERT\n",
    "df_defdet_bert_EN = predict_scores_EN(df= df_defdet_bert_EN, model=english_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_defdet_bert_multil_EN = predict_scores_EN(df= df_defdet_bert_multil_EN, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_defdet_roberta_EN = predict_scores_EN(df=df_defdet_roberta_EN, model=xlm_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "774b984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Indefinite determiner in the context sentence condition (only English)\n",
    "# german BERT\n",
    "df_indefdet_bert_EN = predict_scores_EN(df= df_indefdet_bert_EN, model=english_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_indefdet_bert_multil_EN = predict_scores_EN(df= df_indefdet_bert_multil_EN, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_indefdet_roberta_EN = predict_scores_EN(df=df_indefdet_roberta_EN, model=xlm_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b13546a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### \"both\" in the context sentence\n",
    "# german BERT\n",
    "df_allebeide_beidepre_bert = predict_scores_allebeide(df= df_allebeide_beidepre_bert, model=german_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_allebeide_beidepre_bert_multil= predict_scores_allebeide(df= df_allebeide_beidepre_bert_multil, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_allebeide_beidepre_roberta = predict_scores_allebeide(df=df_allebeide_beidepre_roberta, model=xlm_roberta)\n",
    "\n",
    "## English\n",
    "# english BERT\n",
    "df_allboth_bothpre_bert = predict_scores_allboth(df= df_allboth_bothpre_bert, model=english_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_allboth_bothpre_bert_multil = predict_scores_allboth(df= df_allboth_bothpre_bert_multil, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_allboth_bothpre_roberta = predict_scores_allboth(df=df_allboth_bothpre_roberta, model=xlm_roberta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2a82d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Adjectives \"einzige\"/\"single\" in the context sentence\n",
    "# german BERT\n",
    "df_intervAdjectives_bert = predict_scores(df= df_intervAdjectives_bert, model=german_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_intervAdjectives_bert_multil = predict_scores(df= df_intervAdjectives_bert_multil, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_intervAdjectives_roberta = predict_scores(df=df_intervAdjectives_roberta, model=xlm_roberta)\n",
    "\n",
    "##English\n",
    "# English BERT\n",
    "df_intervAdjectives_bert_EN = predict_scores_EN(df= df_intervAdjectives_bert_EN, model=english_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_intervAdjectives_bert_multil_EN = predict_scores_EN(df= df_intervAdjectives_bert_multil_EN, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_intervAdjectives_roberta_EN = predict_scores_EN(df=df_intervAdjectives_roberta_EN, model=xlm_roberta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a28473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Extended information in the stimulus sentence\n",
    "#### (non-)unique fruit conditions\n",
    "# german BERT\n",
    "df_morecontext_bert = predict_scores(df= df_morecontext_bert, model=german_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_morecontext_bert_multil = predict_scores(df= df_morecontext_bert_multil, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_morecontext_roberta = predict_scores(df=df_morecontext_roberta, model=xlm_roberta)\n",
    "\n",
    "## English\n",
    "# English BERT\n",
    "df_morecontext_bert_EN = predict_scores_EN(df= df_morecontext_bert_EN, model=english_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_morecontext_bert_multil_EN = predict_scores_EN(df= df_morecontext_bert_multil_EN, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_morecontext_roberta_EN = predict_scores_EN(df=df_morecontext_roberta_EN, model=xlm_roberta)\n",
    "\n",
    "#### pair of fruits condition\n",
    "# german BERT\n",
    "df_allebeide_morecontext_bert = predict_scores_allebeide(df= df_allebeide_morecontext_bert, model=german_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_allebeide_morecontext_bert_multil= predict_scores_allebeide(df= df_allebeide_morecontext_bert_multil, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_allebeide_morecontext_roberta = predict_scores_allebeide(df=df_allebeide_morecontext_roberta, model=xlm_roberta)\n",
    "\n",
    "## English\n",
    "# english BERT\n",
    "df_allboth_morecontext_bert = predict_scores_allboth(df= df_allboth_morecontext_bert, model=english_bert)\n",
    "\n",
    "# multilingual BERT\n",
    "df_allboth_morecontext_bert_multil = predict_scores_allboth(df= df_allboth_morecontext_bert_multil, model=multil_bert)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_allboth_morecontext_roberta = predict_scores_allboth(df=df_allboth_morecontext_roberta, model=xlm_roberta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6905eb",
   "metadata": {},
   "source": [
    "##### --> concatenate the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb5a53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---ALL CONDITIONS ---- concatenate the results\n",
    "all_models_results = pd.concat([df_bert, df_bert_multil, df_roberta], ignore_index=True)\n",
    "all_models_results_EN = pd.concat([df_bert_EN, df_bert_multil_EN, df_roberta_EN], ignore_index=True )\n",
    "\n",
    "all_models_results_defdet = pd.concat([df_defdet_bert, df_defdet_bert_multil, df_defdet_roberta], ignore_index=True)\n",
    "all_models_results_defdet_EN = pd.concat([df_defdet_bert_EN, df_defdet_bert_multil_EN, df_defdet_roberta_EN], ignore_index=True)\n",
    "\n",
    "all_models_results_indefdet_EN = pd.concat([df_indefdet_bert_EN, df_indefdet_bert_multil_EN, df_indefdet_roberta_EN], ignore_index=True)\n",
    "\n",
    "all_models_results_intervAdjectives = pd.concat([df_intervAdjectives_bert, df_intervAdjectives_bert_multil, df_intervAdjectives_roberta], ignore_index=True)\n",
    "all_models_results_intervAdjectives_EN = pd.concat([df_intervAdjectives_bert_EN, df_intervAdjectives_bert_multil_EN, df_intervAdjectives_roberta_EN], ignore_index=True)\n",
    "\n",
    "all_models_results_morecontext = pd.concat([df_morecontext_bert, df_morecontext_bert_multil, df_morecontext_roberta], ignore_index=True)\n",
    "all_models_results_morecontext_EN = pd.concat([df_morecontext_bert_EN, df_morecontext_bert_multil_EN, df_morecontext_roberta_EN], ignore_index=True)\n",
    "\n",
    "all_models_results_allebeide = pd.concat([df_allebeide_bert, df_allebeide_bert_multil, df_allebeide_roberta], ignore_index=True)\n",
    "all_models_results_allboth = pd.concat([df_allboth_bert, df_allboth_bert_multil, df_allboth_roberta], ignore_index=True)\n",
    "\n",
    "all_models_results_allebeide_beidepre = pd.concat([df_allebeide_beidepre_bert, df_allebeide_beidepre_bert_multil, df_allebeide_beidepre_roberta], ignore_index=True)\n",
    "all_models_results_allboth_bothpre = pd.concat([df_allboth_bothpre_bert, df_allboth_bothpre_bert_multil, df_allboth_bothpre_roberta], ignore_index=True)\n",
    "\n",
    "all_models_results_allebeide_morecontext = pd.concat([df_allebeide_morecontext_bert, df_allebeide_morecontext_bert_multil, df_allebeide_morecontext_roberta], ignore_index=True)\n",
    "all_models_results_allboth_morecontext = pd.concat([df_allboth_morecontext_bert, df_allboth_morecontext_bert_multil, df_allboth_morecontext_roberta], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1549fb0",
   "metadata": {},
   "source": [
    "##### --> now for the [[fine-tuned models]]: apply to the \"standard\" conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4842ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### (Non-)uniqe fruit condition\n",
    "# english base \n",
    "df_bert_EN_finetuned_specific = predict_scores_EN(df= df_bert_EN_finetuned_specific, model=english_bert_finetuned_specific)\n",
    "\n",
    "# multilingual BERT\n",
    "df_bert_multil_EN_finetuned_specific = predict_scores_EN(df= df_bert_multil_EN_finetuned_specific, model=multil_bert_finetuned_specific)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_roberta_EN_finetuned_specific = predict_scores_EN(df=df_roberta_EN_finetuned_specific, model=xlm_roberta_finetuned_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "900482b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### pair of fruits condition\n",
    "# english BERT\n",
    "df_allboth_bert_finetuned_specific = predict_scores_allboth(df= df_allboth_bert_finetuned_specific, model=english_bert_finetuned_specific)\n",
    "\n",
    "# multilingual BERT\n",
    "df_allboth_bert_multil_finetuned_specific = predict_scores_allboth(df= df_allboth_bert_multil_finetuned_specific, model=multil_bert_finetuned_specific)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_allboth_roberta_finetuned_specific = predict_scores_allboth(df=df_allboth_roberta_finetuned_specific, model=xlm_roberta_finetuned_specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596d429",
   "metadata": {},
   "source": [
    "##### --> now for the fine-tuned models: apply to the \"additional\" conditions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7891c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Definite determiner in the context sentence condition\n",
    "# english BERT\n",
    "df_defdet_bert_EN_finetuned_specific = predict_scores_EN(df= df_defdet_bert_EN_finetuned_specific, model=english_bert_finetuned_specific)\n",
    "\n",
    "# multilingual BERT\n",
    "df_defdet_bert_multil_EN_finetuned_specific = predict_scores_EN(df= df_defdet_bert_multil_EN_finetuned_specific, model=multil_bert_finetuned_specific)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_defdet_roberta_EN_finetuned_specific = predict_scores_EN(df=df_defdet_roberta_EN_finetuned_specific, model=xlm_roberta_finetuned_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cead6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Indefinite determiner in the context sentence condition (only English)\n",
    "# english BERT\n",
    "df_indefdet_bert_EN_finetuned_specific = predict_scores_EN(df= df_indefdet_bert_EN_finetuned_specific, model=english_bert_finetuned_specific)\n",
    "\n",
    "# multilingual BERT\n",
    "df_indefdet_bert_multil_EN_finetuned_specific = predict_scores_EN(df= df_indefdet_bert_multil_EN_finetuned_specific, model=multil_bert_finetuned_specific)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_indefdet_roberta_EN_finetuned_specific = predict_scores_EN(df=df_indefdet_roberta_EN_finetuned_specific, model=xlm_roberta_finetuned_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5906905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### \"both\" in the context sentence\n",
    "# english BERT\n",
    "df_allboth_bothpre_bert_finetuned_specific = predict_scores_allboth(df= df_allboth_bothpre_bert_finetuned_specific, model=english_bert_finetuned_specific)\n",
    "\n",
    "# multilingual BERT\n",
    "df_allboth_bothpre_bert_multil_finetuned_specific = predict_scores_allboth(df= df_allboth_bothpre_bert_multil_finetuned_specific, model=multil_bert_finetuned_specific)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_allboth_bothpre_roberta_finetuned_specific = predict_scores_allboth(df=df_allboth_bothpre_roberta_finetuned_specific, model=xlm_roberta_finetuned_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b728edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Adjectives \"einzige\"/\"single\" in the context sentence\n",
    "# English BERT\n",
    "df_intervAdjectives_bert_EN_finetuned_specific = predict_scores_EN(df= df_intervAdjectives_bert_EN_finetuned_specific, model=english_bert_finetuned_specific)\n",
    "\n",
    "# multilingual BERT\n",
    "df_intervAdjectives_bert_multil_EN_finetuned_specific = predict_scores_EN(df= df_intervAdjectives_bert_multil_EN_finetuned_specific, model=multil_bert_finetuned_specific)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_intervAdjectives_roberta_EN_finetuned_specific = predict_scores_EN(df=df_intervAdjectives_roberta_EN_finetuned_specific, model=xlm_roberta_finetuned_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa2005e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Extended information in the stimulus sentence\n",
    "#### (non-)unique fruit conditions\n",
    "# English BERT\n",
    "df_morecontext_bert_EN_finetuned_specific = predict_scores_EN(df= df_morecontext_bert_EN_finetuned_specific, model=english_bert_finetuned_specific)\n",
    "\n",
    "# multilingual BERT\n",
    "df_morecontext_bert_multil_EN_finetuned_specific = predict_scores_EN(df= df_morecontext_bert_multil_EN_finetuned_specific, model=multil_bert_finetuned_specific)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_morecontext_roberta_EN_finetuned_specific = predict_scores_EN(df=df_morecontext_roberta_EN_finetuned_specific, model=xlm_roberta_finetuned_specific)\n",
    "\n",
    "#### pair of fruits conditions\n",
    "# english BERT\n",
    "df_allboth_morecontext_bert_finetuned_specific = predict_scores_allboth(df= df_allboth_morecontext_bert_finetuned_specific, model=english_bert_finetuned_specific)\n",
    "\n",
    "# multilingual BERT\n",
    "df_allboth_morecontext_bert_multil_finetuned_specific = predict_scores_allboth(df= df_allboth_morecontext_bert_multil_finetuned_specific, model=multil_bert_finetuned_specific)\n",
    "\n",
    "# mutlilingual RoBERTa\n",
    "df_allboth_morecontext_roberta_finetuned_specific = predict_scores_allboth(df=df_allboth_morecontext_roberta_finetuned_specific, model=xlm_roberta_finetuned_specific)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7e6205",
   "metadata": {},
   "source": [
    "##### --> concatenate the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6209be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---ALL CONDITIONS ---- concatenate the results # FINETUNED SPECIFIC\n",
    "\n",
    "all_models_results_EN_finetuned_specific = pd.concat([df_bert_EN_finetuned_specific, df_bert_multil_EN_finetuned_specific, df_roberta_EN_finetuned_specific], ignore_index=True )\n",
    "\n",
    "all_models_results_allboth_finetuned_specific = pd.concat([df_allboth_bert_finetuned_specific, df_allboth_bert_multil_finetuned_specific, df_allboth_roberta_finetuned_specific], ignore_index=True)\n",
    "\n",
    "all_models_results_defdet_EN_finetuned_specific = pd.concat([df_defdet_bert_EN_finetuned_specific, df_defdet_bert_multil_EN_finetuned_specific, df_defdet_roberta_EN_finetuned_specific], ignore_index=True)\n",
    "\n",
    "all_models_results_indefdet_EN_finetuned_specific = pd.concat([df_indefdet_bert_EN_finetuned_specific, df_indefdet_bert_multil_EN_finetuned_specific, df_indefdet_roberta_EN_finetuned_specific], ignore_index=True)\n",
    "\n",
    "all_models_results_allboth_bothpre_finetuned_specific = pd.concat([df_allboth_bothpre_bert_finetuned_specific, df_allboth_bothpre_bert_multil_finetuned_specific, df_allboth_bothpre_roberta_finetuned_specific], ignore_index=True)\n",
    "\n",
    "all_models_results_intervAdjectives_EN_finetuned_specific = pd.concat([df_intervAdjectives_bert_EN_finetuned_specific, df_intervAdjectives_bert_multil_EN_finetuned_specific, df_intervAdjectives_roberta_EN_finetuned_specific], ignore_index=True)\n",
    "\n",
    "all_models_results_morecontext_EN_finetuned_specific = pd.concat([df_morecontext_bert_EN_finetuned_specific, df_morecontext_bert_multil_EN_finetuned_specific, df_morecontext_roberta_EN_finetuned_specific], ignore_index=True)\n",
    "\n",
    "all_models_results_allboth_morecontext_finetuned_specific = pd.concat([df_allboth_morecontext_bert_finetuned_specific, df_allboth_morecontext_bert_multil_finetuned_specific, df_allboth_morecontext_roberta_finetuned_specific], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6194c0",
   "metadata": {},
   "source": [
    "#### Scale the results \n",
    "\n",
    "- because the results for \"alle\" and \"beide\" are so low, we multiplicate these with 100 to make them more comparable\n",
    "- to maintain the comparability across the conditions, all the other conditions are scaled (i.e. multiplied with 100 as well)\n",
    "\n",
    "- **beware:** only apply this once to a dataframe (otherwise the scores will get too big!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04b4ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply the values in the score_columns with 100\n",
    "all_models_results['score_indef'] *= 100\n",
    "all_models_results['score_def'] *= 100\n",
    "all_models_results_EN['score_indef'] *= 100\n",
    "all_models_results_EN['score_def'] *= 100\n",
    "all_models_results_EN['score_one'] *= 100\n",
    "\n",
    "# ----\n",
    "all_models_results_allebeide['score_beide'] *= 100\n",
    "all_models_results_allebeide['score_alle'] *= 100\n",
    "all_models_results_allebeide['score_zwei'] *= 100\n",
    "all_models_results_allebeide['score_drei'] *= 100\n",
    "all_models_results_allebeide['score_vier'] *= 100\n",
    "all_models_results_allboth['score_both'] *= 100\n",
    "all_models_results_allboth['score_all'] *= 100\n",
    "all_models_results_allboth['score_two'] *= 100\n",
    "all_models_results_allboth['score_three'] *= 100\n",
    "all_models_results_allboth['score_four'] *= 100\n",
    "\n",
    "# ---- \n",
    "all_models_results_defdet['score_indef'] *= 100\n",
    "all_models_results_defdet['score_def'] *= 100\n",
    "all_models_results_defdet_EN['score_indef'] *= 100\n",
    "all_models_results_defdet_EN['score_def'] *= 100\n",
    "all_models_results_defdet_EN['score_one'] *= 100\n",
    "\n",
    "# ---- \n",
    "all_models_results_indefdet_EN['score_indef'] *= 100\n",
    "all_models_results_indefdet_EN['score_def'] *= 100\n",
    "all_models_results_indefdet_EN['score_one'] *= 100\n",
    "\n",
    "# ----\n",
    "all_models_results_allebeide_beidepre['score_beide'] *= 100\n",
    "all_models_results_allebeide_beidepre['score_alle'] *= 100\n",
    "all_models_results_allebeide_beidepre['score_zwei'] *= 100\n",
    "all_models_results_allebeide_beidepre['score_drei'] *= 100\n",
    "all_models_results_allebeide_beidepre['score_vier'] *= 100\n",
    "all_models_results_allboth_bothpre['score_both'] *= 100\n",
    "all_models_results_allboth_bothpre['score_all'] *= 100\n",
    "all_models_results_allboth_bothpre['score_two'] *= 100\n",
    "all_models_results_allboth_bothpre['score_three'] *= 100\n",
    "all_models_results_allboth_bothpre['score_four'] *= 100\n",
    "\n",
    "# ---- \n",
    "all_models_results_intervAdjectives['score_indef'] *= 100\n",
    "all_models_results_intervAdjectives['score_def'] *= 100\n",
    "all_models_results_intervAdjectives_EN['score_indef'] *= 100\n",
    "all_models_results_intervAdjectives_EN['score_def'] *= 100\n",
    "all_models_results_intervAdjectives_EN['score_one'] *= 100\n",
    "\n",
    "# ---- \n",
    "all_models_results_morecontext['score_indef'] *= 100\n",
    "all_models_results_morecontext['score_def'] *= 100\n",
    "all_models_results_morecontext_EN['score_indef'] *= 100\n",
    "all_models_results_morecontext_EN['score_def'] *= 100\n",
    "all_models_results_morecontext_EN['score_one'] *= 100\n",
    "\n",
    "# ----\n",
    "all_models_results_allebeide_morecontext['score_beide'] *= 100\n",
    "all_models_results_allebeide_morecontext['score_alle'] *= 100\n",
    "all_models_results_allebeide_morecontext['score_zwei'] *= 100\n",
    "all_models_results_allebeide_morecontext['score_drei'] *= 100\n",
    "all_models_results_allebeide_morecontext['score_vier'] *= 100\n",
    "all_models_results_allboth_morecontext['score_both'] *= 100\n",
    "all_models_results_allboth_morecontext['score_all'] *= 100\n",
    "all_models_results_allboth_morecontext['score_two'] *= 100\n",
    "all_models_results_allboth_morecontext['score_three'] *= 100\n",
    "all_models_results_allboth_morecontext['score_four'] *= 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2702bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also for the fine-tuned models: multiply the values in the score_columns with 100\n",
    "\n",
    "all_models_results_EN_finetuned_specific['score_indef'] *= 100\n",
    "all_models_results_EN_finetuned_specific['score_def'] *= 100\n",
    "all_models_results_EN_finetuned_specific['score_one'] *= 100\n",
    "\n",
    "# ----\n",
    "all_models_results_allboth_finetuned_specific['score_both'] *= 100\n",
    "all_models_results_allboth_finetuned_specific['score_all'] *= 100\n",
    "all_models_results_allboth_finetuned_specific['score_two'] *= 100\n",
    "all_models_results_allboth_finetuned_specific['score_three'] *= 100\n",
    "all_models_results_allboth_finetuned_specific['score_four'] *= 100\n",
    "\n",
    "# ---- \n",
    "all_models_results_defdet_EN_finetuned_specific['score_indef'] *= 100\n",
    "all_models_results_defdet_EN_finetuned_specific['score_def'] *= 100\n",
    "all_models_results_defdet_EN_finetuned_specific['score_one'] *= 100\n",
    "\n",
    "# ---- \n",
    "all_models_results_indefdet_EN_finetuned_specific['score_indef'] *= 100\n",
    "all_models_results_indefdet_EN_finetuned_specific['score_def'] *= 100\n",
    "all_models_results_indefdet_EN_finetuned_specific['score_one'] *= 100\n",
    "\n",
    "# ----\n",
    "all_models_results_allboth_bothpre_finetuned_specific['score_both'] *= 100\n",
    "all_models_results_allboth_bothpre_finetuned_specific['score_all'] *= 100\n",
    "all_models_results_allboth_bothpre_finetuned_specific['score_two'] *= 100\n",
    "all_models_results_allboth_bothpre_finetuned_specific['score_three'] *= 100\n",
    "all_models_results_allboth_bothpre_finetuned_specific['score_four'] *= 100\n",
    "\n",
    "# ---- \n",
    "all_models_results_intervAdjectives_EN_finetuned_specific['score_indef'] *= 100\n",
    "all_models_results_intervAdjectives_EN_finetuned_specific['score_def'] *= 100\n",
    "all_models_results_intervAdjectives_EN_finetuned_specific['score_one'] *= 100\n",
    "\n",
    "# ---- \n",
    "all_models_results_morecontext_EN_finetuned_specific['score_indef'] *= 100\n",
    "all_models_results_morecontext_EN_finetuned_specific['score_def'] *= 100\n",
    "all_models_results_morecontext_EN_finetuned_specific['score_one'] *= 100\n",
    "\n",
    "# ----\n",
    "all_models_results_allboth_morecontext_finetuned_specific['score_both'] *= 100\n",
    "all_models_results_allboth_morecontext_finetuned_specific['score_all'] *= 100\n",
    "all_models_results_allboth_morecontext_finetuned_specific['score_two'] *= 100\n",
    "all_models_results_allboth_morecontext_finetuned_specific['score_three'] *= 100\n",
    "all_models_results_allboth_morecontext_finetuned_specific['score_four'] *= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bbaea1",
   "metadata": {},
   "source": [
    "----------\n",
    "### Evaluation\n",
    "- Calculating some basic statistics with these results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "545bd9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### (non-)unique fruit conditions \n",
    "def calculate_statistics(df):\n",
    "    # Group the DataFrame by \"sentence_type\" and \"model_name\" and calculate the mean and median for each group\n",
    "    statistics_df = df.groupby([ 'model_name','sentence_type']).agg({\n",
    "        'score_def': ['mean', 'std'],\n",
    "        'score_indef': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    statistics_df.columns = ['model_name','sentence_type', \n",
    "                             'mean DEF', 'std DEF',\n",
    "                             'mean INDEF', 'std INDEF']\n",
    "    \n",
    "    # Round the numeric columns to two decimal places\n",
    "    statistics_df = statistics_df.round(2)\n",
    "    \n",
    "    return statistics_df\n",
    "\n",
    "\n",
    "### English\n",
    "def calculate_statistics_EN(df):\n",
    "    # Group the DataFrame by \"sentence_type\" and \"model_name\" and calculate the mean and median for each group\n",
    "    statistics_df = df.groupby([ 'model_name','sentence_type']).agg({\n",
    "        'score_def': ['mean', 'std'],\n",
    "        'score_indef': ['mean', 'std'],\n",
    "        'score_one': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    statistics_df.columns = ['model_name','sentence_type', \n",
    "                             'mean DEF', 'std DEF',\n",
    "                             'mean INDEF', 'std INDEF', \n",
    "                             'mean ONE', 'std ONE']\n",
    "    \n",
    "    # Round the numeric columns to two decimal places\n",
    "    statistics_df = statistics_df.round(2)\n",
    "    \n",
    "    return statistics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49cc59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### pair of fruit condition\n",
    "def calculate_statistics_allebeide(df):\n",
    "    # Group the DataFrame by \"sentence_type\" and \"model_name\" and calculate the mean and median for each group\n",
    "    statistics_df = df.groupby([ 'model_name']).agg({\n",
    "        'score_beide': ['mean', 'std'],\n",
    "        'score_alle': ['mean', 'std'],\n",
    "        'score_zwei': ['mean', 'std'],\n",
    "        'score_drei': ['mean', 'std'],\n",
    "        'score_vier': ['mean', 'std'],\n",
    "    }).reset_index()\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    statistics_df.columns = ['model_name', \n",
    "                             'mean beide', 'std beide',\n",
    "                             'mean alle', 'std alle',\n",
    "                             'mean zwei', 'std zwei',\n",
    "                             'mean drei', 'std drei',\n",
    "                             'mean vier', 'std vier']\n",
    "    \n",
    "    # Round the numeric columns to two decimal places\n",
    "    statistics_df = statistics_df.round(2) # seems not to work in combination with the style\n",
    "    \n",
    "    return statistics_df\n",
    "\n",
    "### English\n",
    "def calculate_statistics_allboth(df):\n",
    "    # Group the DataFrame by \"sentence_type\" and \"model_name\" and calculate the mean and median for each group\n",
    "    statistics_df = df.groupby([ 'model_name']).agg({\n",
    "        'score_both': ['mean', 'std'],\n",
    "        'score_all': ['mean', 'std'],\n",
    "        'score_two': ['mean', 'std'],\n",
    "        'score_three': ['mean', 'std'],\n",
    "        'score_four': ['mean', 'std'],\n",
    "    }).reset_index()\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    statistics_df.columns = ['model_name', \n",
    "                             'mean beide', 'std beide',\n",
    "                             'mean alle', 'std alle', \n",
    "                             'mean two', 'std two',\n",
    "                             'mean three', 'std three',\n",
    "                             'mean four', 'std four'\n",
    "                            ]\n",
    "    \n",
    "    # Round the numeric columns to two decimal places\n",
    "    statistics_df = statistics_df.round(2) # seems not to work in combination with the style\n",
    "\n",
    "    return statistics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6952764",
   "metadata": {},
   "source": [
    "#### --> calculate statistics for the \"standard\" conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c40acc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>8.91</td>\n",
       "      <td>3.22</td>\n",
       "      <td>69.11</td>\n",
       "      <td>19.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>8.10</td>\n",
       "      <td>2.89</td>\n",
       "      <td>67.52</td>\n",
       "      <td>22.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>19.16</td>\n",
       "      <td>5.42</td>\n",
       "      <td>64.96</td>\n",
       "      <td>8.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>7.79</td>\n",
       "      <td>4.84</td>\n",
       "      <td>28.34</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>7.18</td>\n",
       "      <td>1.58</td>\n",
       "      <td>73.28</td>\n",
       "      <td>18.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1.65</td>\n",
       "      <td>50.43</td>\n",
       "      <td>39.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name     sentence_type  mean DEF  std DEF  \\\n",
       "0        bert-base-german-cased    DEF_felicitous      8.91     3.22   \n",
       "1        bert-base-german-cased  INDEF_felicitous      8.10     2.89   \n",
       "2  bert-base-multilingual-cased    DEF_felicitous     19.16     5.42   \n",
       "3  bert-base-multilingual-cased  INDEF_felicitous      7.79     4.84   \n",
       "4              xlm-roberta-base    DEF_felicitous      7.18     1.58   \n",
       "5              xlm-roberta-base  INDEF_felicitous      2.76     1.65   \n",
       "\n",
       "   mean INDEF  std INDEF  \n",
       "0       69.11      19.41  \n",
       "1       67.52      22.29  \n",
       "2       64.96       8.43  \n",
       "3       28.34      24.99  \n",
       "4       73.28      18.32  \n",
       "5       50.43      39.37  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (non-)unique fruit conditions (--> like Schneider's data)\n",
    "calculate_statistics(df=all_models_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5730a874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "      <th>mean ONE</th>\n",
       "      <th>std ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>8.65</td>\n",
       "      <td>4.07</td>\n",
       "      <td>78.95</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10.46</td>\n",
       "      <td>5.17</td>\n",
       "      <td>78.77</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>20.78</td>\n",
       "      <td>9.65</td>\n",
       "      <td>42.65</td>\n",
       "      <td>7.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1.50</td>\n",
       "      <td>25.72</td>\n",
       "      <td>10.60</td>\n",
       "      <td>33.50</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.18</td>\n",
       "      <td>6.30</td>\n",
       "      <td>2.57</td>\n",
       "      <td>90.05</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.28</td>\n",
       "      <td>5.87</td>\n",
       "      <td>85.42</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name     sentence_type  mean DEF  std DEF  \\\n",
       "0               bert-base-cased    DEF_felicitous      1.38     0.33   \n",
       "1               bert-base-cased  INDEF_felicitous      1.46     0.45   \n",
       "2  bert-base-multilingual-cased    DEF_felicitous      5.99     0.94   \n",
       "3  bert-base-multilingual-cased  INDEF_felicitous      8.96     1.50   \n",
       "4              xlm-roberta-base    DEF_felicitous      0.46     0.18   \n",
       "5              xlm-roberta-base  INDEF_felicitous      0.64     0.32   \n",
       "\n",
       "   mean INDEF  std INDEF  mean ONE  std ONE  \n",
       "0        8.65       4.07     78.95     3.48  \n",
       "1       10.46       5.17     78.77     3.82  \n",
       "2       20.78       9.65     42.65     7.02  \n",
       "3       25.72      10.60     33.50     6.48  \n",
       "4        6.30       2.57     90.05     2.32  \n",
       "5       11.28       5.87     85.42     4.94  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-)unique fruit conditions -- English \n",
    "calculate_statistics_EN(df=all_models_results_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92a0e8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "      <th>mean ONE</th>\n",
       "      <th>std ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-cased -- finetuned specific masking</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>17.46</td>\n",
       "      <td>30.37</td>\n",
       "      <td>80.43</td>\n",
       "      <td>33.03</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-cased -- finetuned specific masking</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>15.95</td>\n",
       "      <td>29.21</td>\n",
       "      <td>81.47</td>\n",
       "      <td>33.42</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased finetuned specifi...</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>15.55</td>\n",
       "      <td>33.03</td>\n",
       "      <td>83.94</td>\n",
       "      <td>33.98</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased finetuned specifi...</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>15.01</td>\n",
       "      <td>33.85</td>\n",
       "      <td>84.66</td>\n",
       "      <td>34.44</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>4.63</td>\n",
       "      <td>11.46</td>\n",
       "      <td>94.46</td>\n",
       "      <td>13.45</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>4.41</td>\n",
       "      <td>10.81</td>\n",
       "      <td>94.69</td>\n",
       "      <td>12.96</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name     sentence_type  \\\n",
       "0      bert-base-cased -- finetuned specific masking    DEF_felicitous   \n",
       "1      bert-base-cased -- finetuned specific masking  INDEF_felicitous   \n",
       "2  bert-base-multilingual-cased finetuned specifi...    DEF_felicitous   \n",
       "3  bert-base-multilingual-cased finetuned specifi...  INDEF_felicitous   \n",
       "4     xlm-roberta-base -- finetuned specific masking    DEF_felicitous   \n",
       "5     xlm-roberta-base -- finetuned specific masking  INDEF_felicitous   \n",
       "\n",
       "   mean DEF  std DEF  mean INDEF  std INDEF  mean ONE  std ONE  \n",
       "0     17.46    30.37       80.43      33.03      1.39     1.44  \n",
       "1     15.95    29.21       81.47      33.42      1.60     2.19  \n",
       "2     15.55    33.03       83.94      33.98      0.27     0.48  \n",
       "3     15.01    33.85       84.66      34.44      0.18     0.29  \n",
       "4      4.63    11.46       94.46      13.45      0.66     1.57  \n",
       "5      4.41    10.81       94.69      12.96      0.54     1.37  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-)unique fruit conditions -- English fine-tuned\n",
    "calculate_statistics_EN(df=all_models_results_EN_finetuned_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed739f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean beide</th>\n",
       "      <th>std beide</th>\n",
       "      <th>mean alle</th>\n",
       "      <th>std alle</th>\n",
       "      <th>mean zwei</th>\n",
       "      <th>std zwei</th>\n",
       "      <th>mean drei</th>\n",
       "      <th>std drei</th>\n",
       "      <th>mean vier</th>\n",
       "      <th>std vier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>40.82</td>\n",
       "      <td>17.24</td>\n",
       "      <td>11.44</td>\n",
       "      <td>4.69</td>\n",
       "      <td>5.02</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.52</td>\n",
       "      <td>32.28</td>\n",
       "      <td>6.81</td>\n",
       "      <td>16.98</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28.89</td>\n",
       "      <td>3.97</td>\n",
       "      <td>21.39</td>\n",
       "      <td>2.02</td>\n",
       "      <td>9.15</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name  mean beide  std beide  mean alle  std alle  \\\n",
       "0        bert-base-german-cased        0.15       0.07       0.09      0.06   \n",
       "1  bert-base-multilingual-cased        0.38       0.08       0.89      0.52   \n",
       "2              xlm-roberta-base        0.20       0.03       0.18      0.05   \n",
       "\n",
       "   mean zwei  std zwei  mean drei  std drei  mean vier  std vier  \n",
       "0      40.82     17.24      11.44      4.69       5.02      2.09  \n",
       "1      32.28      6.81      16.98      2.63       2.94      0.43  \n",
       "2      28.89      3.97      21.39      2.02       9.15      1.71  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pair of fruit condition\n",
    "calculate_statistics_allebeide(df=all_models_results_allebeide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36c3d2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean beide</th>\n",
       "      <th>std beide</th>\n",
       "      <th>mean alle</th>\n",
       "      <th>std alle</th>\n",
       "      <th>mean two</th>\n",
       "      <th>std two</th>\n",
       "      <th>mean three</th>\n",
       "      <th>std three</th>\n",
       "      <th>mean four</th>\n",
       "      <th>std four</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>27.72</td>\n",
       "      <td>2.28</td>\n",
       "      <td>20.27</td>\n",
       "      <td>1.48</td>\n",
       "      <td>9.55</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6.52</td>\n",
       "      <td>1.15</td>\n",
       "      <td>8.19</td>\n",
       "      <td>1.41</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40.90</td>\n",
       "      <td>4.62</td>\n",
       "      <td>19.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>12.45</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name  mean beide  std beide  mean alle  std alle  \\\n",
       "0               bert-base-cased        0.11       0.02       0.08      0.02   \n",
       "1  bert-base-multilingual-cased        0.04       0.03       0.11      0.03   \n",
       "2              xlm-roberta-base        0.11       0.02       0.04      0.01   \n",
       "\n",
       "   mean two  std two  mean three  std three  mean four  std four  \n",
       "0     27.72     2.28       20.27       1.48       9.55      0.67  \n",
       "1      6.52     1.15        8.19       1.41       4.67      0.70  \n",
       "2     40.90     4.62       19.94       0.99      12.45      1.11  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pair of fruit condition -- English\n",
    "calculate_statistics_allboth(df=all_models_results_allboth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cb2bc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean beide</th>\n",
       "      <th>std beide</th>\n",
       "      <th>mean alle</th>\n",
       "      <th>std alle</th>\n",
       "      <th>mean two</th>\n",
       "      <th>std two</th>\n",
       "      <th>mean three</th>\n",
       "      <th>std three</th>\n",
       "      <th>mean four</th>\n",
       "      <th>std four</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-cased -- finetuned specific masking</td>\n",
       "      <td>10.78</td>\n",
       "      <td>4.61</td>\n",
       "      <td>7.33</td>\n",
       "      <td>1.96</td>\n",
       "      <td>15.88</td>\n",
       "      <td>6.10</td>\n",
       "      <td>12.24</td>\n",
       "      <td>5.21</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.55</td>\n",
       "      <td>2.41</td>\n",
       "      <td>3.87</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>12.63</td>\n",
       "      <td>7.59</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>11.28</td>\n",
       "      <td>4.29</td>\n",
       "      <td>15.75</td>\n",
       "      <td>7.17</td>\n",
       "      <td>6.78</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name  mean beide  std beide  \\\n",
       "0      bert-base-cased -- finetuned specific masking       10.78       4.61   \n",
       "1  bert-base-multilingual-cased -- finetuned spec...        3.88       1.89   \n",
       "2     xlm-roberta-base -- finetuned specific masking       12.63       7.59   \n",
       "\n",
       "   mean alle  std alle  mean two  std two  mean three  std three  mean four  \\\n",
       "0       7.33      1.96     15.88     6.10       12.24       5.21       3.61   \n",
       "1       1.90      0.83      5.55     2.41        3.87       1.70       2.73   \n",
       "2       2.10      0.91     11.28     4.29       15.75       7.17       6.78   \n",
       "\n",
       "   std four  \n",
       "0      1.45  \n",
       "1      1.14  \n",
       "2      3.33  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pair of fruit condition -- English fine-tuned\n",
    "calculate_statistics_allboth(df=all_models_results_allboth_finetuned_specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e6b2a",
   "metadata": {},
   "source": [
    "#### --> calculate statistics for the additional conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a833acf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>48.01</td>\n",
       "      <td>12.77</td>\n",
       "      <td>29.54</td>\n",
       "      <td>12.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>23.05</td>\n",
       "      <td>7.73</td>\n",
       "      <td>51.47</td>\n",
       "      <td>17.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>83.80</td>\n",
       "      <td>5.57</td>\n",
       "      <td>4.74</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>15.93</td>\n",
       "      <td>10.34</td>\n",
       "      <td>17.47</td>\n",
       "      <td>18.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>41.28</td>\n",
       "      <td>19.00</td>\n",
       "      <td>19.42</td>\n",
       "      <td>13.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>9.65</td>\n",
       "      <td>6.96</td>\n",
       "      <td>36.91</td>\n",
       "      <td>32.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name     sentence_type  mean DEF  std DEF  \\\n",
       "0        bert-base-german-cased    DEF_felicitous     48.01    12.77   \n",
       "1        bert-base-german-cased  INDEF_felicitous     23.05     7.73   \n",
       "2  bert-base-multilingual-cased    DEF_felicitous     83.80     5.57   \n",
       "3  bert-base-multilingual-cased  INDEF_felicitous     15.93    10.34   \n",
       "4              xlm-roberta-base    DEF_felicitous     41.28    19.00   \n",
       "5              xlm-roberta-base  INDEF_felicitous      9.65     6.96   \n",
       "\n",
       "   mean INDEF  std INDEF  \n",
       "0       29.54      12.30  \n",
       "1       51.47      17.77  \n",
       "2        4.74       2.27  \n",
       "3       17.47      18.16  \n",
       "4       19.42      13.56  \n",
       "5       36.91      32.71  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definite determiner in the precontext...  \n",
    "calculate_statistics(df=all_models_results_defdet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43c4b6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "      <th>mean ONE</th>\n",
       "      <th>std ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>44.48</td>\n",
       "      <td>7.94</td>\n",
       "      <td>12.97</td>\n",
       "      <td>5.85</td>\n",
       "      <td>32.88</td>\n",
       "      <td>8.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>11.74</td>\n",
       "      <td>4.56</td>\n",
       "      <td>15.05</td>\n",
       "      <td>7.56</td>\n",
       "      <td>62.41</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>82.99</td>\n",
       "      <td>4.97</td>\n",
       "      <td>9.19</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>48.05</td>\n",
       "      <td>7.79</td>\n",
       "      <td>23.65</td>\n",
       "      <td>10.27</td>\n",
       "      <td>7.66</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>20.13</td>\n",
       "      <td>7.99</td>\n",
       "      <td>11.50</td>\n",
       "      <td>4.82</td>\n",
       "      <td>63.10</td>\n",
       "      <td>8.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>12.86</td>\n",
       "      <td>7.74</td>\n",
       "      <td>13.87</td>\n",
       "      <td>6.32</td>\n",
       "      <td>69.18</td>\n",
       "      <td>10.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name     sentence_type  mean DEF  std DEF  \\\n",
       "0        bert-base-german-cased    DEF_felicitous     44.48     7.94   \n",
       "1        bert-base-german-cased  INDEF_felicitous     11.74     4.56   \n",
       "2  bert-base-multilingual-cased    DEF_felicitous     82.99     4.97   \n",
       "3  bert-base-multilingual-cased  INDEF_felicitous     48.05     7.79   \n",
       "4              xlm-roberta-base    DEF_felicitous     20.13     7.99   \n",
       "5              xlm-roberta-base  INDEF_felicitous     12.86     7.74   \n",
       "\n",
       "   mean INDEF  std INDEF  mean ONE  std ONE  \n",
       "0       12.97       5.85     32.88     8.51  \n",
       "1       15.05       7.56     62.41     7.10  \n",
       "2        9.19       4.70      0.64     0.26  \n",
       "3       23.65      10.27      7.66     2.80  \n",
       "4       11.50       4.82     63.10     8.61  \n",
       "5       13.87       6.32     69.18    10.02  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definite determiner in the precontext -- English  \n",
    "calculate_statistics_EN(df=all_models_results_defdet_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "828897aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "      <th>mean ONE</th>\n",
       "      <th>std ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased -- finetuned specific m...</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>65.84</td>\n",
       "      <td>15.36</td>\n",
       "      <td>34.01</td>\n",
       "      <td>15.37</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased -- finetuned specific m...</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>34.72</td>\n",
       "      <td>28.44</td>\n",
       "      <td>64.51</td>\n",
       "      <td>29.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>59.14</td>\n",
       "      <td>19.64</td>\n",
       "      <td>40.84</td>\n",
       "      <td>19.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>23.06</td>\n",
       "      <td>31.87</td>\n",
       "      <td>76.88</td>\n",
       "      <td>31.92</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>33.86</td>\n",
       "      <td>33.99</td>\n",
       "      <td>66.12</td>\n",
       "      <td>34.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>18.75</td>\n",
       "      <td>33.25</td>\n",
       "      <td>81.20</td>\n",
       "      <td>33.31</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name     sentence_type  \\\n",
       "0  bert-base-german-cased -- finetuned specific m...    DEF_felicitous   \n",
       "1  bert-base-german-cased -- finetuned specific m...  INDEF_felicitous   \n",
       "2  bert-base-multilingual-cased -- finetuned spec...    DEF_felicitous   \n",
       "3  bert-base-multilingual-cased -- finetuned spec...  INDEF_felicitous   \n",
       "4     xlm-roberta-base -- finetuned specific masking    DEF_felicitous   \n",
       "5     xlm-roberta-base -- finetuned specific masking  INDEF_felicitous   \n",
       "\n",
       "   mean DEF  std DEF  mean INDEF  std INDEF  mean ONE  std ONE  \n",
       "0     65.84    15.36       34.01      15.37      0.10     0.06  \n",
       "1     34.72    28.44       64.51      29.03      0.52     0.39  \n",
       "2     59.14    19.64       40.84      19.64      0.00     0.00  \n",
       "3     23.06    31.87       76.88      31.92      0.03     0.02  \n",
       "4     33.86    33.99       66.12      34.01      0.01     0.01  \n",
       "5     18.75    33.25       81.20      33.31      0.03     0.08  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definite determiner in the precontext -- English fine-tuned\n",
    "calculate_statistics_EN(df=all_models_results_defdet_EN_finetuned_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c3053ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "      <th>mean ONE</th>\n",
       "      <th>std ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.24</td>\n",
       "      <td>34.19</td>\n",
       "      <td>15.21</td>\n",
       "      <td>42.36</td>\n",
       "      <td>7.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.80</td>\n",
       "      <td>23.00</td>\n",
       "      <td>11.52</td>\n",
       "      <td>61.07</td>\n",
       "      <td>7.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>14.79</td>\n",
       "      <td>4.00</td>\n",
       "      <td>61.95</td>\n",
       "      <td>23.54</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>14.21</td>\n",
       "      <td>2.44</td>\n",
       "      <td>51.15</td>\n",
       "      <td>20.16</td>\n",
       "      <td>9.62</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.94</td>\n",
       "      <td>25.08</td>\n",
       "      <td>9.28</td>\n",
       "      <td>68.90</td>\n",
       "      <td>6.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.45</td>\n",
       "      <td>23.16</td>\n",
       "      <td>10.66</td>\n",
       "      <td>71.24</td>\n",
       "      <td>7.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name     sentence_type  mean DEF  std DEF  \\\n",
       "0        bert-base-german-cased    DEF_felicitous      5.68     1.24   \n",
       "1        bert-base-german-cased  INDEF_felicitous      2.89     0.80   \n",
       "2  bert-base-multilingual-cased    DEF_felicitous     14.79     4.00   \n",
       "3  bert-base-multilingual-cased  INDEF_felicitous     14.21     2.44   \n",
       "4              xlm-roberta-base    DEF_felicitous      2.04     0.94   \n",
       "5              xlm-roberta-base  INDEF_felicitous      1.03     0.45   \n",
       "\n",
       "   mean INDEF  std INDEF  mean ONE  std ONE  \n",
       "0       34.19      15.21     42.36     7.32  \n",
       "1       23.00      11.52     61.07     7.47  \n",
       "2       61.95      23.54      3.24     0.98  \n",
       "3       51.15      20.16      9.62     2.98  \n",
       "4       25.08       9.28     68.90     6.78  \n",
       "5       23.16      10.66     71.24     7.21  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indefinite determiner in the precontext -- English  \n",
    "calculate_statistics_EN(df=all_models_results_indefdet_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90510a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "      <th>mean ONE</th>\n",
       "      <th>std ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased -- finetuned specific m...</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>18.72</td>\n",
       "      <td>32.58</td>\n",
       "      <td>80.81</td>\n",
       "      <td>33.30</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased -- finetuned specific m...</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>16.42</td>\n",
       "      <td>31.12</td>\n",
       "      <td>82.13</td>\n",
       "      <td>33.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>16.74</td>\n",
       "      <td>34.02</td>\n",
       "      <td>83.17</td>\n",
       "      <td>34.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>15.56</td>\n",
       "      <td>34.26</td>\n",
       "      <td>84.28</td>\n",
       "      <td>34.57</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>10.08</td>\n",
       "      <td>22.61</td>\n",
       "      <td>89.69</td>\n",
       "      <td>23.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>4.43</td>\n",
       "      <td>10.89</td>\n",
       "      <td>94.88</td>\n",
       "      <td>12.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name     sentence_type  \\\n",
       "0  bert-base-german-cased -- finetuned specific m...    DEF_felicitous   \n",
       "1  bert-base-german-cased -- finetuned specific m...  INDEF_felicitous   \n",
       "2  bert-base-multilingual-cased -- finetuned spec...    DEF_felicitous   \n",
       "3  bert-base-multilingual-cased -- finetuned spec...  INDEF_felicitous   \n",
       "4     xlm-roberta-base -- finetuned specific masking    DEF_felicitous   \n",
       "5     xlm-roberta-base -- finetuned specific masking  INDEF_felicitous   \n",
       "\n",
       "   mean DEF  std DEF  mean INDEF  std INDEF  mean ONE  std ONE  \n",
       "0     18.72    32.58       80.81      33.30      0.17     0.16  \n",
       "1     16.42    31.12       82.13      33.74      0.73     1.06  \n",
       "2     16.74    34.02       83.17      34.19      0.01     0.01  \n",
       "3     15.56    34.26       84.28      34.57      0.05     0.09  \n",
       "4     10.08    22.61       89.69      23.12      0.10     0.27  \n",
       "5      4.43    10.89       94.88      12.61      0.28     0.73  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indefinite determiner in the precontext -- English fine-tuned\n",
    "calculate_statistics_EN(df=all_models_results_indefdet_EN_finetuned_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d04c4f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean beide</th>\n",
       "      <th>std beide</th>\n",
       "      <th>mean alle</th>\n",
       "      <th>std alle</th>\n",
       "      <th>mean zwei</th>\n",
       "      <th>std zwei</th>\n",
       "      <th>mean drei</th>\n",
       "      <th>std drei</th>\n",
       "      <th>mean vier</th>\n",
       "      <th>std vier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>5.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.37</td>\n",
       "      <td>33.92</td>\n",
       "      <td>14.06</td>\n",
       "      <td>7.37</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2.86</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>23.38</td>\n",
       "      <td>7.60</td>\n",
       "      <td>10.42</td>\n",
       "      <td>4.48</td>\n",
       "      <td>13.99</td>\n",
       "      <td>3.43</td>\n",
       "      <td>10.86</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.18</td>\n",
       "      <td>41.60</td>\n",
       "      <td>4.77</td>\n",
       "      <td>15.15</td>\n",
       "      <td>3.43</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name  mean beide  std beide  mean alle  std alle  \\\n",
       "0        bert-base-german-cased        5.98       3.86       0.75      0.37   \n",
       "1  bert-base-multilingual-cased       23.38       7.60      10.42      4.48   \n",
       "2              xlm-roberta-base        3.94       1.32       0.56      0.18   \n",
       "\n",
       "   mean zwei  std zwei  mean drei  std drei  mean vier  std vier  \n",
       "0      33.92     14.06       7.37      3.11       2.86      1.24  \n",
       "1      13.99      3.43      10.86      1.83       0.65      0.16  \n",
       "2      41.60      4.77      15.15      3.43       4.94      1.36  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"both\" in the context sentence\n",
    "calculate_statistics_allebeide(df=all_models_results_allebeide_beidepre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2201a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean beide</th>\n",
       "      <th>std beide</th>\n",
       "      <th>mean alle</th>\n",
       "      <th>std alle</th>\n",
       "      <th>mean two</th>\n",
       "      <th>std two</th>\n",
       "      <th>mean three</th>\n",
       "      <th>std three</th>\n",
       "      <th>mean four</th>\n",
       "      <th>std four</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>38.60</td>\n",
       "      <td>3.32</td>\n",
       "      <td>18.16</td>\n",
       "      <td>1.23</td>\n",
       "      <td>7.04</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10.82</td>\n",
       "      <td>2.32</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.37</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>55.72</td>\n",
       "      <td>5.07</td>\n",
       "      <td>17.69</td>\n",
       "      <td>1.51</td>\n",
       "      <td>8.15</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name  mean beide  std beide  mean alle  std alle  \\\n",
       "0               bert-base-cased        0.72       0.19       0.17      0.06   \n",
       "1  bert-base-multilingual-cased        0.39       0.25       0.31      0.10   \n",
       "2              xlm-roberta-base        0.73       0.15       0.09      0.01   \n",
       "\n",
       "   mean two  std two  mean three  std three  mean four  std four  \n",
       "0     38.60     3.32       18.16       1.23       7.04      0.50  \n",
       "1     10.82     2.32        9.89       1.37       5.29      0.56  \n",
       "2     55.72     5.07       17.69       1.51       8.15      1.16  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"both\" in the context sentence -- English\n",
    "calculate_statistics_allboth(df=all_models_results_allboth_bothpre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "341fa3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean beide</th>\n",
       "      <th>std beide</th>\n",
       "      <th>mean alle</th>\n",
       "      <th>std alle</th>\n",
       "      <th>mean two</th>\n",
       "      <th>std two</th>\n",
       "      <th>mean three</th>\n",
       "      <th>std three</th>\n",
       "      <th>mean four</th>\n",
       "      <th>std four</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-cased -- finetuned specific masking</td>\n",
       "      <td>33.95</td>\n",
       "      <td>9.58</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.92</td>\n",
       "      <td>14.75</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>16.66</td>\n",
       "      <td>7.55</td>\n",
       "      <td>5.78</td>\n",
       "      <td>1.99</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>34.15</td>\n",
       "      <td>14.56</td>\n",
       "      <td>2.49</td>\n",
       "      <td>1.27</td>\n",
       "      <td>7.68</td>\n",
       "      <td>3.97</td>\n",
       "      <td>6.33</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name  mean beide  std beide  \\\n",
       "0      bert-base-cased -- finetuned specific masking       33.95       9.58   \n",
       "1  bert-base-multilingual-cased -- finetuned spec...       16.66       7.55   \n",
       "2     xlm-roberta-base -- finetuned specific masking       34.15      14.56   \n",
       "\n",
       "   mean alle  std alle  mean two  std two  mean three  std three  mean four  \\\n",
       "0       8.00      2.92     14.75     5.25        5.33       1.97       1.29   \n",
       "1       5.78      1.99      4.05     1.61        2.04       0.80       1.44   \n",
       "2       2.49      1.27      7.68     3.97        6.33       4.06       1.94   \n",
       "\n",
       "   std four  \n",
       "0      0.44  \n",
       "1      0.54  \n",
       "2      1.27  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"both\" in the context sentence -- English fine-tuned\n",
    "calculate_statistics_allboth(df=all_models_results_allboth_bothpre_finetuned_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6c44b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>8.47</td>\n",
       "      <td>3.22</td>\n",
       "      <td>62.04</td>\n",
       "      <td>18.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>7.56</td>\n",
       "      <td>2.67</td>\n",
       "      <td>65.34</td>\n",
       "      <td>21.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>9.95</td>\n",
       "      <td>4.15</td>\n",
       "      <td>42.49</td>\n",
       "      <td>17.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>5.59</td>\n",
       "      <td>3.56</td>\n",
       "      <td>24.69</td>\n",
       "      <td>24.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.67</td>\n",
       "      <td>49.30</td>\n",
       "      <td>30.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.14</td>\n",
       "      <td>41.83</td>\n",
       "      <td>35.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name     sentence_type  mean DEF  std DEF  \\\n",
       "0        bert-base-german-cased    DEF_felicitous      8.47     3.22   \n",
       "1        bert-base-german-cased  INDEF_felicitous      7.56     2.67   \n",
       "2  bert-base-multilingual-cased    DEF_felicitous      9.95     4.15   \n",
       "3  bert-base-multilingual-cased  INDEF_felicitous      5.59     3.56   \n",
       "4              xlm-roberta-base    DEF_felicitous      3.30     1.67   \n",
       "5              xlm-roberta-base  INDEF_felicitous      1.79     1.14   \n",
       "\n",
       "   mean INDEF  std INDEF  \n",
       "0       62.04      18.98  \n",
       "1       65.34      21.58  \n",
       "2       42.49      17.24  \n",
       "3       24.69      24.77  \n",
       "4       49.30      30.11  \n",
       "5       41.83      35.60  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjectives \"einzige\"/\"single\" in the context sentence\n",
    "calculate_statistics(df=all_models_results_intervAdjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5282cd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "      <th>mean ONE</th>\n",
       "      <th>std ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.18</td>\n",
       "      <td>4.55</td>\n",
       "      <td>75.46</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>10.44</td>\n",
       "      <td>5.04</td>\n",
       "      <td>78.05</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>7.34</td>\n",
       "      <td>1.65</td>\n",
       "      <td>20.31</td>\n",
       "      <td>10.24</td>\n",
       "      <td>32.19</td>\n",
       "      <td>7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>9.49</td>\n",
       "      <td>1.40</td>\n",
       "      <td>26.70</td>\n",
       "      <td>11.41</td>\n",
       "      <td>28.10</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.74</td>\n",
       "      <td>2.24</td>\n",
       "      <td>90.32</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.24</td>\n",
       "      <td>9.50</td>\n",
       "      <td>4.87</td>\n",
       "      <td>87.39</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name     sentence_type  mean DEF  std DEF  \\\n",
       "0        bert-base-german-cased    DEF_felicitous      1.74     0.55   \n",
       "1        bert-base-german-cased  INDEF_felicitous      1.52     0.48   \n",
       "2  bert-base-multilingual-cased    DEF_felicitous      7.34     1.65   \n",
       "3  bert-base-multilingual-cased  INDEF_felicitous      9.49     1.40   \n",
       "4              xlm-roberta-base    DEF_felicitous      0.36     0.17   \n",
       "5              xlm-roberta-base  INDEF_felicitous      0.48     0.24   \n",
       "\n",
       "   mean INDEF  std INDEF  mean ONE  std ONE  \n",
       "0        9.18       4.55     75.46     5.06  \n",
       "1       10.44       5.04     78.05     3.85  \n",
       "2       20.31      10.24     32.19     7.71  \n",
       "3       26.70      11.41     28.10     6.10  \n",
       "4        5.74       2.24     90.32     2.02  \n",
       "5        9.50       4.87     87.39     4.02  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjectives \"einzige\"/\"single\" in the context sentence -- English\n",
    "calculate_statistics_EN(df=all_models_results_intervAdjectives_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0569a254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "      <th>mean ONE</th>\n",
       "      <th>std ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased -- finetuned specific m...</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>18.73</td>\n",
       "      <td>30.79</td>\n",
       "      <td>79.58</td>\n",
       "      <td>32.76</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased -- finetuned specific m...</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>16.26</td>\n",
       "      <td>29.23</td>\n",
       "      <td>81.22</td>\n",
       "      <td>33.32</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>15.00</td>\n",
       "      <td>31.80</td>\n",
       "      <td>84.21</td>\n",
       "      <td>33.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>14.88</td>\n",
       "      <td>33.71</td>\n",
       "      <td>84.75</td>\n",
       "      <td>34.35</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>3.91</td>\n",
       "      <td>9.64</td>\n",
       "      <td>94.59</td>\n",
       "      <td>12.99</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>3.24</td>\n",
       "      <td>7.94</td>\n",
       "      <td>95.54</td>\n",
       "      <td>10.88</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name     sentence_type  \\\n",
       "0  bert-base-german-cased -- finetuned specific m...    DEF_felicitous   \n",
       "1  bert-base-german-cased -- finetuned specific m...  INDEF_felicitous   \n",
       "2  bert-base-multilingual-cased -- finetuned spec...    DEF_felicitous   \n",
       "3  bert-base-multilingual-cased -- finetuned spec...  INDEF_felicitous   \n",
       "4     xlm-roberta-base -- finetuned specific masking    DEF_felicitous   \n",
       "5     xlm-roberta-base -- finetuned specific masking  INDEF_felicitous   \n",
       "\n",
       "   mean DEF  std DEF  mean INDEF  std INDEF  mean ONE  std ONE  \n",
       "0     18.73    30.79       79.58      32.76      1.06     1.01  \n",
       "1     16.26    29.23       81.22      33.32      1.60     2.23  \n",
       "2     15.00    31.80       84.21      33.24      0.35     0.61  \n",
       "3     14.88    33.71       84.75      34.35      0.20     0.29  \n",
       "4      3.91     9.64       94.59      12.99      1.10     2.66  \n",
       "5      3.24     7.94       95.54      10.88      0.81     1.99  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjectives \"einzige\"/\"single\" in the context sentence -- English fine-tuned\n",
    "calculate_statistics_EN(df=all_models_results_intervAdjectives_EN_finetuned_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21adf1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>7.61</td>\n",
       "      <td>3.03</td>\n",
       "      <td>57.68</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>7.25</td>\n",
       "      <td>2.66</td>\n",
       "      <td>56.33</td>\n",
       "      <td>20.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>14.76</td>\n",
       "      <td>3.80</td>\n",
       "      <td>65.44</td>\n",
       "      <td>9.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>4.67</td>\n",
       "      <td>2.96</td>\n",
       "      <td>29.82</td>\n",
       "      <td>27.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.42</td>\n",
       "      <td>60.91</td>\n",
       "      <td>10.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.34</td>\n",
       "      <td>38.63</td>\n",
       "      <td>32.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name     sentence_type  mean DEF  std DEF  \\\n",
       "0        bert-base-german-cased    DEF_felicitous      7.61     3.03   \n",
       "1        bert-base-german-cased  INDEF_felicitous      7.25     2.66   \n",
       "2  bert-base-multilingual-cased    DEF_felicitous     14.76     3.80   \n",
       "3  bert-base-multilingual-cased  INDEF_felicitous      4.67     2.96   \n",
       "4              xlm-roberta-base    DEF_felicitous      1.91     0.42   \n",
       "5              xlm-roberta-base  INDEF_felicitous      0.73     0.34   \n",
       "\n",
       "   mean INDEF  std INDEF  \n",
       "0       57.68      20.25  \n",
       "1       56.33      20.56  \n",
       "2       65.44       9.61  \n",
       "3       29.82      27.20  \n",
       "4       60.91      10.18  \n",
       "5       38.63      32.34  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extended information in the stimulus sentence -- (non-)uniquefruit condition\n",
    "calculate_statistics(df=all_models_results_morecontext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d45037db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "      <th>mean ONE</th>\n",
       "      <th>std ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.43</td>\n",
       "      <td>7.05</td>\n",
       "      <td>3.43</td>\n",
       "      <td>79.67</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.25</td>\n",
       "      <td>4.20</td>\n",
       "      <td>80.11</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.39</td>\n",
       "      <td>17.01</td>\n",
       "      <td>7.61</td>\n",
       "      <td>68.75</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>3.78</td>\n",
       "      <td>1.26</td>\n",
       "      <td>29.35</td>\n",
       "      <td>13.12</td>\n",
       "      <td>50.84</td>\n",
       "      <td>7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.48</td>\n",
       "      <td>10.32</td>\n",
       "      <td>4.34</td>\n",
       "      <td>85.02</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.36</td>\n",
       "      <td>15.09</td>\n",
       "      <td>6.43</td>\n",
       "      <td>80.75</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name     sentence_type  mean DEF  std DEF  \\\n",
       "0        bert-base-german-cased    DEF_felicitous      1.82     0.43   \n",
       "1        bert-base-german-cased  INDEF_felicitous      1.94     0.54   \n",
       "2  bert-base-multilingual-cased    DEF_felicitous      2.44     0.39   \n",
       "3  bert-base-multilingual-cased  INDEF_felicitous      3.78     1.26   \n",
       "4              xlm-roberta-base    DEF_felicitous      0.86     0.48   \n",
       "5              xlm-roberta-base  INDEF_felicitous      0.85     0.36   \n",
       "\n",
       "   mean INDEF  std INDEF  mean ONE  std ONE  \n",
       "0        7.05       3.43     79.67     2.96  \n",
       "1        8.25       4.20     80.11     3.11  \n",
       "2       17.01       7.61     68.75     5.52  \n",
       "3       29.35      13.12     50.84     7.71  \n",
       "4       10.32       4.34     85.02     4.12  \n",
       "5       15.09       6.43     80.75     5.47  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extended information in the stimulus sentence -- (non-)uniquefruit condition -- English\n",
    "calculate_statistics_EN(df=all_models_results_morecontext_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66012d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>mean DEF</th>\n",
       "      <th>std DEF</th>\n",
       "      <th>mean INDEF</th>\n",
       "      <th>std INDEF</th>\n",
       "      <th>mean ONE</th>\n",
       "      <th>std ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased -- finetuned specific m...</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>24.70</td>\n",
       "      <td>29.13</td>\n",
       "      <td>73.40</td>\n",
       "      <td>30.54</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-german-cased -- finetuned specific m...</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>23.32</td>\n",
       "      <td>29.29</td>\n",
       "      <td>74.69</td>\n",
       "      <td>31.15</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>13.59</td>\n",
       "      <td>32.12</td>\n",
       "      <td>85.78</td>\n",
       "      <td>33.58</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>13.71</td>\n",
       "      <td>32.83</td>\n",
       "      <td>85.84</td>\n",
       "      <td>33.91</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>DEF_felicitous</td>\n",
       "      <td>7.93</td>\n",
       "      <td>18.90</td>\n",
       "      <td>91.50</td>\n",
       "      <td>20.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>INDEF_felicitous</td>\n",
       "      <td>5.06</td>\n",
       "      <td>12.38</td>\n",
       "      <td>94.14</td>\n",
       "      <td>14.33</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name     sentence_type  \\\n",
       "0  bert-base-german-cased -- finetuned specific m...    DEF_felicitous   \n",
       "1  bert-base-german-cased -- finetuned specific m...  INDEF_felicitous   \n",
       "2  bert-base-multilingual-cased -- finetuned spec...    DEF_felicitous   \n",
       "3  bert-base-multilingual-cased -- finetuned spec...  INDEF_felicitous   \n",
       "4     xlm-roberta-base -- finetuned specific masking    DEF_felicitous   \n",
       "5     xlm-roberta-base -- finetuned specific masking  INDEF_felicitous   \n",
       "\n",
       "   mean DEF  std DEF  mean INDEF  std INDEF  mean ONE  std ONE  \n",
       "0     24.70    29.13       73.40      30.54      1.39     0.89  \n",
       "1     23.32    29.29       74.69      31.15      1.48     1.22  \n",
       "2     13.59    32.12       85.78      33.58      0.31     0.70  \n",
       "3     13.71    32.83       85.84      33.91      0.17     0.39  \n",
       "4      7.93    18.90       91.50      20.26      0.32     0.77  \n",
       "5      5.06    12.38       94.14      14.33      0.41     1.01  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extended information in the stimulus sentence -- (non-)uniquefruit condition -- English fine-tuned\n",
    "calculate_statistics_EN(df=all_models_results_morecontext_EN_finetuned_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25327149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean beide</th>\n",
       "      <th>std beide</th>\n",
       "      <th>mean alle</th>\n",
       "      <th>std alle</th>\n",
       "      <th>mean zwei</th>\n",
       "      <th>std zwei</th>\n",
       "      <th>mean drei</th>\n",
       "      <th>std drei</th>\n",
       "      <th>mean vier</th>\n",
       "      <th>std vier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12.76</td>\n",
       "      <td>6.93</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.65</td>\n",
       "      <td>41.81</td>\n",
       "      <td>7.73</td>\n",
       "      <td>14.04</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>33.80</td>\n",
       "      <td>3.10</td>\n",
       "      <td>17.52</td>\n",
       "      <td>1.15</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name  mean beide  std beide  mean alle  std alle  \\\n",
       "0        bert-base-german-cased        0.14       0.07       0.18      0.10   \n",
       "1  bert-base-multilingual-cased        0.37       0.11       1.10      0.65   \n",
       "2              xlm-roberta-base        0.13       0.03       0.11      0.02   \n",
       "\n",
       "   mean zwei  std zwei  mean drei  std drei  mean vier  std vier  \n",
       "0      12.76      6.93       4.30      2.15       1.37      0.73  \n",
       "1      41.81      7.73      14.04      2.06       2.20      0.47  \n",
       "2      33.80      3.10      17.52      1.15       8.62      1.46  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extended information in the stimulus sentence -- pair of fruit condition -- English\n",
    "calculate_statistics_allebeide(df=all_models_results_allebeide_morecontext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fc9a8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean beide</th>\n",
       "      <th>std beide</th>\n",
       "      <th>mean alle</th>\n",
       "      <th>std alle</th>\n",
       "      <th>mean two</th>\n",
       "      <th>std two</th>\n",
       "      <th>mean three</th>\n",
       "      <th>std three</th>\n",
       "      <th>mean four</th>\n",
       "      <th>std four</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.76</td>\n",
       "      <td>2.34</td>\n",
       "      <td>18.59</td>\n",
       "      <td>1.04</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>34.21</td>\n",
       "      <td>3.65</td>\n",
       "      <td>18.36</td>\n",
       "      <td>1.37</td>\n",
       "      <td>7.09</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40.70</td>\n",
       "      <td>3.94</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.21</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name  mean beide  std beide  mean alle  std alle  \\\n",
       "0               bert-base-cased        0.10       0.02       0.18      0.05   \n",
       "1  bert-base-multilingual-cased        0.11       0.02       0.05      0.01   \n",
       "2              xlm-roberta-base        0.17       0.04       0.10      0.01   \n",
       "\n",
       "   mean two  std two  mean three  std three  mean four  std four  \n",
       "0     21.76     2.34       18.59       1.04       9.26      0.59  \n",
       "1     34.21     3.65       18.36       1.37       7.09      0.40  \n",
       "2     40.70     3.94       19.87       0.75      10.21      0.95  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extended information in the stimulus sentence -- pair of fruit condition -- English\n",
    "calculate_statistics_allboth(df=all_models_results_allboth_morecontext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4878615c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean beide</th>\n",
       "      <th>std beide</th>\n",
       "      <th>mean alle</th>\n",
       "      <th>std alle</th>\n",
       "      <th>mean two</th>\n",
       "      <th>std two</th>\n",
       "      <th>mean three</th>\n",
       "      <th>std three</th>\n",
       "      <th>mean four</th>\n",
       "      <th>std four</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-cased -- finetuned specific masking</td>\n",
       "      <td>7.91</td>\n",
       "      <td>2.75</td>\n",
       "      <td>16.89</td>\n",
       "      <td>2.42</td>\n",
       "      <td>8.47</td>\n",
       "      <td>3.55</td>\n",
       "      <td>9.43</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>14.46</td>\n",
       "      <td>7.77</td>\n",
       "      <td>6.33</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name  mean beide  std beide  \\\n",
       "0      bert-base-cased -- finetuned specific masking        7.91       2.75   \n",
       "1  bert-base-multilingual-cased -- finetuned spec...        4.37       1.80   \n",
       "2     xlm-roberta-base -- finetuned specific masking       14.46       7.77   \n",
       "\n",
       "   mean alle  std alle  mean two  std two  mean three  std three  mean four  \\\n",
       "0      16.89      2.42      8.47     3.55        9.43       3.93       3.05   \n",
       "1       3.20      1.30      2.61     1.43        1.74       0.85       1.11   \n",
       "2       6.33      3.97      2.86     2.13        2.92       2.14       0.71   \n",
       "\n",
       "   std four  \n",
       "0      1.22  \n",
       "1      0.51  \n",
       "2      0.50  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extended information in the stimulus sentence -- pair of fruit condition -- English fine-tuned\n",
    "calculate_statistics_allboth(df=all_models_results_allboth_morecontext_finetuned_specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d059a7",
   "metadata": {},
   "source": [
    "### Calculate *Completion Sensitivity*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2852a95e",
   "metadata": {},
   "source": [
    "##### (non-)unique fruits condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46c3c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data with both German and English results \n",
    "all_models_results['language'] = 'German'\n",
    "all_models_results_EN['language'] = 'English'\n",
    "\n",
    "merged_data = pd.concat([all_models_results, all_models_results_EN], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "deccf0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_completion_sensitivity(df):\n",
    "    def calculate_score(row, good_col, other_col):\n",
    "        return 1 if row[good_col] > row[other_col] else 0\n",
    "\n",
    "    sensitivity_results = []\n",
    "\n",
    "    for model_name, model_group in df.groupby(\"model_name\"):\n",
    "        model_group[\"sensitivity_def\"] = model_group.apply(lambda row: calculate_score(row, \"score_def\", \"score_indef\"), axis=1)\n",
    "        model_group[\"sensitivity_indef\"] = model_group.apply(lambda row: calculate_score(row, \"score_indef\", \"score_def\"), axis=1)\n",
    "\n",
    "        sensitivity_def_percent = (model_group[\"sensitivity_def\"].sum() / len(model_group)) * 100\n",
    "        sensitivity_indef_percent = (model_group[\"sensitivity_indef\"].sum() / len(model_group)) * 100\n",
    "\n",
    "        sensitivity_results.append({\n",
    "            \"model_name\": model_name,\n",
    "            \"sensitivity_def\": sensitivity_def_percent,\n",
    "            \"sensitivity_indef\": sensitivity_indef_percent\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(sensitivity_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24b387b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_completion_sensitivity(df):\n",
    "    def calculate_score(row, good_col, other_col):\n",
    "        return 1 if row[good_col] > row[other_col] else 0\n",
    "\n",
    "    sensitivity_results = []\n",
    "\n",
    "    for language, dataframe_group in df.groupby(\"language\"):\n",
    "        dataframe_group_results = []\n",
    "\n",
    "        for model_name, model_group in dataframe_group.groupby(\"model_name\"):\n",
    "            model_group[\"sensitivity_def\"] = model_group.apply(lambda row: calculate_score(row, \"score_def\", \"score_indef\"), axis=1)\n",
    "            model_group[\"sensitivity_indef\"] = model_group.apply(lambda row: calculate_score(row, \"score_indef\", \"score_def\"), axis=1)\n",
    "\n",
    "            sensitivity_def_percent = round((model_group[\"sensitivity_def\"].sum() / len(model_group)) * 100, 2)\n",
    "            sensitivity_indef_percent = round((model_group[\"sensitivity_indef\"].sum() / len(model_group)) * 100, 2)\n",
    "\n",
    "            dataframe_group_results.append({\n",
    "                \"model_name\": model_name,\n",
    "                \"sensitivity_def\": sensitivity_def_percent,\n",
    "                \"sensitivity_indef\": sensitivity_indef_percent\n",
    "            })\n",
    "\n",
    "        sensitivity_results.append({\n",
    "            \"language\": language,\n",
    "            \"model_results\": dataframe_group_results\n",
    "        })\n",
    "\n",
    "    final_results = []\n",
    "\n",
    "    for result in sensitivity_results:\n",
    "        for model_result in result[\"model_results\"]:\n",
    "            final_results.append({\n",
    "                \"language\": result[\"language\"],\n",
    "                \"model_name\": model_result[\"model_name\"],\n",
    "                \"sensitivity_def\": model_result[\"sensitivity_def\"],\n",
    "                \"sensitivity_indef\": model_result[\"sensitivity_indef\"]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(final_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ba83a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sensitivity_def</th>\n",
       "      <th>sensitivity_indef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>14.29</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>14.29</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German</td>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>German</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>7.14</td>\n",
       "      <td>92.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>7.14</td>\n",
       "      <td>92.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                    model_name  sensitivity_def  sensitivity_indef\n",
       "0  English               bert-base-cased            14.29              85.71\n",
       "1  English  bert-base-multilingual-cased            14.29              85.71\n",
       "2  English              xlm-roberta-base             0.00             100.00\n",
       "3   German        bert-base-german-cased             0.00             100.00\n",
       "4   German  bert-base-multilingual-cased             7.14              92.86\n",
       "5   German              xlm-roberta-base             7.14              92.86"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_completion_sensitivity(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d56976e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sensitivity_def</th>\n",
       "      <th>sensitivity_indef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-cased -- finetuned specific masking</td>\n",
       "      <td>14.29</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-multilingual-cased finetuned specifi...</td>\n",
       "      <td>14.29</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>1.19</td>\n",
       "      <td>98.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                         model_name  \\\n",
       "0  English      bert-base-cased -- finetuned specific masking   \n",
       "1  English  bert-base-multilingual-cased finetuned specifi...   \n",
       "2  English     xlm-roberta-base -- finetuned specific masking   \n",
       "\n",
       "   sensitivity_def  sensitivity_indef  \n",
       "0            14.29              85.71  \n",
       "1            14.29              85.71  \n",
       "2             1.19              98.81  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tuned English data \n",
    "all_models_results_EN_finetuned_specific['language'] = 'English'\n",
    "calculate_completion_sensitivity(all_models_results_EN_finetuned_specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2171aab5",
   "metadata": {},
   "source": [
    "##### pair of fruits condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c6537c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we can merge the dataframes, first we need to change the column names of the german one \n",
    "column_name_changes = {\n",
    "    \"score_beide\": \"score_both\",\n",
    "    \"score_alle\": \"score_all\", \n",
    "    \"score_zwei\": \"score_two\",\n",
    "    \"score_drei\": \"score_three\", \n",
    "    \"score_vier\": \"score_four\"}\n",
    "\n",
    "# Rename selected columns\n",
    "all_models_results_allebeide.rename(columns=column_name_changes, inplace=True)\n",
    "\n",
    "### data with both German and English results \n",
    "all_models_results_allebeide['language'] = 'German'\n",
    "all_models_results_allboth['language'] = 'English'\n",
    "\n",
    "merged_data_allboth = pd.concat([all_models_results_allebeide, all_models_results_allboth], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b9834d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_completion_sensitivity_allboth(df):\n",
    "    def calculate_score(row, good_col, other_col):\n",
    "        return 1 if row[good_col] > row[other_col] else 0\n",
    "\n",
    "    sensitivity_results = []\n",
    "\n",
    "    for language, dataframe_group in df.groupby(\"language\"):\n",
    "        dataframe_group_results = []\n",
    "\n",
    "        for model_name, model_group in dataframe_group.groupby(\"model_name\"):\n",
    "            model_group[\"sensitivity_both\"] = model_group.apply(lambda row: calculate_score(row, \"score_both\", \"score_all\"), axis=1)\n",
    "            \n",
    "            sensitivity_felicitous_both = round((model_group[\"sensitivity_both\"].sum() / len(model_group)) * 100, 2)\n",
    "\n",
    "            dataframe_group_results.append({\n",
    "                \"model_name\": model_name,\n",
    "                \"sensitivity_both\": sensitivity_felicitous_both,\n",
    "            })\n",
    "\n",
    "        sensitivity_results.append({\n",
    "            \"language\": language,\n",
    "            \"model_results\": dataframe_group_results\n",
    "        })\n",
    "\n",
    "    final_results = []\n",
    "\n",
    "    for result in sensitivity_results:\n",
    "        for model_result in result[\"model_results\"]:\n",
    "            final_results.append({\n",
    "                \"language\": result[\"language\"],\n",
    "                \"model_name\": model_result[\"model_name\"],\n",
    "                \"sensitivity_both\": model_result[\"sensitivity_both\"],\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(final_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2bfe7033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sensitivity_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>90.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German</td>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>German</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>80.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                    model_name  sensitivity_both\n",
       "0  English               bert-base-cased             90.48\n",
       "1  English  bert-base-multilingual-cased              0.00\n",
       "2  English              xlm-roberta-base            100.00\n",
       "3   German        bert-base-german-cased             85.71\n",
       "4   German  bert-base-multilingual-cased              7.14\n",
       "5   German              xlm-roberta-base             80.95"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_completion_sensitivity_allboth(merged_data_allboth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4175e2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sensitivity_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-cased -- finetuned specific masking</td>\n",
       "      <td>69.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                         model_name  \\\n",
       "0  English      bert-base-cased -- finetuned specific masking   \n",
       "1  English  bert-base-multilingual-cased -- finetuned spec...   \n",
       "2  English     xlm-roberta-base -- finetuned specific masking   \n",
       "\n",
       "   sensitivity_both  \n",
       "0             69.05  \n",
       "1            100.00  \n",
       "2            100.00  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tuned English data \n",
    "all_models_results_allboth_finetuned_specific['language'] = 'English'\n",
    "calculate_completion_sensitivity_allboth(all_models_results_allboth_finetuned_specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828b451",
   "metadata": {},
   "source": [
    "### Calculate *Prediction Accuracy*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad4036",
   "metadata": {},
   "source": [
    "##### (non-)unique fruits condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "36b76261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction_accuracy(df, k, defdet, indefdet):\n",
    "    \n",
    "    def is_expected_in_top_k(row, expected_token, k):\n",
    "        predicted_tokens = row[\"predicted_tokens\"]\n",
    "        if isinstance(predicted_tokens, str):\n",
    "            predicted_tokens = predicted_tokens.split()\n",
    "        elif not isinstance(predicted_tokens, list):\n",
    "            raise ValueError(\"Predicted tokens should be a list or a string\")\n",
    "            \n",
    "        return expected_token in predicted_tokens[:k]\n",
    "    \n",
    "    accuracy_results = []\n",
    "\n",
    "    for language, dataframe_group in df.groupby(\"language\"):\n",
    "        dataframe_group_results = []\n",
    "\n",
    "        for model_name, model_group in dataframe_group.groupby(\"model_name\"):\n",
    "            def_accuracy_def = model_group[model_group[\"sentence_type\"] == \"DEF_felicitous\"].apply(\n",
    "                lambda row: is_expected_in_top_k(row, defdet, k),\n",
    "                axis=1\n",
    "            ).mean() * 100\n",
    "\n",
    "            def_accuracy_indef = model_group[model_group[\"sentence_type\"] == \"INDEF_felicitous\"].apply(\n",
    "                lambda row: is_expected_in_top_k(row, indefdet, k),\n",
    "                axis=1\n",
    "            ).mean() * 100\n",
    "            \n",
    "            def_accuracy_def = round(def_accuracy_def, 2)\n",
    "            def_accuracy_indef = round(def_accuracy_indef, 2)\n",
    "\n",
    "            dataframe_group_results.append({\n",
    "                \"model_name\": model_name,\n",
    "                \"accuracy_def_felicitous\": def_accuracy_def,\n",
    "                \"accuracy_indef_felicitous\": def_accuracy_indef\n",
    "            })\n",
    "\n",
    "        accuracy_results.append({\n",
    "            \"language\": language,\n",
    "            \"model_results\": dataframe_group_results\n",
    "        })\n",
    "\n",
    "    final_results = []\n",
    "\n",
    "    for result in accuracy_results:\n",
    "        for model_result in result[\"model_results\"]:\n",
    "            final_results.append({\n",
    "                \"language\": result[\"language\"],\n",
    "                \"model_name\": model_result[\"model_name\"],\n",
    "                \"accuracy_def_felicitous\": model_result[\"accuracy_def_felicitous\"],\n",
    "                \"accuracy_indef_felicitous\": model_result[\"accuracy_indef_felicitous\"]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(final_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c8435ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_def_felicitous</th>\n",
       "      <th>accuracy_indef_felicitous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German</td>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>95.24</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>100.00</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>80.95</td>\n",
       "      <td>78.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                    model_name  accuracy_def_felicitous  \\\n",
       "0   German        bert-base-german-cased                    95.24   \n",
       "1   German  bert-base-multilingual-cased                   100.00   \n",
       "2   German              xlm-roberta-base                    80.95   \n",
       "\n",
       "   accuracy_indef_felicitous  \n",
       "0                     100.00  \n",
       "1                      85.71  \n",
       "2                      78.57  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_prediction_accuracy(all_models_results, k =3,  defdet=\"die\", indefdet=\"eine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a6ea6aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_def_felicitous</th>\n",
       "      <th>accuracy_indef_felicitous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.00</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>100.00</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>16.67</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                    model_name  accuracy_def_felicitous  \\\n",
       "0  English               bert-base-cased                     0.00   \n",
       "1  English  bert-base-multilingual-cased                   100.00   \n",
       "2  English              xlm-roberta-base                    16.67   \n",
       "\n",
       "   accuracy_indef_felicitous  \n",
       "0                      85.71  \n",
       "1                      85.71  \n",
       "2                     100.00  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_prediction_accuracy(all_models_results_EN, k =3,  defdet=\"the\", indefdet=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6179d171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_def_felicitous</th>\n",
       "      <th>accuracy_indef_felicitous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-cased -- finetuned specific masking</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-multilingual-cased finetuned specifi...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                         model_name  \\\n",
       "0  English      bert-base-cased -- finetuned specific masking   \n",
       "1  English  bert-base-multilingual-cased finetuned specifi...   \n",
       "2  English     xlm-roberta-base -- finetuned specific masking   \n",
       "\n",
       "   accuracy_def_felicitous  accuracy_indef_felicitous  \n",
       "0                    100.0                      85.71  \n",
       "1                    100.0                     100.00  \n",
       "2                    100.0                     100.00  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### for fine-tuned English data: \n",
    "calculate_prediction_accuracy(all_models_results_EN_finetuned_specific, k =3,  defdet=\"the\", indefdet=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e3392a",
   "metadata": {},
   "source": [
    "##### pair of fruits condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb820045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction_accuracy_both(df, k, beide):\n",
    "    \n",
    "    def is_expected_in_top_k(row, expected_token, k):\n",
    "        predicted_tokens = row[\"predicted_tokens\"]\n",
    "        if isinstance(predicted_tokens, str):\n",
    "            predicted_tokens = predicted_tokens.split()\n",
    "        elif not isinstance(predicted_tokens, list):\n",
    "            raise ValueError(\"Predicted tokens should be a list or a string\")\n",
    "            \n",
    "        return expected_token in predicted_tokens[:k]\n",
    "    \n",
    "    accuracy_results = []\n",
    "\n",
    "    for language, dataframe_group in df.groupby(\"language\"):\n",
    "        dataframe_group_results = []\n",
    "\n",
    "        for model_name, model_group in dataframe_group.groupby(\"model_name\"):\n",
    "            accuracy_both = model_group[model_group[\"sentence_type\"] == \"all_both\"].apply(\n",
    "                lambda row: is_expected_in_top_k(row, beide, k),\n",
    "                axis=1\n",
    "            ).mean() * 100\n",
    "            \n",
    "            accuracy_both = round(accuracy_both,2)\n",
    "\n",
    "            dataframe_group_results.append({\n",
    "                \"model_name\": model_name,\n",
    "                \"accuracy_felicitous_both\": accuracy_both\n",
    "            })\n",
    "\n",
    "        accuracy_results.append({\n",
    "            \"language\": language,\n",
    "            \"model_results\": dataframe_group_results\n",
    "        })\n",
    "\n",
    "    final_results = []\n",
    "\n",
    "    for result in accuracy_results:\n",
    "        for model_result in result[\"model_results\"]:\n",
    "            final_results.append({\n",
    "                \"language\": result[\"language\"],\n",
    "                \"model_name\": model_result[\"model_name\"],\n",
    "                \"accuracy_felicitous_both\": model_result[\"accuracy_felicitous_both\"],\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fe93fca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_felicitous_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German</td>\n",
       "      <td>bert-base-german-cased</td>\n",
       "      <td>59.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>83.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                    model_name  accuracy_felicitous_both\n",
       "0   German        bert-base-german-cased                     59.52\n",
       "1   German  bert-base-multilingual-cased                     85.71\n",
       "2   German              xlm-roberta-base                     83.33"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_prediction_accuracy_both(all_models_results_allebeide, k =40,  beide=\"beide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "658b5f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_felicitous_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                    model_name  accuracy_felicitous_both\n",
       "0  English               bert-base-cased                      4.76\n",
       "1  English  bert-base-multilingual-cased                      0.00\n",
       "2  English              xlm-roberta-base                     85.71"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_prediction_accuracy_both(all_models_results_allboth, k =40,  beide=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bca7d58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_felicitous_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-cased -- finetuned specific masking</td>\n",
       "      <td>30.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>bert-base-multilingual-cased -- finetuned spec...</td>\n",
       "      <td>38.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>xlm-roberta-base -- finetuned specific masking</td>\n",
       "      <td>54.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                         model_name  \\\n",
       "0  English      bert-base-cased -- finetuned specific masking   \n",
       "1  English  bert-base-multilingual-cased -- finetuned spec...   \n",
       "2  English     xlm-roberta-base -- finetuned specific masking   \n",
       "\n",
       "   accuracy_felicitous_both  \n",
       "0                     30.95  \n",
       "1                     38.10  \n",
       "2                     54.76  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_prediction_accuracy_both(all_models_results_allboth_finetuned_specific, k =3,  beide=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434d1e6",
   "metadata": {},
   "source": [
    "### Visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "af2117a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the data so that we can visualize it \n",
    "\n",
    "### data with both German and English results \n",
    "all_models_results['dataframe_name'] = 'all_models_results'\n",
    "all_models_results_EN['dataframe_name'] = 'all_models_resultsEN'\n",
    "\n",
    "merged_data = pd.concat([all_models_results, all_models_results_EN], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "68d9a581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grouped data for GERMAN\n",
    "grouped_data_german = all_models_results.groupby(\"sentence_type\")[[\"score_def\", \"score_indef\"]].mean()\n",
    "# Grouped data for English\n",
    "grouped_data_english = all_models_results_EN.groupby(\"sentence_type\")[[\"score_def\", \"score_indef\", \"score_one\"]].mean()\n",
    "\n",
    "# Define custom colors for the columns ## hier noch gucken, was schn wre \n",
    "german_colors = [\"blue\", \"orange\"]  \n",
    "english_colors = [\"blue\", \"orange\", \"purple\"]  \n",
    "\n",
    "# Create a figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Define custom labels for sentence types\n",
    "custom_labels = [\"Unique fruit\", \"Non-unique fruit\"]\n",
    "\n",
    "# Plot for German\n",
    "grouped_data_german.plot(kind=\"bar\", ax=ax1, color=german_colors)\n",
    "ax1.set_title(\"German data\", fontsize=\"26\")\n",
    "ax1.set_ylabel(\"Scores\", fontsize=\"26\")\n",
    "ax1.set_xticklabels(custom_labels, rotation=0, fontsize=\"26\")\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.legend([\"Definite determiner\", \"Indefinite determiner\"], fontsize=\"19\")\n",
    "\n",
    "# Plot for English\n",
    "grouped_data_english.plot(kind=\"bar\", ax=ax2, color=english_colors)\n",
    "ax2.set_title(\"English data\", fontsize=\"26\")\n",
    "ax2.set_ylabel(\"Scores\", fontsize=\"26\")\n",
    "ax2.set_xticklabels(custom_labels, rotation=0, fontsize=\"26\")\n",
    "ax2.set_xlabel(\"\")\n",
    "ax2.legend([\"Definite determiner\", \"Indefinite determiner\", \"Numeral 'one'\"], fontsize=\"19\")\n",
    "\n",
    "# Make the y-axis scales of the subplots the same\n",
    "ymin = min(ax1.get_ylim()[0], ax2.get_ylim()[0])\n",
    "ymax = max(ax1.get_ylim()[1], ax2.get_ylim()[1])\n",
    "ax1.set_ylim(ymin, ymax)\n",
    "ax2.set_ylim(ymin, ymax)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Add space for the suptitle\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2b5ba793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grouped data for GERMAN\n",
    "grouped_data_german = all_models_results_allebeide.groupby(\"sentence_type\")[[\"score_both\", \n",
    "                                                                            \"score_all\", \n",
    "                                                                            \"score_two\", \n",
    "                                                                            \"score_three\",\n",
    "                                                                            \"score_four\"]].mean()\n",
    "# Grouped data for English\n",
    "grouped_data_english = all_models_results_allboth.groupby(\"sentence_type\")[[\"score_both\", \n",
    "                                                                            \"score_all\", \n",
    "                                                                            \"score_two\", \n",
    "                                                                            \"score_three\",\n",
    "                                                                            \"score_four\"]].mean()\n",
    "\n",
    "# Define custom colors for the columns ## hier noch gucken, was schn wre \n",
    "german_colors = [\"blue\", \"orange\", \"purple\", \"pink\", \"red\"]  \n",
    "english_colors = [\"blue\", \"orange\", \"purple\", \"pink\", \"red\"]  \n",
    "\n",
    "# Create a figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Define custom labels for sentence types\n",
    "custom_labels = [\"Non-unique fruits\"]#, \"Felicitous indefinite\"]\n",
    "\n",
    "# Plot for GERMAN\n",
    "grouped_data_german.plot(kind=\"bar\", ax=ax1, color=german_colors)\n",
    "ax1.set_title(\"German data\", fontsize=\"26\")\n",
    "ax1.set_ylabel(\"Scores\", fontsize=\"26\")\n",
    "ax1.set_xticklabels(custom_labels, rotation=0, fontsize=\"26\")\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.legend([\"beide\", \"alle\",\"zwei\", \"drei\", \"vier\"], fontsize=\"20\")\n",
    "ax1.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "# Plot for English\n",
    "grouped_data_english.plot(kind=\"bar\", ax=ax2, color=english_colors)\n",
    "ax2.set_title(\"English data\", fontsize=\"26\")\n",
    "ax2.set_ylabel(\"Scores\", fontsize=\"26\")\n",
    "ax2.set_xticklabels(custom_labels, rotation=0, fontsize=\"26\")\n",
    "ax2.set_xlabel(\"\")\n",
    "ax2.legend([\"both\", \"all\",\"two\", \"three\", \"four\"], fontsize=\"20\")\n",
    "ax2.set_yscale(\"log\")\n",
    "\n",
    "# Make the y-axis scales of the subplots the same\n",
    "ymin = min(ax1.get_ylim()[0], ax2.get_ylim()[0])\n",
    "ymax = max(ax1.get_ylim()[1], ax2.get_ylim()[1])\n",
    "ax1.set_ylim(ymin, ymax)\n",
    "ax2.set_ylim(ymin, ymax)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Add space for the suptitle\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ffd763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
